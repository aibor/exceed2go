
exceed2go_bpfel.o:	file format elf64-bpf

Disassembly of section .text:

0000000000000000 <target_search_cb>:
;                  struct target_search_cb_ctx *cb_ctx) {
       0:	r0 = 0x0
;   if (*key == 0) {
       1:	r1 = *(u32 *)(r2 + 0x0)
       2:	if w1 == 0x0 goto +0xf <LBB3_6>
       3:	r0 = 0x1
;   if (!value || !((const __u32 *)(value))[0])
       4:	if r3 == 0x0 goto +0xd <LBB3_6>
       5:	r2 = *(u32 *)(r3 + 0x0)
       6:	if w2 == 0x0 goto +0xb <LBB3_6>
;   return ((a->in6_u.u6_addr64[0] == b->in6_u.u6_addr64[0]) &&
       7:	r2 = *(u64 *)(r3 + 0x0)
       8:	r5 = *(u64 *)(r4 + 0x0)
       9:	r0 = 0x0
      10:	if r5 != r2 goto +0x7 <LBB3_6>
;           (a->in6_u.u6_addr64[1] == b->in6_u.u6_addr64[1]));
      11:	r2 = *(u64 *)(r3 + 0x8)
      12:	r3 = *(u64 *)(r4 + 0x8)
;   if (in6_addr_equal(&cb_ctx->needle, value)) {
      13:	if r3 != r2 goto +0x4 <LBB3_6>
;     cb_ctx->key   = *key;
      14:	*(u32 *)(r4 + 0x10) = r1
      15:	w1 = 0x1
;     cb_ctx->found = true;
      16:	*(u8 *)(r4 + 0x14) = r1
      17:	r0 = 0x1

0000000000000090 <LBB3_6>:
; }
      18:	exit

Disassembly of section xdp:

0000000000000000 <exceed2go_xdp_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r2 = *(u32 *)(r1 + 0x0)
       1:	r9 = *(u32 *)(r1 + 0x4)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       2:	r8 = r2
       3:	r8 += 0x36
       4:	if r8 > r9 goto +0x24 <LBB0_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       5:	r3 = *(u16 *)(r2 + 0xc)
       6:	if w3 != 0xdd86 goto +0x22 <LBB0_6>
       7:	r6 = r2
       8:	r6 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
       9:	r3 = *(u8 *)(r6 + 0x0)
      10:	w3 &= 0xf0
      11:	if w3 != 0x60 goto +0x1d <LBB0_6>
      12:	*(u64 *)(r10 - 0x38) = r1
      13:	*(u64 *)(r10 - 0x30) = r2
      14:	w7 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r7
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB0_5>
      22:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB0_5>:
      24:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
      25:	r1 = *(u64 *)(r2 + 0x2e)
      26:	*(u64 *)(r10 - 0x18) = r1
      27:	r1 = *(u64 *)(r2 + 0x26)
      28:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      29:	*(u8 *)(r10 - 0xc) = r7
      30:	*(u32 *)(r10 - 0x10) = r7
      31:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      32:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      33:	r1 = 0x0 ll
      35:	r2 = 0x0 ll
      37:	r4 = 0x0
      38:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      39:	r1 = *(u8 *)(r10 - 0xc)
      40:	if w1 != 0x0 goto +0xc <LBB0_7>

0000000000000148 <LBB0_6>:
      41:	w1 = 0x5
      42:	*(u32 *)(r10 - 0x20) = r1
      43:	r2 = r10
      44:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      45:	r1 = 0x0 ll
      47:	call 0x1
;   if (likely(value)) {
      48:	if r0 == 0x0 goto +0x2 <LBB0_49>
      49:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      50:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000198 <LBB0_49>:
      51:	w8 = 0x2
      52:	goto +0x159 <LBB0_77>

00000000000001a8 <LBB0_7>:
      53:	*(u64 *)(r10 - 0x40) = r6
      54:	w6 = 0x1
      55:	*(u32 *)(r10 - 0x4) = r6
      56:	r2 = r10
      57:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      58:	r1 = 0x0 ll
      60:	call 0x1
;   if (likely(value)) {
      61:	if r0 == 0x0 goto +0x1 <LBB0_9>
;     __sync_fetch_and_add(value, 1);
      62:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001f8 <LBB0_9>:
      63:	r7 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
      64:	r1 = *(u8 *)(r7 + 0x15)
      65:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      66:	r2 = *(u32 *)(r10 - 0x10)
      67:	if w2 <= w1 goto +0x85 <LBB0_15>
      68:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      69:	r2 += -0x24
      70:	r1 = 0x0 ll
      72:	call 0x1
;     if (exceed_addr != NULL) {
      73:	if r0 == 0x0 goto +0x7f <LBB0_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      74:	r1 = *(u64 *)(r10 - 0x40)
      75:	w9 -= w1
      76:	w6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      77:	w6 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      78:	if w6 s< 0x1 goto +0x4 <LBB0_14>
      79:	w9 &= 0x3
      80:	if w9 == 0x0 goto +0x2 <LBB0_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      81:	w9 = -w9
      82:	w6 = w9

0000000000000298 <LBB0_14>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      83:	r1 = *(u64 *)(r7 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      84:	*(u64 *)(r10 - 0x40) = r1
      85:	r1 = *(u64 *)(r7 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      86:	*(u64 *)(r10 - 0x50) = r1
      87:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      88:	*(u64 *)(r10 - 0x48) = r1
      89:	r1 = *(u64 *)(r0 + 0x0)
      90:	*(u64 *)(r10 - 0x30) = r1
      91:	w1 = 0x6
      92:	*(u32 *)(r10 - 0x20) = r1
;   return tail_adj < 0 ? tail_adj : 0;
      93:	if w6 s< 0x0 goto +0x1 <LBB0_51>
      94:	w6 = 0x0

00000000000002f8 <LBB0_51>:
      95:	r2 = r10
      96:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      97:	r1 = 0x0 ll
      99:	call 0x1
     100:	r7 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     101:	if r0 == 0x0 goto +0x2 <LBB0_53>
     102:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     103:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000340 <LBB0_53>:
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
     104:	r1 = r7
     105:	w2 = -0x30
     106:	call 0x2c
     107:	w8 = 0x0
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
     108:	if r0 != 0x0 goto +0x121 <LBB0_77>
;     assert_equal(bpf_xdp_adjust_tail(ctx, tail_adj), 0, XDP_ABORTED);
     109:	r1 = r7
     110:	w2 = w6
     111:	call 0x41
     112:	if r0 != 0x0 goto +0x11d <LBB0_77>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     113:	r9 = *(u32 *)(r7 + 0x4)
     114:	r6 = *(u32 *)(r7 + 0x0)
;       assert_boundary(old_eth, pkt.end, XDP_ABORTED);
     115:	r1 = r6
     116:	r1 += 0x3e
     117:	if r1 > r9 goto +0x118 <LBB0_77>
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     118:	r7 = r6
     119:	r7 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     120:	w1 = w9
     121:	w1 -= w7
     122:	w2 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     123:	*(u32 *)(r6 + 0xe) = r2
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     124:	r2 = *(u64 *)(r10 - 0x50)
     125:	*(u64 *)(r6 + 0x26) = r2
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     126:	r2 = *(u64 *)(r10 - 0x48)
     127:	*(u64 *)(r6 + 0x1e) = r2
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     128:	r2 = *(u64 *)(r10 - 0x30)
     129:	*(u64 *)(r6 + 0x16) = r2
     130:	w2 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     131:	*(u16 *)(r6 + 0x14) = r2
;   __u32 daddr_first           = *(__u32 *)old;
     132:	r2 = *(u32 *)(r6 + 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     133:	r3 = *(u64 *)(r10 - 0x40)
     134:	*(u64 *)(r6 + 0x2e) = r3
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     135:	r3 = *(u16 *)(r6 + 0x36)
     136:	r4 = *(u16 *)(r6 + 0x38)
     137:	w5 = 0x3
;   *icmp6                    = icmp6_new;
     138:	*(u32 *)(r6 + 0x36) = r5
;   *(__u32 *)&new->saddr       = daddr_first;
     139:	w5 = w2
     140:	w5 >>= 0x10
     141:	*(u16 *)(r6 + 0x8) = r5
     142:	*(u16 *)(r6 + 0x6) = r2
;   __u16 daddr_last            = *(__u16 *)old + 2;
     143:	w2 += 0x2
;   *((__u16 *)&new->saddr + 2) = daddr_last;
     144:	*(u16 *)(r6 + 0xa) = r2
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     145:	r2 = *(u16 *)(r6 + 0x3a)
     146:	*(u16 *)(r6 + 0x4) = r2
     147:	*(u16 *)(r6 + 0x2) = r4
     148:	*(u16 *)(r6 + 0x0) = r3
;   new->proto                  = old->proto;
     149:	r2 = *(u16 *)(r6 + 0x3c)
     150:	*(u16 *)(r6 + 0xc) = r2
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     151:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     152:	*(u16 *)(r6 + 0x12) = r1
     153:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     154:	*(u32 *)(r6 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     155:	r3 = r6
     156:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     157:	r1 = 0x0
     158:	w2 = 0x0
     159:	w4 = 0x20
     160:	w5 = 0x0
     161:	call 0x1c
     162:	r1 = r0
     163:	*(u64 *)(r10 - 0x30) = r6
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     164:	r3 = *(u16 *)(r6 + 0x12)
     165:	w3 <<= 0x10
;   csum += addend;
     166:	w0 = w3
     167:	w0 += w1
     168:	w1 = 0x1
     169:	w2 = 0x1
;   csum += addend;
     170:	if w0 < w3 goto +0x1 <LBB0_58>
     171:	w2 = 0x0

0000000000000560 <LBB0_58>:
;   return csum + (csum < addend);
     172:	w0 += w2
     173:	if w0 > -0x3a000001 goto +0x1 <LBB0_60>
     174:	w1 = 0x0

0000000000000578 <LBB0_60>:
;   csum += addend;
     175:	w0 += w1
     176:	w8 = 0x400
;   return csum + (csum < addend);
     177:	w0 += 0x3a000000
     178:	goto +0x4 <LBB0_61>

0000000000000598 <LBB0_67>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     179:	w1 &= 0xffff
     180:	w8 = w1
     181:	if w1 > 0x4 goto +0x1 <LBB0_61>
     182:	goto +0xb7 <LBB0_79>

00000000000005b8 <LBB0_61>:
     183:	w4 = w8
;     __u16 j = (i >= 512) ? 512 : i;
     184:	if w8 < 0x200 goto +0x1 <LBB0_63>
     185:	w4 = 0x200

00000000000005d0 <LBB0_63>:
;     if (likely(buf + j <= data_end)) {
     186:	r6 = r7
     187:	r6 += r4
     188:	if r6 > r9 goto +0x6 <LBB0_65>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     189:	r1 = 0x0
     190:	w2 = 0x0
     191:	r3 = r7
     192:	w5 = w0
     193:	call 0x1c
     194:	r7 = r6

0000000000000618 <LBB0_65>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     195:	w1 = w8
     196:	w1 += 0xfe00
     197:	if w8 > 0x200 goto -0x13 <LBB0_67>
     198:	w8 >>= 0x1
     199:	w1 = w8
     200:	goto -0x16 <LBB0_67>

0000000000000648 <LBB0_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     201:	r1 = *(u8 *)(r7 + 0x14)
     202:	if w1 != 0x3a goto -0xa2 <LBB0_6>
     203:	w1 = 0x2
     204:	*(u32 *)(r10 - 0x4) = r1
     205:	r2 = r10
     206:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     207:	r1 = 0x0 ll
     209:	call 0x1
;   if (likely(value)) {
     210:	if r0 == 0x0 goto +0x2 <LBB0_18>
     211:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     212:	lock *(u32 *)(r0 + 0x0) += r1

00000000000006a8 <LBB0_18>:
;   assert_boundary(icmp6, pkt->end, false);
     213:	r1 = r7
     214:	r1 += 0x3e
     215:	if r1 > r9 goto -0xaf <LBB0_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     216:	r1 = *(u8 *)(r8 + 0x0)
     217:	if w1 != 0x80 goto -0xb1 <LBB0_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     218:	r1 = *(u8 *)(r7 + 0x37)
     219:	if w1 != 0x0 goto -0xb3 <LBB0_6>
     220:	w1 = 0x3
     221:	*(u32 *)(r10 - 0x4) = r1
     222:	r2 = r10
     223:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     224:	r1 = 0x0 ll
     226:	call 0x1
;   if (likely(value)) {
     227:	if r0 == 0x0 goto +0x2 <LBB0_23>
     228:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     229:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000730 <LBB0_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     230:	r3 = r7
     231:	r3 += 0x16
     232:	r1 = 0x0
     233:	w2 = 0x0
     234:	w4 = 0x20
     235:	w5 = 0x0
     236:	call 0x1c
     237:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     238:	r3 = *(u16 *)(r7 + 0x12)
     239:	w3 <<= 0x10
;   csum += addend;
     240:	w0 = w3
     241:	w0 += w1
     242:	w1 = 0x1
     243:	w2 = 0x1
;   csum += addend;
     244:	if w0 < w3 goto +0x1 <LBB0_25>
     245:	w2 = 0x0

00000000000007b0 <LBB0_25>:
;   return csum + (csum < addend);
     246:	w0 += w2
     247:	if w0 > -0x3a000001 goto +0x1 <LBB0_27>
     248:	w1 = 0x0

00000000000007c8 <LBB0_27>:
;   csum += addend;
     249:	w0 += w1
     250:	w7 = 0x400
;   return csum + (csum < addend);
     251:	w0 += 0x3a000000
     252:	goto +0x4 <LBB0_28>

00000000000007e8 <LBB0_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     253:	w1 &= 0xffff
     254:	w7 = w1
     255:	if w1 > 0x4 goto +0x1 <LBB0_28>
     256:	goto +0x12 <LBB0_78>

0000000000000808 <LBB0_28>:
     257:	w4 = w7
;     __u16 j = (i >= 512) ? 512 : i;
     258:	if w7 < 0x200 goto +0x1 <LBB0_30>
     259:	w4 = 0x200

0000000000000820 <LBB0_30>:
;     if (likely(buf + j <= data_end)) {
     260:	r6 = r8
     261:	r6 += r4
     262:	if r6 > r9 goto +0x6 <LBB0_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     263:	r1 = 0x0
     264:	w2 = 0x0
     265:	r3 = r8
     266:	w5 = w0
     267:	call 0x1c
     268:	r8 = r6

0000000000000868 <LBB0_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     269:	w1 = w7
     270:	w1 += 0xfe00
     271:	if w7 > 0x200 goto -0x13 <LBB0_34>
     272:	w7 >>= 0x1
     273:	w1 = w7
     274:	goto -0x16 <LBB0_34>

0000000000000898 <LBB0_78>:
;   if (likely(buf + 4 <= data_end)) {
     275:	r1 = r8
     276:	r1 += 0x4
     277:	r6 = *(u64 *)(r10 - 0x30)
     278:	if r1 > r9 goto +0x9 <LBB0_38>
;     sum = csum_add(sum, *(__be32 *)buf++);
     279:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     280:	w1 = w3
     281:	w1 += w0
     282:	w2 = 0x1
     283:	if w1 < w3 goto +0x1 <LBB0_37>
     284:	w2 = 0x0

00000000000008e8 <LBB0_37>:
;   return csum + (csum < addend);
     285:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     286:	r8 += 0x1
     287:	w0 = w1

0000000000000900 <LBB0_38>:
     288:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     289:	r2 = r8
     290:	r2 += 0x2
     291:	if r2 > r9 goto +0x2 <LBB0_40>
;     addend = *(__be16 *)buf++;
     292:	r1 = *(u16 *)(r8 + 0x0)
     293:	r8 += 0x1

0000000000000930 <LBB0_40>:
;   if (likely(buf + 1 <= data_end)) {
     294:	r2 = r8
     295:	r2 += 0x1
     296:	if r2 > r9 goto +0x2 <LBB0_42>
;     addend += *(__u8 *)buf++;
     297:	r2 = *(u8 *)(r8 + 0x0)
     298:	w1 += w2

0000000000000958 <LBB0_42>:
;   csum += addend;
     299:	w2 = w1
     300:	w2 += w0
     301:	w3 = 0x1
     302:	if w2 < w1 goto +0x1 <LBB0_44>
     303:	w3 = 0x0

0000000000000980 <LBB0_44>:
;   return csum + (csum < addend);
     304:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     305:	w1 = w2
     306:	w1 >>= 0x10
     307:	w2 &= 0xffff
     308:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     309:	w1 = w2
     310:	w1 >>= 0x10
     311:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     312:	w1 &= 0xffff
     313:	if w1 != 0xffff goto -0x111 <LBB0_6>
     314:	w1 = 0x4
     315:	*(u32 *)(r10 - 0x4) = r1
     316:	r2 = r10
     317:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     318:	r1 = 0x0 ll
     320:	call 0x1
;   if (likely(value)) {
     321:	if r0 == 0x0 goto +0x2 <LBB0_47>
     322:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     323:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000a20 <LBB0_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     324:	r8 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     325:	r9 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     326:	r7 = *(u64 *)(r6 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     327:	r6 = *(u64 *)(r6 + 0x26)
     328:	w1 = 0x7
     329:	*(u32 *)(r10 - 0x20) = r1
     330:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     331:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     332:	r1 = 0x0 ll
     334:	call 0x1
;   if (likely(value)) {
     335:	if r0 == 0x0 goto +0x2 <LBB0_73>
     336:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     337:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000a90 <LBB0_73>:
     338:	w1 = 0x60
     339:	r5 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     340:	*(u32 *)(r5 + 0xe) = r1
     341:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     342:	*(u16 *)(r5 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     343:	*(u64 *)(r5 + 0x2e) = r8
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     344:	*(u64 *)(r5 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     345:	*(u64 *)(r5 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     346:	*(u64 *)(r5 + 0x16) = r6
     347:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     348:	*(u16 *)(r5 + 0x14) = r1
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     349:	r1 = *(u16 *)(r5 + 0xa)
;   __u32 daddr_first           = *(__u32 *)old;
     350:	r2 = *(u32 *)(r5 + 0x0)
;   __u16 daddr_last            = *(__u16 *)old + 2;
     351:	w3 = w2
     352:	w3 += 0x2
;   *((__u16 *)&new->saddr + 2) = daddr_last;
     353:	*(u16 *)(r5 + 0xa) = r3
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     354:	r3 = *(u16 *)(r5 + 0x8)
     355:	r4 = *(u16 *)(r5 + 0x6)
;   *(__u32 *)&new->saddr       = daddr_first;
     356:	*(u16 *)(r5 + 0x6) = r2
     357:	w2 >>= 0x10
     358:	*(u16 *)(r5 + 0x8) = r2
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     359:	r2 = *(u16 *)(r5 + 0x38)
     360:	w2 += -0x1
     361:	*(u16 *)(r5 + 0x38) = r2
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     362:	*(u16 *)(r5 + 0x4) = r1
     363:	*(u16 *)(r5 + 0x0) = r4
     364:	*(u16 *)(r5 + 0x2) = r3
     365:	goto +0x15 <LBB0_74>

0000000000000b70 <LBB0_79>:
;   if (likely(buf + 4 <= data_end)) {
     366:	r1 = r7
     367:	r1 += 0x4
     368:	if r1 > r9 goto +0x8 <LBB0_71>
;     sum = csum_add(sum, *(__be32 *)buf++);
     369:	r3 = *(u32 *)(r7 + 0x0)
;   csum += addend;
     370:	w1 = w3
     371:	w1 += w0
     372:	w2 = 0x1
     373:	if w1 < w3 goto +0x1 <LBB0_70>
     374:	w2 = 0x0

0000000000000bb8 <LBB0_70>:
;   return csum + (csum < addend);
     375:	w1 += w2
     376:	w0 = w1

0000000000000bc8 <LBB0_71>:
;   sum = (sum & 0xffff) + (sum >> 16);
     377:	w1 = w0
     378:	w1 >>= 0x10
     379:	w0 &= 0xffff
     380:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     381:	w1 = w0
     382:	w1 >>= 0x10
     383:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     384:	w1 ^= -0x1
     385:	r2 = *(u64 *)(r10 - 0x30)
     386:	*(u16 *)(r2 + 0x38) = r1

0000000000000c18 <LBB0_74>:
     387:	w1 = 0x8
     388:	*(u32 *)(r10 - 0x20) = r1
     389:	r2 = r10
     390:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     391:	r1 = 0x0 ll
     393:	call 0x1
;   if (likely(value)) {
     394:	if r0 == 0x0 goto +0x2 <LBB0_76>
     395:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     396:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000c68 <LBB0_76>:
     397:	w8 = 0x3

0000000000000c70 <LBB0_77>:
;   return exceed2go_xdp(ctx, BASE_LAYER_L2);
     398:	w0 = w8
     399:	exit

Disassembly of section tc:

0000000000000000 <exceed2go_tc_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r9 = *(u32 *)(r1 + 0x50)
       1:	*(u64 *)(r10 - 0x38) = r1
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       2:	r2 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       3:	r8 = r2
       4:	r8 += 0x36
       5:	if r8 > r9 goto +0x23 <LBB1_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       6:	r1 = *(u16 *)(r2 + 0xc)
       7:	if w1 != 0xdd86 goto +0x21 <LBB1_6>
       8:	r7 = r2
       9:	r7 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
      10:	r1 = *(u8 *)(r7 + 0x0)
      11:	w1 &= 0xf0
      12:	if w1 != 0x60 goto +0x1c <LBB1_6>
      13:	*(u64 *)(r10 - 0x30) = r2
      14:	w6 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r6
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB1_5>
      22:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB1_5>:
      24:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
      25:	r1 = *(u64 *)(r2 + 0x2e)
      26:	*(u64 *)(r10 - 0x18) = r1
      27:	r1 = *(u64 *)(r2 + 0x26)
      28:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      29:	*(u8 *)(r10 - 0xc) = r6
      30:	*(u32 *)(r10 - 0x10) = r6
      31:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      32:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      33:	r1 = 0x0 ll
      35:	r2 = 0x0 ll
      37:	r4 = 0x0
      38:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      39:	r1 = *(u8 *)(r10 - 0xc)
      40:	if w1 != 0x0 goto +0xc <LBB1_7>

0000000000000148 <LBB1_6>:
      41:	w1 = 0x5
      42:	*(u32 *)(r10 - 0x20) = r1
      43:	r2 = r10
      44:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      45:	r1 = 0x0 ll
      47:	call 0x1
;   if (likely(value)) {
      48:	if r0 == 0x0 goto +0x2 <LBB1_49>
      49:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      50:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000198 <LBB1_49>:
      51:	w3 = -0x1
      52:	goto +0x17f <LBB1_78>

00000000000001a8 <LBB1_7>:
      53:	w6 = 0x1
      54:	*(u32 *)(r10 - 0x4) = r6
      55:	r2 = r10
      56:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      57:	r1 = 0x0 ll
      59:	call 0x1
;   if (likely(value)) {
      60:	if r0 == 0x0 goto +0x1 <LBB1_9>
;     __sync_fetch_and_add(value, 1);
      61:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001f0 <LBB1_9>:
      62:	r6 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
      63:	r1 = *(u8 *)(r6 + 0x15)
      64:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      65:	r2 = *(u32 *)(r10 - 0x10)
      66:	if w2 <= w1 goto +0xa5 <LBB1_15>
      67:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      68:	r2 += -0x24
      69:	r1 = 0x0 ll
      71:	call 0x1
;     if (exceed_addr != NULL) {
      72:	if r0 == 0x0 goto +0x9f <LBB1_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      73:	w9 -= w7
      74:	w2 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      75:	w2 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      76:	if w2 s< 0x1 goto +0x4 <LBB1_14>
      77:	w9 &= 0x3
      78:	if w9 == 0x0 goto +0x2 <LBB1_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      79:	w9 = -w9
      80:	w2 = w9

0000000000000288 <LBB1_14>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      81:	r1 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      82:	*(u64 *)(r10 - 0x70) = r1
      83:	r1 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      84:	*(u64 *)(r10 - 0x68) = r1
      85:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      86:	*(u64 *)(r10 - 0x60) = r1
      87:	r1 = *(u64 *)(r0 + 0x0)
      88:	*(u64 *)(r10 - 0x58) = r1
      89:	w1 = 0x6
      90:	*(u32 *)(r10 - 0x20) = r1
      91:	r8 = *(u64 *)(r10 - 0x38)
;   return tail_adj < 0 ? tail_adj : 0;
      92:	if w2 s< 0x0 goto +0x1 <LBB1_51>
      93:	w2 = 0x0

00000000000002f0 <LBB1_51>:
      94:	w9 = w2
      95:	r2 = r10
      96:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      97:	r1 = 0x0 ll
      99:	call 0x1
;   if (likely(value)) {
     100:	if r0 == 0x0 goto +0x2 <LBB1_53>
     101:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     102:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000338 <LBB1_53>:
;       bpf_memcpy(&eth, pkt.eth, sizeof(struct ethhdr));
     103:	r1 = *(u16 *)(r6 + 0x6)
     104:	*(u64 *)(r10 - 0x50) = r1
     105:	r1 = *(u16 *)(r6 + 0x0)
     106:	*(u32 *)(r10 - 0x40) = r1
     107:	r7 = *(u16 *)(r6 + 0x2)
     108:	r1 = *(u16 *)(r6 + 0xa)
     109:	*(u32 *)(r10 - 0x48) = r1
     110:	r1 = r6
     111:	r6 = *(u16 *)(r1 + 0xc)
     112:	r1 = *(u16 *)(r1 + 0x8)
;     long rc_head_adj = bpf_skb_adjust_room(ctx,
     113:	*(u64 *)(r10 - 0x30) = r1
     114:	r1 = r8
     115:	w2 = 0x30
     116:	w3 = 0x1
     117:	r4 = 0x1
     118:	call 0x32
     119:	w3 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     120:	if r0 != 0x0 goto +0x13b <LBB1_78>
;     int new_len = ctx->len + pkt.tail_adjust;
     121:	r2 = *(u32 *)(r8 + 0x0)
     122:	w2 += w9
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     123:	r1 = r8
     124:	r3 = 0x0
     125:	call 0x26
     126:	w3 = 0x2
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     127:	if r0 != 0x0 goto +0x134 <LBB1_78>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     128:	r9 = *(u32 *)(r8 + 0x50)
     129:	r2 = *(u32 *)(r8 + 0x4c)
;       assert_boundary(pkt.eth, pkt.end, TC_ACT_SHOT);
     130:	r1 = r2
     131:	r1 += 0xe
     132:	if r1 > r9 goto +0x12f <LBB1_78>
     133:	r1 = *(u64 *)(r10 - 0x30)
     134:	r1 <<= 0x10
     135:	r4 = *(u64 *)(r10 - 0x50)
     136:	r1 |= r4
     137:	w6 <<= 0x10
     138:	r4 = *(u32 *)(r10 - 0x48)
     139:	w6 |= w4
     140:	r6 <<= 0x20
     141:	r6 |= r1
     142:	w7 <<= 0x10
     143:	r1 = *(u32 *)(r10 - 0x40)
     144:	w7 |= w1
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     145:	*(u16 *)(r2 + 0x0) = r6
;   *(__u32 *)&new->saddr       = daddr_first;
     146:	w1 = w7
     147:	w1 >>= 0x10
     148:	*(u16 *)(r2 + 0x8) = r1
     149:	*(u16 *)(r2 + 0x6) = r7
;   __u16 daddr_last            = *(__u16 *)old + 2;
     150:	w7 += 0x2
;   *((__u16 *)&new->saddr + 2) = daddr_last;
     151:	*(u16 *)(r2 + 0xa) = r7
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     152:	r1 = r6
     153:	r1 >>= 0x20
     154:	*(u16 *)(r2 + 0x4) = r1
     155:	r1 = r6
     156:	r1 >>= 0x10
     157:	*(u16 *)(r2 + 0x2) = r1
     158:	r6 >>= 0x30
;   new->proto                  = old->proto;
     159:	*(u16 *)(r2 + 0xc) = r6
;   assert_boundary(icmp6, pkt->end, false);
     160:	r1 = r2
     161:	r1 += 0x3e
     162:	if r1 > r9 goto +0x111 <LBB1_78>
     163:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     164:	*(u32 *)(r2 + 0xe) = r1
     165:	w1 = 0x3
;   *icmp6                    = icmp6_new;
     166:	*(u32 *)(r2 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     167:	r1 = *(u64 *)(r10 - 0x70)
     168:	*(u64 *)(r2 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     169:	r1 = *(u64 *)(r10 - 0x68)
     170:	*(u64 *)(r2 + 0x26) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     171:	r1 = *(u64 *)(r10 - 0x60)
     172:	*(u64 *)(r2 + 0x1e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     173:	r1 = *(u64 *)(r10 - 0x58)
     174:	*(u64 *)(r2 + 0x16) = r1
     175:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     176:	*(u16 *)(r2 + 0x14) = r1
     177:	r6 = r2
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     178:	r8 = r6
     179:	r8 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     180:	w1 = w9
     181:	w1 -= w8
     182:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     183:	*(u16 *)(r6 + 0x12) = r1
     184:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     185:	*(u32 *)(r6 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     186:	r3 = r6
     187:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     188:	r1 = 0x0
     189:	w2 = 0x0
     190:	w4 = 0x20
     191:	w5 = 0x0
     192:	call 0x1c
     193:	r1 = r0
     194:	*(u64 *)(r10 - 0x30) = r6
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     195:	r3 = *(u16 *)(r6 + 0x12)
     196:	w3 <<= 0x10
;   csum += addend;
     197:	w0 = w3
     198:	w0 += w1
     199:	w1 = 0x1
     200:	w2 = 0x1
;   csum += addend;
     201:	if w0 < w3 goto +0x1 <LBB1_59>
     202:	w2 = 0x0

0000000000000658 <LBB1_59>:
;   return csum + (csum < addend);
     203:	w0 += w2
     204:	if w0 > -0x3a000001 goto +0x1 <LBB1_61>
     205:	w1 = 0x0

0000000000000670 <LBB1_61>:
;   csum += addend;
     206:	w0 += w1
     207:	w6 = 0x400
;   return csum + (csum < addend);
     208:	w0 += 0x3a000000
     209:	goto +0x4 <LBB1_62>

0000000000000690 <LBB1_68>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     210:	w1 &= 0xffff
     211:	w6 = w1
     212:	if w1 > 0x4 goto +0x1 <LBB1_62>
     213:	goto +0xba <LBB1_80>

00000000000006b0 <LBB1_62>:
     214:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     215:	if w6 < 0x200 goto +0x1 <LBB1_64>
     216:	w4 = 0x200

00000000000006c8 <LBB1_64>:
;     if (likely(buf + j <= data_end)) {
     217:	r7 = r8
     218:	r7 += r4
     219:	if r7 > r9 goto +0x6 <LBB1_66>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     220:	r1 = 0x0
     221:	w2 = 0x0
     222:	r3 = r8
     223:	w5 = w0
     224:	call 0x1c
     225:	r8 = r7

0000000000000710 <LBB1_66>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     226:	w1 = w6
     227:	w1 += 0xfe00
     228:	if w6 > 0x200 goto -0x13 <LBB1_68>
     229:	w6 >>= 0x1
     230:	w1 = w6
     231:	goto -0x16 <LBB1_68>

0000000000000740 <LBB1_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     232:	r1 = *(u8 *)(r6 + 0x14)
     233:	if w1 != 0x3a goto -0xc1 <LBB1_6>
     234:	w1 = 0x2
     235:	*(u32 *)(r10 - 0x4) = r1
     236:	r2 = r10
     237:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     238:	r1 = 0x0 ll
     240:	call 0x1
;   if (likely(value)) {
     241:	if r0 == 0x0 goto +0x2 <LBB1_18>
     242:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     243:	lock *(u32 *)(r0 + 0x0) += r1

00000000000007a0 <LBB1_18>:
;   assert_boundary(icmp6, pkt->end, false);
     244:	r1 = r6
     245:	r1 += 0x3e
     246:	if r1 > r9 goto -0xce <LBB1_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     247:	r1 = *(u8 *)(r8 + 0x0)
     248:	if w1 != 0x80 goto -0xd0 <LBB1_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     249:	r1 = *(u8 *)(r6 + 0x37)
     250:	if w1 != 0x0 goto -0xd2 <LBB1_6>
     251:	w1 = 0x3
     252:	*(u32 *)(r10 - 0x4) = r1
     253:	r2 = r10
     254:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     255:	r1 = 0x0 ll
     257:	call 0x1
;   if (likely(value)) {
     258:	if r0 == 0x0 goto +0x2 <LBB1_23>
     259:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     260:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000828 <LBB1_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     261:	r3 = r6
     262:	r3 += 0x16
     263:	r1 = 0x0
     264:	w2 = 0x0
     265:	w4 = 0x20
     266:	w5 = 0x0
     267:	call 0x1c
     268:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     269:	r3 = *(u16 *)(r6 + 0x12)
     270:	w3 <<= 0x10
;   csum += addend;
     271:	w0 = w3
     272:	w0 += w1
     273:	w1 = 0x1
     274:	w2 = 0x1
;   csum += addend;
     275:	if w0 < w3 goto +0x1 <LBB1_25>
     276:	w2 = 0x0

00000000000008a8 <LBB1_25>:
;   return csum + (csum < addend);
     277:	w0 += w2
     278:	if w0 > -0x3a000001 goto +0x1 <LBB1_27>
     279:	w1 = 0x0

00000000000008c0 <LBB1_27>:
;   csum += addend;
     280:	w0 += w1
     281:	w6 = 0x400
;   return csum + (csum < addend);
     282:	w0 += 0x3a000000
     283:	goto +0x4 <LBB1_28>

00000000000008e0 <LBB1_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     284:	w1 &= 0xffff
     285:	w6 = w1
     286:	if w1 > 0x4 goto +0x1 <LBB1_28>
     287:	goto +0x12 <LBB1_79>

0000000000000900 <LBB1_28>:
     288:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     289:	if w6 < 0x200 goto +0x1 <LBB1_30>
     290:	w4 = 0x200

0000000000000918 <LBB1_30>:
;     if (likely(buf + j <= data_end)) {
     291:	r7 = r8
     292:	r7 += r4
     293:	if r7 > r9 goto +0x6 <LBB1_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     294:	r1 = 0x0
     295:	w2 = 0x0
     296:	r3 = r8
     297:	w5 = w0
     298:	call 0x1c
     299:	r8 = r7

0000000000000960 <LBB1_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     300:	w1 = w6
     301:	w1 += 0xfe00
     302:	if w6 > 0x200 goto -0x13 <LBB1_34>
     303:	w6 >>= 0x1
     304:	w1 = w6
     305:	goto -0x16 <LBB1_34>

0000000000000990 <LBB1_79>:
;   if (likely(buf + 4 <= data_end)) {
     306:	r1 = r8
     307:	r1 += 0x4
     308:	r6 = *(u64 *)(r10 - 0x30)
     309:	if r1 > r9 goto +0x9 <LBB1_38>
;     sum = csum_add(sum, *(__be32 *)buf++);
     310:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     311:	w1 = w3
     312:	w1 += w0
     313:	w2 = 0x1
     314:	if w1 < w3 goto +0x1 <LBB1_37>
     315:	w2 = 0x0

00000000000009e0 <LBB1_37>:
;   return csum + (csum < addend);
     316:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     317:	r8 += 0x1
     318:	w0 = w1

00000000000009f8 <LBB1_38>:
     319:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     320:	r2 = r8
     321:	r2 += 0x2
     322:	if r2 > r9 goto +0x2 <LBB1_40>
;     addend = *(__be16 *)buf++;
     323:	r1 = *(u16 *)(r8 + 0x0)
     324:	r8 += 0x1

0000000000000a28 <LBB1_40>:
;   if (likely(buf + 1 <= data_end)) {
     325:	r2 = r8
     326:	r2 += 0x1
     327:	if r2 > r9 goto +0x2 <LBB1_42>
;     addend += *(__u8 *)buf++;
     328:	r2 = *(u8 *)(r8 + 0x0)
     329:	w1 += w2

0000000000000a50 <LBB1_42>:
;   csum += addend;
     330:	w2 = w1
     331:	w2 += w0
     332:	w3 = 0x1
     333:	if w2 < w1 goto +0x1 <LBB1_44>
     334:	w3 = 0x0

0000000000000a78 <LBB1_44>:
;   return csum + (csum < addend);
     335:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     336:	w1 = w2
     337:	w1 >>= 0x10
     338:	w2 &= 0xffff
     339:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     340:	w1 = w2
     341:	w1 >>= 0x10
     342:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     343:	w1 &= 0xffff
     344:	if w1 != 0xffff goto -0x130 <LBB1_6>
     345:	w1 = 0x4
     346:	*(u32 *)(r10 - 0x4) = r1
     347:	r2 = r10
     348:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     349:	r1 = 0x0 ll
     351:	call 0x1
     352:	r8 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     353:	if r0 == 0x0 goto +0x2 <LBB1_47>
     354:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     355:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000b20 <LBB1_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     356:	r1 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     357:	*(u64 *)(r10 - 0x40) = r1
     358:	r9 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     359:	r7 = *(u64 *)(r6 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     360:	r6 = *(u64 *)(r6 + 0x26)
     361:	w1 = 0x7
     362:	*(u32 *)(r10 - 0x20) = r1
     363:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     364:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     365:	r1 = 0x0 ll
     367:	call 0x1
;   if (likely(value)) {
     368:	if r0 == 0x0 goto +0x2 <LBB1_74>
     369:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     370:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000b98 <LBB1_74>:
     371:	w1 = 0x60
     372:	r5 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     373:	*(u32 *)(r5 + 0xe) = r1
     374:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     375:	*(u16 *)(r5 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     376:	r1 = *(u64 *)(r10 - 0x40)
     377:	*(u64 *)(r5 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     378:	*(u64 *)(r5 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     379:	*(u64 *)(r5 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     380:	*(u64 *)(r5 + 0x16) = r6
     381:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     382:	*(u16 *)(r5 + 0x14) = r1
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     383:	r1 = *(u16 *)(r5 + 0xa)
;   __u32 daddr_first           = *(__u32 *)old;
     384:	r2 = *(u32 *)(r5 + 0x0)
;   __u16 daddr_last            = *(__u16 *)old + 2;
     385:	w3 = w2
     386:	w3 += 0x2
;   *((__u16 *)&new->saddr + 2) = daddr_last;
     387:	*(u16 *)(r5 + 0xa) = r3
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     388:	r3 = *(u16 *)(r5 + 0x8)
     389:	r4 = *(u16 *)(r5 + 0x6)
;   *(__u32 *)&new->saddr       = daddr_first;
     390:	*(u16 *)(r5 + 0x6) = r2
     391:	w2 >>= 0x10
     392:	*(u16 *)(r5 + 0x8) = r2
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     393:	r2 = *(u16 *)(r5 + 0x38)
     394:	w2 += -0x1
     395:	*(u16 *)(r5 + 0x38) = r2
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     396:	*(u16 *)(r5 + 0x4) = r1
     397:	*(u16 *)(r5 + 0x0) = r4
     398:	*(u16 *)(r5 + 0x2) = r3
     399:	goto +0x16 <LBB1_75>

0000000000000c80 <LBB1_80>:
;   if (likely(buf + 4 <= data_end)) {
     400:	r1 = r8
     401:	r1 += 0x4
     402:	if r1 > r9 goto +0x8 <LBB1_72>
;     sum = csum_add(sum, *(__be32 *)buf++);
     403:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     404:	w1 = w3
     405:	w1 += w0
     406:	w2 = 0x1
     407:	if w1 < w3 goto +0x1 <LBB1_71>
     408:	w2 = 0x0

0000000000000cc8 <LBB1_71>:
;   return csum + (csum < addend);
     409:	w1 += w2
     410:	w0 = w1

0000000000000cd8 <LBB1_72>:
;   sum = (sum & 0xffff) + (sum >> 16);
     411:	w1 = w0
     412:	w1 >>= 0x10
     413:	w0 &= 0xffff
     414:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     415:	w1 = w0
     416:	w1 >>= 0x10
     417:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     418:	w1 ^= -0x1
     419:	r2 = *(u64 *)(r10 - 0x30)
     420:	*(u16 *)(r2 + 0x38) = r1
     421:	r8 = *(u64 *)(r10 - 0x38)

0000000000000d30 <LBB1_75>:
     422:	w1 = 0x8
     423:	*(u32 *)(r10 - 0x20) = r1
     424:	r2 = r10
     425:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     426:	r1 = 0x0 ll
     428:	call 0x1
;   if (likely(value)) {
     429:	if r0 == 0x0 goto +0x2 <LBB1_77>
     430:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     431:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000d80 <LBB1_77>:
;   return bpf_redirect(ctx->ifindex, 0);
     432:	r1 = *(u32 *)(r8 + 0x28)
     433:	r2 = 0x0
     434:	call 0x17
     435:	r3 = r0

0000000000000da0 <LBB1_78>:
;   return exceed2go_tc(ctx, BASE_LAYER_L2);
     436:	w0 = w3
     437:	exit

0000000000000db0 <exceed2go_tc_l3>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     438:	r9 = *(u32 *)(r1 + 0x50)
     439:	*(u64 *)(r10 - 0x38) = r1
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     440:	r2 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
     441:	r8 = r2
     442:	r8 += 0x28
     443:	if r8 > r9 goto +0x1f <LBB2_5>
;   assert_equal(pkt->ipv6->version, 6, false);
     444:	r1 = *(u8 *)(r2 + 0x0)
     445:	w1 &= 0xf0
     446:	if w1 != 0x60 goto +0x1c <LBB2_5>
     447:	*(u64 *)(r10 - 0x30) = r2
     448:	w6 = 0x0
     449:	*(u32 *)(r10 - 0x20) = r6
     450:	r2 = r10
     451:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     452:	r1 = 0x0 ll
     454:	call 0x1
;   if (likely(value)) {
     455:	if r0 == 0x0 goto +0x2 <LBB2_4>
     456:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     457:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000e50 <LBB2_4>:
     458:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
     459:	r1 = *(u64 *)(r2 + 0x20)
     460:	*(u64 *)(r10 - 0x18) = r1
     461:	r1 = *(u64 *)(r2 + 0x18)
     462:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
     463:	*(u8 *)(r10 - 0xc) = r6
     464:	*(u32 *)(r10 - 0x10) = r6
     465:	r3 = r10
;       .needle = pkt->ipv6->daddr,
     466:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
     467:	r1 = 0x0 ll
     469:	r2 = 0x0 ll
     471:	r4 = 0x0
     472:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
     473:	r1 = *(u8 *)(r10 - 0xc)
     474:	if w1 != 0x0 goto +0xc <LBB2_6>

0000000000000ed8 <LBB2_5>:
     475:	w1 = 0x5
     476:	*(u32 *)(r10 - 0x20) = r1
     477:	r2 = r10
     478:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     479:	r1 = 0x0 ll
     481:	call 0x1
;   if (likely(value)) {
     482:	if r0 == 0x0 goto +0x2 <LBB2_48>
     483:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     484:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000f28 <LBB2_48>:
     485:	w7 = -0x1
     486:	goto +0x147 <LBB2_76>

0000000000000f38 <LBB2_6>:
     487:	w6 = 0x1
     488:	*(u32 *)(r10 - 0x4) = r6
     489:	r2 = r10
     490:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     491:	r1 = 0x0 ll
     493:	call 0x1
;   if (likely(value)) {
     494:	if r0 == 0x0 goto +0x1 <LBB2_8>
;     __sync_fetch_and_add(value, 1);
     495:	lock *(u32 *)(r0 + 0x0) += r6

0000000000000f80 <LBB2_8>:
     496:	r6 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
     497:	r1 = *(u8 *)(r6 + 0x7)
     498:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
     499:	r2 = *(u32 *)(r10 - 0x10)
     500:	if w2 <= w1 goto +0x7a <LBB2_14>
     501:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
     502:	r2 += -0x24
     503:	r1 = 0x0 ll
     505:	call 0x1
;     if (exceed_addr != NULL) {
     506:	if r0 == 0x0 goto +0x74 <LBB2_14>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
     507:	w9 -= w6
     508:	w6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
     509:	w6 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
     510:	if w6 s< 0x1 goto +0x4 <LBB2_13>
     511:	w9 &= 0x3
     512:	if w9 == 0x0 goto +0x2 <LBB2_13>
;     tail_adj = -(new_ip_pkt_len % 4);
     513:	w9 = -w9
     514:	w6 = w9

0000000000001018 <LBB2_13>:
     515:	r1 = *(u64 *)(r10 - 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     516:	r2 = *(u64 *)(r1 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     517:	*(u64 *)(r10 - 0x50) = r2
     518:	r1 = *(u64 *)(r1 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     519:	*(u64 *)(r10 - 0x48) = r1
     520:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     521:	*(u64 *)(r10 - 0x40) = r1
     522:	r1 = *(u64 *)(r0 + 0x0)
     523:	*(u64 *)(r10 - 0x30) = r1
     524:	w1 = 0x6
     525:	*(u32 *)(r10 - 0x20) = r1
     526:	r8 = *(u64 *)(r10 - 0x38)
;   return tail_adj < 0 ? tail_adj : 0;
     527:	if w6 s< 0x0 goto +0x1 <LBB2_50>
     528:	w6 = 0x0

0000000000001088 <LBB2_50>:
     529:	r2 = r10
     530:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     531:	r1 = 0x0 ll
     533:	call 0x1
;   if (likely(value)) {
     534:	if r0 == 0x0 goto +0x2 <LBB2_52>
     535:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     536:	lock *(u32 *)(r0 + 0x0) += r1

00000000000010c8 <LBB2_52>:
;     long rc_head_adj = bpf_skb_adjust_room(ctx,
     537:	r1 = r8
     538:	w2 = 0x30
     539:	w3 = 0x1
     540:	r4 = 0x1
     541:	call 0x32
     542:	w7 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     543:	if r0 != 0x0 goto +0x10e <LBB2_76>
;     int new_len = ctx->len + pkt.tail_adjust;
     544:	r2 = *(u32 *)(r8 + 0x0)
     545:	w2 += w6
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     546:	r1 = r8
     547:	r3 = 0x0
     548:	call 0x26
     549:	if r0 != 0x0 goto +0x108 <LBB2_76>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     550:	r9 = *(u32 *)(r8 + 0x50)
     551:	r6 = *(u32 *)(r8 + 0x4c)
;   assert_boundary(icmp6, pkt->end, false);
     552:	r1 = r6
     553:	r1 += 0x30
     554:	if r1 > r9 goto +0x103 <LBB2_76>
     555:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     556:	*(u32 *)(r6 + 0x0) = r1
     557:	w1 = 0x3
;   *icmp6                    = icmp6_new;
     558:	*(u32 *)(r6 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     559:	r1 = *(u64 *)(r10 - 0x50)
     560:	*(u64 *)(r6 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     561:	r1 = *(u64 *)(r10 - 0x48)
     562:	*(u64 *)(r6 + 0x18) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     563:	r1 = *(u64 *)(r10 - 0x40)
     564:	*(u64 *)(r6 + 0x10) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     565:	r1 = *(u64 *)(r10 - 0x30)
     566:	*(u64 *)(r6 + 0x8) = r1
     567:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     568:	*(u16 *)(r6 + 0x6) = r1
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     569:	r8 = r6
     570:	r8 += 0x28
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     571:	w1 = w9
     572:	w1 -= w8
     573:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     574:	*(u16 *)(r6 + 0x4) = r1
     575:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     576:	*(u32 *)(r6 + 0x2c) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     577:	r3 = r6
     578:	r3 += 0x8
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     579:	r1 = 0x0
     580:	w2 = 0x0
     581:	w4 = 0x20
     582:	w5 = 0x0
     583:	call 0x1c
     584:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     585:	r3 = *(u16 *)(r6 + 0x4)
     586:	w3 <<= 0x10
;   csum += addend;
     587:	w0 = w3
     588:	w0 += w1
     589:	w1 = 0x1
     590:	w2 = 0x1
;   csum += addend;
     591:	if w0 < w3 goto +0x1 <LBB2_57>
     592:	w2 = 0x0

0000000000001288 <LBB2_57>:
     593:	*(u64 *)(r10 - 0x30) = r6
;   return csum + (csum < addend);
     594:	w0 += w2
     595:	if w0 > -0x3a000001 goto +0x1 <LBB2_59>
     596:	w1 = 0x0

00000000000012a8 <LBB2_59>:
;   csum += addend;
     597:	w0 += w1
     598:	w6 = 0x400
;   return csum + (csum < addend);
     599:	w0 += 0x3a000000
     600:	goto +0x4 <LBB2_60>

00000000000012c8 <LBB2_66>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     601:	w1 &= 0xffff
     602:	w6 = w1
     603:	if w1 > 0x4 goto +0x1 <LBB2_60>
     604:	goto +0xad <LBB2_78>

00000000000012e8 <LBB2_60>:
     605:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     606:	if w6 < 0x200 goto +0x1 <LBB2_62>
     607:	w4 = 0x200

0000000000001300 <LBB2_62>:
;     if (likely(buf + j <= data_end)) {
     608:	r7 = r8
     609:	r7 += r4
     610:	if r7 > r9 goto +0x6 <LBB2_64>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     611:	r1 = 0x0
     612:	w2 = 0x0
     613:	r3 = r8
     614:	w5 = w0
     615:	call 0x1c
     616:	r8 = r7

0000000000001348 <LBB2_64>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     617:	w1 = w6
     618:	w1 += 0xfe00
     619:	if w6 > 0x200 goto -0x13 <LBB2_66>
     620:	w6 >>= 0x1
     621:	w1 = w6
     622:	goto -0x16 <LBB2_66>

0000000000001378 <LBB2_14>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     623:	r1 = *(u8 *)(r6 + 0x6)
     624:	if w1 != 0x3a goto -0x96 <LBB2_5>
     625:	w1 = 0x2
     626:	*(u32 *)(r10 - 0x4) = r1
     627:	r2 = r10
     628:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     629:	r1 = 0x0 ll
     631:	call 0x1
;   if (likely(value)) {
     632:	if r0 == 0x0 goto +0x2 <LBB2_17>
     633:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     634:	lock *(u32 *)(r0 + 0x0) += r1

00000000000013d8 <LBB2_17>:
;   assert_boundary(icmp6, pkt->end, false);
     635:	r1 = r6
     636:	r1 += 0x30
     637:	if r1 > r9 goto -0xa3 <LBB2_5>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     638:	r1 = *(u8 *)(r8 + 0x0)
     639:	if w1 != 0x80 goto -0xa5 <LBB2_5>
;   assert_equal(icmp6->icmp6_code, 0, false);
     640:	r1 = *(u8 *)(r6 + 0x29)
     641:	if w1 != 0x0 goto -0xa7 <LBB2_5>
     642:	w1 = 0x3
     643:	*(u32 *)(r10 - 0x4) = r1
     644:	r2 = r10
     645:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     646:	r1 = 0x0 ll
     648:	call 0x1
;   if (likely(value)) {
     649:	if r0 == 0x0 goto +0x2 <LBB2_22>
     650:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     651:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001460 <LBB2_22>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     652:	r3 = r6
     653:	r3 += 0x8
     654:	r1 = 0x0
     655:	w2 = 0x0
     656:	w4 = 0x20
     657:	w5 = 0x0
     658:	call 0x1c
     659:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     660:	r3 = *(u16 *)(r6 + 0x4)
     661:	w3 <<= 0x10
;   csum += addend;
     662:	w0 = w3
     663:	w0 += w1
     664:	w1 = 0x1
     665:	w2 = 0x1
;   csum += addend;
     666:	if w0 < w3 goto +0x1 <LBB2_24>
     667:	w2 = 0x0

00000000000014e0 <LBB2_24>:
;   return csum + (csum < addend);
     668:	w0 += w2
     669:	if w0 > -0x3a000001 goto +0x1 <LBB2_26>
     670:	w1 = 0x0

00000000000014f8 <LBB2_26>:
;   csum += addend;
     671:	w0 += w1
     672:	w6 = 0x400
;   return csum + (csum < addend);
     673:	w0 += 0x3a000000
     674:	goto +0x4 <LBB2_27>

0000000000001518 <LBB2_33>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     675:	w1 &= 0xffff
     676:	w6 = w1
     677:	if w1 > 0x4 goto +0x1 <LBB2_27>
     678:	goto +0x12 <LBB2_77>

0000000000001538 <LBB2_27>:
     679:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     680:	if w6 < 0x200 goto +0x1 <LBB2_29>
     681:	w4 = 0x200

0000000000001550 <LBB2_29>:
;     if (likely(buf + j <= data_end)) {
     682:	r7 = r8
     683:	r7 += r4
     684:	if r7 > r9 goto +0x6 <LBB2_31>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     685:	r1 = 0x0
     686:	w2 = 0x0
     687:	r3 = r8
     688:	w5 = w0
     689:	call 0x1c
     690:	r8 = r7

0000000000001598 <LBB2_31>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     691:	w1 = w6
     692:	w1 += 0xfe00
     693:	if w6 > 0x200 goto -0x13 <LBB2_33>
     694:	w6 >>= 0x1
     695:	w1 = w6
     696:	goto -0x16 <LBB2_33>

00000000000015c8 <LBB2_77>:
;   if (likely(buf + 4 <= data_end)) {
     697:	r1 = r8
     698:	r1 += 0x4
     699:	r6 = *(u64 *)(r10 - 0x30)
     700:	if r1 > r9 goto +0x9 <LBB2_37>
;     sum = csum_add(sum, *(__be32 *)buf++);
     701:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     702:	w1 = w3
     703:	w1 += w0
     704:	w2 = 0x1
     705:	if w1 < w3 goto +0x1 <LBB2_36>
     706:	w2 = 0x0

0000000000001618 <LBB2_36>:
;   return csum + (csum < addend);
     707:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     708:	r8 += 0x1
     709:	w0 = w1

0000000000001630 <LBB2_37>:
     710:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     711:	r2 = r8
     712:	r2 += 0x2
     713:	if r2 > r9 goto +0x2 <LBB2_39>
;     addend = *(__be16 *)buf++;
     714:	r1 = *(u16 *)(r8 + 0x0)
     715:	r8 += 0x1

0000000000001660 <LBB2_39>:
;   if (likely(buf + 1 <= data_end)) {
     716:	r2 = r8
     717:	r2 += 0x1
     718:	if r2 > r9 goto +0x2 <LBB2_41>
;     addend += *(__u8 *)buf++;
     719:	r2 = *(u8 *)(r8 + 0x0)
     720:	w1 += w2

0000000000001688 <LBB2_41>:
;   csum += addend;
     721:	w2 = w1
     722:	w2 += w0
     723:	w3 = 0x1
     724:	if w2 < w1 goto +0x1 <LBB2_43>
     725:	w3 = 0x0

00000000000016b0 <LBB2_43>:
;   return csum + (csum < addend);
     726:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     727:	w1 = w2
     728:	w1 >>= 0x10
     729:	w2 &= 0xffff
     730:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     731:	w1 = w2
     732:	w1 >>= 0x10
     733:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     734:	w1 &= 0xffff
     735:	if w1 != 0xffff goto -0x105 <LBB2_5>
     736:	w1 = 0x4
     737:	*(u32 *)(r10 - 0x4) = r1
     738:	r2 = r10
     739:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     740:	r1 = 0x0 ll
     742:	call 0x1
     743:	r8 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     744:	if r0 == 0x0 goto +0x2 <LBB2_46>
     745:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     746:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001758 <LBB2_46>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     747:	r1 = *(u64 *)(r6 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     748:	*(u64 *)(r10 - 0x40) = r1
     749:	r9 = *(u64 *)(r6 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     750:	r7 = *(u64 *)(r6 + 0x20)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     751:	r6 = *(u64 *)(r6 + 0x18)
     752:	w1 = 0x7
     753:	*(u32 *)(r10 - 0x20) = r1
     754:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     755:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     756:	r1 = 0x0 ll
     758:	call 0x1
;   if (likely(value)) {
     759:	if r0 == 0x0 goto +0x2 <LBB2_72>
     760:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     761:	lock *(u32 *)(r0 + 0x0) += r1

00000000000017d0 <LBB2_72>:
     762:	w1 = 0x60
     763:	r2 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     764:	*(u32 *)(r2 + 0x0) = r1
     765:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     766:	*(u16 *)(r2 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     767:	r1 = *(u64 *)(r10 - 0x40)
     768:	*(u64 *)(r2 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     769:	*(u64 *)(r2 + 0x18) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     770:	*(u64 *)(r2 + 0x10) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     771:	*(u64 *)(r2 + 0x8) = r6
     772:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     773:	*(u16 *)(r2 + 0x6) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     774:	r1 = *(u16 *)(r2 + 0x2a)
     775:	w1 += -0x1
     776:	*(u16 *)(r2 + 0x2a) = r1
     777:	goto +0x16 <LBB2_73>

0000000000001850 <LBB2_78>:
;   if (likely(buf + 4 <= data_end)) {
     778:	r1 = r8
     779:	r1 += 0x4
     780:	r4 = *(u64 *)(r10 - 0x30)
     781:	if r1 > r9 goto +0x8 <LBB2_70>
;     sum = csum_add(sum, *(__be32 *)buf++);
     782:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     783:	w1 = w3
     784:	w1 += w0
     785:	w2 = 0x1
     786:	if w1 < w3 goto +0x1 <LBB2_69>
     787:	w2 = 0x0

00000000000018a0 <LBB2_69>:
;   return csum + (csum < addend);
     788:	w1 += w2
     789:	w0 = w1

00000000000018b0 <LBB2_70>:
;   sum = (sum & 0xffff) + (sum >> 16);
     790:	w1 = w0
     791:	w1 >>= 0x10
     792:	w0 &= 0xffff
     793:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     794:	w1 = w0
     795:	w1 >>= 0x10
     796:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     797:	w1 ^= -0x1
     798:	*(u16 *)(r4 + 0x2a) = r1
     799:	r8 = *(u64 *)(r10 - 0x38)

0000000000001900 <LBB2_73>:
     800:	w1 = 0x8
     801:	*(u32 *)(r10 - 0x20) = r1
     802:	r2 = r10
     803:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     804:	r1 = 0x0 ll
     806:	call 0x1
;   if (likely(value)) {
     807:	if r0 == 0x0 goto +0x2 <LBB2_75>
     808:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     809:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001950 <LBB2_75>:
;   return bpf_redirect(ctx->ifindex, 0);
     810:	r1 = *(u32 *)(r8 + 0x28)
     811:	r2 = 0x0
     812:	call 0x17
     813:	r7 = r0

0000000000001970 <LBB2_76>:
;   return exceed2go_tc(ctx, BASE_LAYER_L3);
     814:	w0 = w7
     815:	exit
