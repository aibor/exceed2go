
exceed2go_bpfel.o:	file format elf64-bpf

Disassembly of section .text:

0000000000000000 <target_search_cb>:
;                  struct target_search_cb_ctx *cb_ctx) {
       0:	r0 = 0x0
;   if (*key == 0) {
       1:	r1 = *(u32 *)(r2 + 0x0)
       2:	if r1 == 0x0 goto +0xe <LBB3_6>
       3:	r0 = 0x1
;   if (!value || !((const __u32 *)(value))[0])
       4:	if r3 == 0x0 goto +0xc <LBB3_6>
       5:	r2 = *(u32 *)(r3 + 0x0)
       6:	if r2 == 0x0 goto +0xa <LBB3_6>
;   return ((a->in6_u.u6_addr64[0] == b->in6_u.u6_addr64[0]) &&
       7:	r2 = *(u64 *)(r3 + 0x0)
       8:	r5 = *(u64 *)(r4 + 0x0)
       9:	r0 = 0x0
      10:	if r5 != r2 goto +0x6 <LBB3_6>
;           (a->in6_u.u6_addr64[1] == b->in6_u.u6_addr64[1]));
      11:	r2 = *(u64 *)(r3 + 0x8)
      12:	r3 = *(u64 *)(r4 + 0x8)
;   if (in6_addr_equal(&cb_ctx->needle, value)) {
      13:	if r3 != r2 goto +0x3 <LBB3_6>
;     cb_ctx->key   = *key;
      14:	*(u32 *)(r4 + 0x10) = r1
      15:	r0 = 0x1
;     cb_ctx->found = true;
      16:	*(u8 *)(r4 + 0x14) = r0

0000000000000088 <LBB3_6>:
; }
      17:	exit

Disassembly of section xdp:

0000000000000000 <exceed2go_xdp_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r2 = *(u32 *)(r1 + 0x0)
       1:	r9 = *(u32 *)(r1 + 0x4)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       2:	r8 = r2
       3:	r8 += 0x36
       4:	if r8 > r9 goto +0x24 <LBB0_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       5:	r3 = *(u16 *)(r2 + 0xc)
       6:	if r3 != 0xdd86 goto +0x22 <LBB0_6>
       7:	r6 = r2
       8:	r6 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
       9:	r3 = *(u8 *)(r6 + 0x0)
      10:	r3 &= 0xf0
      11:	if r3 != 0x60 goto +0x1d <LBB0_6>
      12:	*(u64 *)(r10 - 0x38) = r1
      13:	*(u64 *)(r10 - 0x30) = r2
      14:	r7 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r7
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB0_5>
      22:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB0_5>:
      24:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
      25:	r1 = *(u64 *)(r2 + 0x2e)
      26:	*(u64 *)(r10 - 0x18) = r1
      27:	r1 = *(u64 *)(r2 + 0x26)
      28:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      29:	*(u8 *)(r10 - 0xc) = r7
      30:	*(u32 *)(r10 - 0x10) = r7
      31:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      32:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      33:	r1 = 0x0 ll
      35:	r2 = 0x0 ll
      37:	r4 = 0x0
      38:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      39:	r1 = *(u8 *)(r10 - 0xc)
      40:	if r1 != 0x0 goto +0xc <LBB0_7>

0000000000000148 <LBB0_6>:
      41:	r1 = 0x5
      42:	*(u32 *)(r10 - 0x20) = r1
      43:	r2 = r10
      44:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      45:	r1 = 0x0 ll
      47:	call 0x1
;   if (likely(value)) {
      48:	if r0 == 0x0 goto +0x2 <LBB0_49>
      49:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
      50:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000198 <LBB0_49>:
      51:	r8 = 0x2
      52:	goto +0x192 <LBB0_77>

00000000000001a8 <LBB0_7>:
      53:	*(u64 *)(r10 - 0x40) = r6
      54:	r6 = 0x1
      55:	*(u32 *)(r10 - 0x4) = r6
      56:	r2 = r10
      57:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      58:	r1 = 0x0 ll
      60:	call 0x1
;   if (likely(value)) {
      61:	if r0 == 0x0 goto +0x1 <LBB0_9>
;     __sync_fetch_and_add(value, 1);
      62:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001f8 <LBB0_9>:
      63:	r7 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
      64:	r1 = *(u8 *)(r7 + 0x15)
      65:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      66:	r2 = *(u32 *)(r10 - 0x10)
      67:	if r1 >= r2 goto +0x9b <LBB0_15>
      68:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      69:	r2 += -0x24
      70:	r1 = 0x0 ll
      72:	call 0x1
;     if (exceed_addr != NULL) {
      73:	if r0 == 0x0 goto +0x95 <LBB0_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      74:	r1 = *(u64 *)(r10 - 0x40)
      75:	r9 -= r1
      76:	r6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      77:	r6 -= r9
      78:	r6 <<= 0x20
      79:	r6 s>>= 0x20
      80:	r1 = 0x1
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      81:	if r1 s> r6 goto +0x4 <LBB0_14>
      82:	r9 &= 0x3
      83:	if r9 == 0x0 goto +0x2 <LBB0_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      84:	r9 = -r9
      85:	r6 = r9

00000000000002b0 <LBB0_14>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      86:	r1 = *(u64 *)(r7 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      87:	*(u64 *)(r10 - 0x40) = r1
      88:	r1 = *(u64 *)(r7 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      89:	*(u64 *)(r10 - 0x50) = r1
      90:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      91:	*(u64 *)(r10 - 0x48) = r1
      92:	r1 = *(u64 *)(r0 + 0x0)
      93:	*(u64 *)(r10 - 0x30) = r1
      94:	r1 = 0x6
      95:	*(u32 *)(r10 - 0x20) = r1
      96:	r1 = 0x0
;   return tail_adj < 0 ? tail_adj : 0;
      97:	if r1 s> r6 goto +0x1 <LBB0_51>
      98:	r6 = 0x0

0000000000000318 <LBB0_51>:
      99:	r2 = r10
     100:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     101:	r1 = 0x0 ll
     103:	call 0x1
     104:	r7 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     105:	if r0 == 0x0 goto +0x2 <LBB0_53>
     106:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     107:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000360 <LBB0_53>:
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
     108:	r1 = r7
     109:	r2 = 0xffffffd0 ll
     111:	call 0x2c
     112:	r8 = 0x0
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
     113:	if r0 != 0x0 goto +0x155 <LBB0_77>
;     assert_equal(bpf_xdp_adjust_tail(ctx, tail_adj), 0, XDP_ABORTED);
     114:	r1 = r7
     115:	r2 = r6
     116:	call 0x41
     117:	if r0 != 0x0 goto +0x151 <LBB0_77>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     118:	r9 = *(u32 *)(r7 + 0x4)
     119:	r4 = *(u32 *)(r7 + 0x0)
;       assert_boundary(old_eth, pkt.end, XDP_ABORTED);
     120:	r1 = r4
     121:	r1 += 0x3e
     122:	if r1 > r9 goto +0x14c <LBB0_77>
     123:	r1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     124:	*(u32 *)(r4 + 0xe) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     125:	r1 = *(u64 *)(r10 - 0x50)
     126:	*(u64 *)(r4 + 0x26) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     127:	r1 = *(u64 *)(r10 - 0x48)
     128:	*(u64 *)(r4 + 0x1e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     129:	r1 = *(u64 *)(r10 - 0x30)
     130:	*(u64 *)(r4 + 0x16) = r1
     131:	r1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     132:	*(u16 *)(r4 + 0x14) = r1
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     133:	r1 = *(u16 *)(r4 + 0x36)
     134:	r2 = *(u16 *)(r4 + 0x38)
     135:	r3 = 0x3
;   *icmp6                    = icmp6_new;
     136:	*(u32 *)(r4 + 0x36) = r3
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     137:	r3 = *(u16 *)(r4 + 0x3a)
     138:	*(u16 *)(r4 + 0x4) = r3
     139:	*(u16 *)(r4 + 0x2) = r2
     140:	*(u16 *)(r4 + 0x0) = r1
     141:	r1 = *(u16 *)(r4 + 0x3c)
;   new->proto                  = old->proto;
     142:	*(u16 *)(r4 + 0xc) = r1
;   __u32 daddr_first           = *(__u32 *)old;
     143:	r1 = *(u32 *)(r4 + 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     144:	r2 = *(u64 *)(r10 - 0x40)
     145:	*(u64 *)(r4 + 0x2e) = r2
;   *(__u32 *)&new->saddr       = daddr_first;
     146:	r2 = r1
     147:	r2 >>= 0x10
     148:	*(u16 *)(r4 + 0x8) = r2
     149:	*(u16 *)(r4 + 0x6) = r1
;   __u16 daddr_last            = *(__u16 *)old + 2;
     150:	r1 += 0x2
;   *((__u16 *)&new->saddr + 2) = daddr_last;
     151:	*(u16 *)(r4 + 0xa) = r1
     152:	r6 = r4
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     153:	r7 = r6
     154:	r7 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     155:	r1 = r9
     156:	r1 -= r7
     157:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     158:	*(u16 *)(r6 + 0x12) = r1
     159:	r1 = 0x0
;   *icmp6                    = icmp6_new;
     160:	*(u32 *)(r6 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     161:	r3 = r6
     162:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     163:	r2 = 0x0
     164:	r4 = 0x20
     165:	r5 = 0x0
     166:	call 0x1c
     167:	r1 = r0
     168:	r1 <<= 0x20
     169:	r1 >>= 0x20
     170:	*(u64 *)(r10 - 0x30) = r6
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     171:	r0 = *(u16 *)(r6 + 0x12)
     172:	r0 <<= 0x10
     173:	r0 <<= 0x20
     174:	r0 >>= 0x20
;   csum += addend;
     175:	r0 += r1
     176:	r3 = r0
     177:	r3 <<= 0x20
     178:	r3 >>= 0x20
     179:	r1 = 0x1
     180:	r2 = 0x1
     181:	if r3 != r0 goto +0x1 <LBB0_58>
     182:	r2 = 0x0

00000000000005b8 <LBB0_58>:
;   return csum + (csum < addend);
     183:	r0 += r2
     184:	r2 = r0
     185:	r2 <<= 0x20
     186:	r2 >>= 0x20
     187:	r3 = 0xc5ffffff ll
     189:	if r2 > r3 goto +0x1 <LBB0_60>
     190:	r1 = 0x0

00000000000005f8 <LBB0_60>:
;   csum += addend;
     191:	r0 += r1
     192:	r8 = 0x400
;   return csum + (csum < addend);
     193:	r0 += 0x3a000000
     194:	goto +0x4 <LBB0_61>

0000000000000618 <LBB0_67>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     195:	r1 &= 0xffff
     196:	r8 = r1
     197:	if r1 > 0x4 goto +0x1 <LBB0_61>
     198:	goto +0xd9 <LBB0_79>

0000000000000638 <LBB0_61>:
;     __u16 j = (i >= 512) ? 512 : i;
     199:	r4 = r8
     200:	r4 <<= 0x20
     201:	r4 >>= 0x20
     202:	r1 = 0x200
     203:	if r1 > r4 goto +0x1 <LBB0_63>
     204:	r4 = 0x200

0000000000000668 <LBB0_63>:
;     if (likely(buf + j <= data_end)) {
     205:	r6 = r7
     206:	r6 += r4
     207:	if r6 > r9 goto +0x6 <LBB0_65>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     208:	r1 = 0x0
     209:	r2 = 0x0
     210:	r3 = r7
     211:	r5 = r0
     212:	call 0x1c
     213:	r7 = r6

00000000000006b0 <LBB0_65>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     214:	r1 = r8
     215:	r1 += 0xfe00
     216:	r2 = r8
     217:	r2 <<= 0x20
     218:	r2 >>= 0x20
     219:	if r2 > 0x200 goto -0x19 <LBB0_67>
     220:	r8 >>= 0x1
     221:	r1 = r8
     222:	goto -0x1c <LBB0_67>

00000000000006f8 <LBB0_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     223:	r1 = *(u8 *)(r7 + 0x14)
     224:	if r1 != 0x3a goto -0xb8 <LBB0_6>
     225:	r1 = 0x2
     226:	*(u32 *)(r10 - 0x4) = r1
     227:	r2 = r10
     228:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     229:	r1 = 0x0 ll
     231:	call 0x1
;   if (likely(value)) {
     232:	if r0 == 0x0 goto +0x2 <LBB0_18>
     233:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     234:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000758 <LBB0_18>:
;   assert_boundary(icmp6, pkt->end, false);
     235:	r1 = r7
     236:	r1 += 0x3e
     237:	if r1 > r9 goto -0xc5 <LBB0_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     238:	r1 = *(u8 *)(r8 + 0x0)
     239:	if r1 != 0x80 goto -0xc7 <LBB0_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     240:	r1 = *(u8 *)(r7 + 0x37)
     241:	if r1 != 0x0 goto -0xc9 <LBB0_6>
     242:	r1 = 0x3
     243:	*(u32 *)(r10 - 0x4) = r1
     244:	r2 = r10
     245:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     246:	r1 = 0x0 ll
     248:	call 0x1
;   if (likely(value)) {
     249:	if r0 == 0x0 goto +0x2 <LBB0_23>
     250:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     251:	lock *(u32 *)(r0 + 0x0) += r1

00000000000007e0 <LBB0_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     252:	r3 = r7
     253:	r3 += 0x16
     254:	r1 = 0x0
     255:	r2 = 0x0
     256:	r4 = 0x20
     257:	r5 = 0x0
     258:	call 0x1c
     259:	r1 = r0
     260:	r1 <<= 0x20
     261:	r1 >>= 0x20
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     262:	r0 = *(u16 *)(r7 + 0x12)
     263:	r0 <<= 0x10
     264:	r0 <<= 0x20
     265:	r0 >>= 0x20
;   csum += addend;
     266:	r0 += r1
     267:	r3 = r0
     268:	r3 <<= 0x20
     269:	r3 >>= 0x20
     270:	r1 = 0x1
     271:	r2 = 0x1
     272:	if r3 != r0 goto +0x1 <LBB0_25>
     273:	r2 = 0x0

0000000000000890 <LBB0_25>:
;   return csum + (csum < addend);
     274:	r0 += r2
     275:	r2 = r0
     276:	r2 <<= 0x20
     277:	r2 >>= 0x20
     278:	r3 = 0xc5ffffff ll
     280:	if r2 > r3 goto +0x1 <LBB0_27>
     281:	r1 = 0x0

00000000000008d0 <LBB0_27>:
;   csum += addend;
     282:	r0 += r1
     283:	r7 = 0x400
;   return csum + (csum < addend);
     284:	r0 += 0x3a000000
     285:	goto +0x4 <LBB0_28>

00000000000008f0 <LBB0_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     286:	r1 &= 0xffff
     287:	r7 = r1
     288:	if r1 > 0x4 goto +0x1 <LBB0_28>
     289:	goto +0x18 <LBB0_78>

0000000000000910 <LBB0_28>:
;     __u16 j = (i >= 512) ? 512 : i;
     290:	r4 = r7
     291:	r4 <<= 0x20
     292:	r4 >>= 0x20
     293:	r1 = 0x200
     294:	if r1 > r4 goto +0x1 <LBB0_30>
     295:	r4 = 0x200

0000000000000940 <LBB0_30>:
;     if (likely(buf + j <= data_end)) {
     296:	r6 = r8
     297:	r6 += r4
     298:	if r6 > r9 goto +0x6 <LBB0_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     299:	r1 = 0x0
     300:	r2 = 0x0
     301:	r3 = r8
     302:	r5 = r0
     303:	call 0x1c
     304:	r8 = r6

0000000000000988 <LBB0_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     305:	r1 = r7
     306:	r1 += 0xfe00
     307:	r2 = r7
     308:	r2 <<= 0x20
     309:	r2 >>= 0x20
     310:	if r2 > 0x200 goto -0x19 <LBB0_34>
     311:	r7 >>= 0x1
     312:	r1 = r7
     313:	goto -0x1c <LBB0_34>

00000000000009d0 <LBB0_78>:
;   if (likely(buf + 4 <= data_end)) {
     314:	r1 = r8
     315:	r1 += 0x4
     316:	r6 = *(u64 *)(r10 - 0x30)
     317:	if r1 > r9 goto +0xd <LBB0_38>
;   csum += addend;
     318:	r0 <<= 0x20
     319:	r0 >>= 0x20
;     sum = csum_add(sum, *(__be32 *)buf++);
     320:	r1 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     321:	r1 += r0
     322:	r3 = r1
     323:	r3 <<= 0x20
     324:	r3 >>= 0x20
     325:	r2 = 0x1
     326:	if r3 != r1 goto +0x1 <LBB0_37>
     327:	r2 = 0x0

0000000000000a40 <LBB0_37>:
;   return csum + (csum < addend);
     328:	r1 += r2
;     sum = csum_add(sum, *(__be32 *)buf++);
     329:	r8 += 0x1
     330:	r0 = r1

0000000000000a58 <LBB0_38>:
     331:	r1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     332:	r2 = r8
     333:	r2 += 0x2
     334:	if r2 > r9 goto +0x2 <LBB0_40>
;     addend = *(__be16 *)buf++;
     335:	r1 = *(u16 *)(r8 + 0x0)
     336:	r8 += 0x1

0000000000000a88 <LBB0_40>:
;   if (likely(buf + 1 <= data_end)) {
     337:	r2 = r8
     338:	r2 += 0x1
     339:	if r2 > r9 goto +0x2 <LBB0_42>
;     addend += *(__u8 *)buf++;
     340:	r2 = *(u8 *)(r8 + 0x0)
     341:	r1 += r2

0000000000000ab0 <LBB0_42>:
;   csum += addend;
     342:	r0 <<= 0x20
     343:	r0 >>= 0x20
     344:	r1 += r0
     345:	r3 = r1
     346:	r3 <<= 0x20
     347:	r3 >>= 0x20
     348:	r2 = 0x1
     349:	if r3 != r1 goto +0x1 <LBB0_44>
     350:	r2 = 0x0

0000000000000af8 <LBB0_44>:
;   return csum + (csum < addend);
     351:	r1 += r2
     352:	r2 = 0xffff0000 ll
;   return csum + (csum < addend);
     354:	r3 = r1
     355:	r3 &= r2
;   sum = (sum & 0xffff) + (sum >> 16);
     356:	r1 &= 0xffff
     357:	r3 >>= 0x10
     358:	r1 += r3
;   sum = (sum & 0xffff) + (sum >> 16);
     359:	r2 = r1
     360:	r2 >>= 0x10
     361:	r2 += r1
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     362:	r2 &= 0xffff
     363:	if r2 != 0xffff goto -0x143 <LBB0_6>
     364:	r1 = 0x4
     365:	*(u32 *)(r10 - 0x4) = r1
     366:	r2 = r10
     367:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     368:	r1 = 0x0 ll
     370:	call 0x1
;   if (likely(value)) {
     371:	if r0 == 0x0 goto +0x2 <LBB0_47>
     372:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     373:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000bb0 <LBB0_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     374:	r8 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     375:	r9 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     376:	r7 = *(u64 *)(r6 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     377:	r6 = *(u64 *)(r6 + 0x26)
     378:	r1 = 0x7
     379:	*(u32 *)(r10 - 0x20) = r1
     380:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     381:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     382:	r1 = 0x0 ll
     384:	call 0x1
;   if (likely(value)) {
     385:	if r0 == 0x0 goto +0x2 <LBB0_73>
     386:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     387:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000c20 <LBB0_73>:
     388:	r1 = 0x60
     389:	r3 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     390:	*(u32 *)(r3 + 0xe) = r1
     391:	r1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     392:	*(u16 *)(r3 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     393:	*(u64 *)(r3 + 0x2e) = r8
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     394:	*(u64 *)(r3 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     395:	*(u64 *)(r3 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     396:	*(u64 *)(r3 + 0x16) = r6
     397:	r1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     398:	*(u16 *)(r3 + 0x14) = r1
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     399:	r1 = *(u16 *)(r3 + 0xa)
     400:	*(u16 *)(r3 + 0x4) = r1
;   __u32 daddr_first           = *(__u32 *)old;
     401:	r1 = *(u32 *)(r3 + 0x0)
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     402:	r2 = *(u16 *)(r3 + 0x6)
     403:	*(u16 *)(r3 + 0x0) = r2
     404:	r2 = *(u16 *)(r3 + 0x8)
     405:	*(u16 *)(r3 + 0x2) = r2
;   __u16 daddr_last            = *(__u16 *)old + 2;
     406:	r2 = r1
     407:	r2 += 0x2
;   *((__u16 *)&new->saddr + 2) = daddr_last;
     408:	*(u16 *)(r3 + 0xa) = r2
;   *(__u32 *)&new->saddr       = daddr_first;
     409:	*(u16 *)(r3 + 0x6) = r1
     410:	r1 >>= 0x10
     411:	*(u16 *)(r3 + 0x8) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     412:	r1 = *(u16 *)(r3 + 0x38)
     413:	r1 += -0x1
     414:	*(u16 *)(r3 + 0x38) = r1
     415:	goto +0x1c <LBB0_74>

0000000000000d00 <LBB0_79>:
;   if (likely(buf + 4 <= data_end)) {
     416:	r1 = r7
     417:	r1 += 0x4
     418:	if r1 > r9 goto +0xc <LBB0_71>
;     sum = csum_add(sum, *(__be32 *)buf++);
     419:	r1 = *(u32 *)(r7 + 0x0)
;   csum += addend;
     420:	r0 <<= 0x20
     421:	r0 >>= 0x20
     422:	r1 += r0
     423:	r3 = r1
     424:	r3 <<= 0x20
     425:	r3 >>= 0x20
     426:	r2 = 0x1
     427:	if r3 != r1 goto +0x1 <LBB0_70>
     428:	r2 = 0x0

0000000000000d68 <LBB0_70>:
;   return csum + (csum < addend);
     429:	r1 += r2
     430:	r0 = r1

0000000000000d78 <LBB0_71>:
     431:	r1 = 0xffff0000 ll
;   sum = (sum & 0xffff) + (sum >> 16);
     433:	r2 = r0
     434:	r2 &= r1
     435:	r2 >>= 0x10
     436:	r0 &= 0xffff
     437:	r0 += r2
;   sum = (sum & 0xffff) + (sum >> 16);
     438:	r1 = r0
     439:	r1 >>= 0x10
     440:	r1 += r0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     441:	r1 ^= -0x1
     442:	r2 = *(u64 *)(r10 - 0x30)
     443:	*(u16 *)(r2 + 0x38) = r1

0000000000000de0 <LBB0_74>:
     444:	r1 = 0x8
     445:	*(u32 *)(r10 - 0x20) = r1
     446:	r2 = r10
     447:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     448:	r1 = 0x0 ll
     450:	call 0x1
;   if (likely(value)) {
     451:	if r0 == 0x0 goto +0x2 <LBB0_76>
     452:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     453:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000e30 <LBB0_76>:
     454:	r8 = 0x3

0000000000000e38 <LBB0_77>:
;   return exceed2go_xdp(ctx, BASE_LAYER_L2);
     455:	r0 = r8
     456:	exit

Disassembly of section tc:

0000000000000000 <exceed2go_tc_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r9 = *(u32 *)(r1 + 0x50)
       1:	*(u64 *)(r10 - 0x38) = r1
       2:	r2 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       3:	r8 = r2
       4:	r8 += 0x36
       5:	if r8 > r9 goto +0x23 <LBB1_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       6:	r1 = *(u16 *)(r2 + 0xc)
       7:	if r1 != 0xdd86 goto +0x21 <LBB1_6>
       8:	r7 = r2
       9:	r7 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
      10:	r1 = *(u8 *)(r7 + 0x0)
      11:	r1 &= 0xf0
      12:	if r1 != 0x60 goto +0x1c <LBB1_6>
      13:	*(u64 *)(r10 - 0x30) = r2
      14:	r6 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r6
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB1_5>
      22:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB1_5>:
      24:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
      25:	r1 = *(u64 *)(r2 + 0x2e)
      26:	*(u64 *)(r10 - 0x18) = r1
      27:	r1 = *(u64 *)(r2 + 0x26)
      28:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      29:	*(u8 *)(r10 - 0xc) = r6
      30:	*(u32 *)(r10 - 0x10) = r6
      31:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      32:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      33:	r1 = 0x0 ll
      35:	r2 = 0x0 ll
      37:	r4 = 0x0
      38:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      39:	r1 = *(u8 *)(r10 - 0xc)
      40:	if r1 != 0x0 goto +0xd <LBB1_7>

0000000000000148 <LBB1_6>:
      41:	r1 = 0x5
      42:	*(u32 *)(r10 - 0x20) = r1
      43:	r2 = r10
      44:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      45:	r1 = 0x0 ll
      47:	call 0x1
;   if (likely(value)) {
      48:	if r0 == 0x0 goto +0x2 <LBB1_49>
      49:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
      50:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000198 <LBB1_49>:
      51:	r3 = 0xffffffff ll
      53:	goto +0x1b3 <LBB1_78>

00000000000001b0 <LBB1_7>:
      54:	r6 = 0x1
      55:	*(u32 *)(r10 - 0x4) = r6
      56:	r2 = r10
      57:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      58:	r1 = 0x0 ll
      60:	call 0x1
;   if (likely(value)) {
      61:	if r0 == 0x0 goto +0x1 <LBB1_9>
;     __sync_fetch_and_add(value, 1);
      62:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001f8 <LBB1_9>:
      63:	r6 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
      64:	r1 = *(u8 *)(r6 + 0x15)
      65:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      66:	r2 = *(u32 *)(r10 - 0x10)
      67:	if r1 >= r2 goto +0xb9 <LBB1_15>
      68:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      69:	r2 += -0x24
      70:	r1 = 0x0 ll
      72:	call 0x1
;     if (exceed_addr != NULL) {
      73:	if r0 == 0x0 goto +0xb3 <LBB1_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      74:	r9 -= r7
      75:	r6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      76:	r6 -= r9
      77:	r6 <<= 0x20
      78:	r6 s>>= 0x20
      79:	r1 = 0x1
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      80:	if r1 s> r6 goto +0x4 <LBB1_14>
      81:	r9 &= 0x3
      82:	if r9 == 0x0 goto +0x2 <LBB1_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      83:	r9 = -r9
      84:	r6 = r9

00000000000002a8 <LBB1_14>:
      85:	r1 = *(u64 *)(r10 - 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      86:	r2 = *(u64 *)(r1 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      87:	*(u64 *)(r10 - 0x78) = r2
      88:	r1 = *(u64 *)(r1 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      89:	*(u64 *)(r10 - 0x70) = r1
      90:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      91:	*(u64 *)(r10 - 0x68) = r1
      92:	r1 = *(u64 *)(r0 + 0x0)
      93:	*(u64 *)(r10 - 0x60) = r1
      94:	r1 = 0x6
      95:	*(u32 *)(r10 - 0x20) = r1
      96:	r1 = 0x0
;   return tail_adj < 0 ? tail_adj : 0;
      97:	if r1 s> r6 goto +0x1 <LBB1_51>
      98:	r6 = 0x0

0000000000000318 <LBB1_51>:
      99:	r2 = r10
     100:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     101:	r1 = 0x0 ll
     103:	call 0x1
;   if (likely(value)) {
     104:	if r0 == 0x0 goto +0x2 <LBB1_53>
     105:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     106:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000358 <LBB1_53>:
     107:	r1 = *(u64 *)(r10 - 0x30)
;       bpf_memcpy(&eth, pkt.eth, sizeof(struct ethhdr));
     108:	r2 = *(u16 *)(r1 + 0x8)
     109:	*(u64 *)(r10 - 0x40) = r2
     110:	r2 = *(u16 *)(r1 + 0x6)
     111:	*(u64 *)(r10 - 0x58) = r2
     112:	r2 = *(u16 *)(r1 + 0xa)
     113:	*(u64 *)(r10 - 0x50) = r2
     114:	r7 = *(u16 *)(r1 + 0xc)
     115:	r2 = *(u16 *)(r1 + 0x0)
     116:	*(u64 *)(r10 - 0x48) = r2
     117:	r8 = *(u16 *)(r1 + 0x2)
;     long rc_head_adj = bpf_skb_adjust_room(ctx,
     118:	r1 = *(u64 *)(r10 - 0x38)
     119:	r2 = 0x30
     120:	r3 = 0x1
     121:	r4 = 0x1
     122:	call 0x32
     123:	r3 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     124:	if r0 != 0x0 goto +0x16c <LBB1_78>
     125:	r1 = *(u64 *)(r10 - 0x38)
;     int new_len = ctx->len + pkt.tail_adjust;
     126:	r2 = *(u32 *)(r1 + 0x0)
     127:	r2 += r6
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     128:	r3 = 0x0
     129:	call 0x26
     130:	r3 = 0x2
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     131:	if r0 != 0x0 goto +0x165 <LBB1_78>
     132:	r1 = *(u64 *)(r10 - 0x38)
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     133:	r9 = *(u32 *)(r1 + 0x50)
     134:	r2 = *(u32 *)(r1 + 0x4c)
;       assert_boundary(pkt.eth, pkt.end, TC_ACT_SHOT);
     135:	r1 = r2
     136:	r1 += 0xe
     137:	if r1 > r9 goto +0x15f <LBB1_78>
     138:	r1 = *(u64 *)(r10 - 0x40)
     139:	r1 <<= 0x10
     140:	r4 = *(u64 *)(r10 - 0x58)
     141:	r1 |= r4
     142:	r4 = *(u64 *)(r10 - 0x50)
     143:	r4 <<= 0x20
     144:	r7 <<= 0x30
     145:	r7 |= r4
     146:	r7 |= r1
     147:	r8 <<= 0x10
     148:	r1 = *(u64 *)(r10 - 0x48)
     149:	r8 |= r1
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     150:	r1 = r7
     151:	r1 >>= 0x20
     152:	*(u16 *)(r2 + 0x4) = r1
     153:	r1 = r7
     154:	r1 >>= 0x10
     155:	*(u16 *)(r2 + 0x2) = r1
;   *(__u32 *)&new->saddr       = daddr_first;
     156:	r1 = r8
     157:	r1 >>= 0x10
     158:	*(u16 *)(r2 + 0x8) = r1
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     159:	*(u16 *)(r2 + 0x0) = r7
     160:	r7 >>= 0x30
;   new->proto                  = old->proto;
     161:	*(u16 *)(r2 + 0xc) = r7
;   *(__u32 *)&new->saddr       = daddr_first;
     162:	*(u16 *)(r2 + 0x6) = r8
;   __u16 daddr_last            = *(__u16 *)old + 2;
     163:	r8 += 0x2
;   *((__u16 *)&new->saddr + 2) = daddr_last;
     164:	*(u16 *)(r2 + 0xa) = r8
;   assert_boundary(icmp6, pkt->end, false);
     165:	r1 = r2
     166:	r1 += 0x3e
     167:	if r1 > r9 goto +0x141 <LBB1_78>
     168:	r1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     169:	*(u32 *)(r2 + 0xe) = r1
     170:	r1 = 0x3
;   *icmp6                    = icmp6_new;
     171:	*(u32 *)(r2 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     172:	r1 = *(u64 *)(r10 - 0x78)
     173:	*(u64 *)(r2 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     174:	r1 = *(u64 *)(r10 - 0x70)
     175:	*(u64 *)(r2 + 0x26) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     176:	r1 = *(u64 *)(r10 - 0x68)
     177:	*(u64 *)(r2 + 0x1e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     178:	r1 = *(u64 *)(r10 - 0x60)
     179:	*(u64 *)(r2 + 0x16) = r1
     180:	r1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     181:	*(u16 *)(r2 + 0x14) = r1
     182:	r7 = r2
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     183:	r6 = r7
     184:	r6 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     185:	r1 = r9
     186:	r1 -= r6
     187:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     188:	*(u16 *)(r7 + 0x12) = r1
     189:	r1 = 0x0
;   *icmp6                    = icmp6_new;
     190:	*(u32 *)(r7 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     191:	r3 = r7
     192:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     193:	r2 = 0x0
     194:	r4 = 0x20
     195:	r5 = 0x0
     196:	call 0x1c
     197:	r1 = r0
     198:	r1 <<= 0x20
     199:	r1 >>= 0x20
     200:	*(u64 *)(r10 - 0x30) = r7
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     201:	r0 = *(u16 *)(r7 + 0x12)
     202:	r0 <<= 0x10
     203:	r0 <<= 0x20
     204:	r0 >>= 0x20
;   csum += addend;
     205:	r0 += r1
     206:	r3 = r0
     207:	r3 <<= 0x20
     208:	r3 >>= 0x20
     209:	r1 = 0x1
     210:	r2 = 0x1
     211:	if r3 != r0 goto +0x1 <LBB1_59>
     212:	r2 = 0x0

00000000000006a8 <LBB1_59>:
;   return csum + (csum < addend);
     213:	r0 += r2
     214:	r2 = r0
     215:	r2 <<= 0x20
     216:	r2 >>= 0x20
     217:	r3 = 0xc5ffffff ll
     219:	if r2 > r3 goto +0x1 <LBB1_61>
     220:	r1 = 0x0

00000000000006e8 <LBB1_61>:
;   csum += addend;
     221:	r0 += r1
     222:	r8 = 0x400
;   return csum + (csum < addend);
     223:	r0 += 0x3a000000
     224:	goto +0x4 <LBB1_62>

0000000000000708 <LBB1_68>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     225:	r1 &= 0xffff
     226:	r8 = r1
     227:	if r1 > 0x4 goto +0x1 <LBB1_62>
     228:	goto +0xd9 <LBB1_80>

0000000000000728 <LBB1_62>:
;     __u16 j = (i >= 512) ? 512 : i;
     229:	r4 = r8
     230:	r4 <<= 0x20
     231:	r4 >>= 0x20
     232:	r1 = 0x200
     233:	if r1 > r4 goto +0x1 <LBB1_64>
     234:	r4 = 0x200

0000000000000758 <LBB1_64>:
;     if (likely(buf + j <= data_end)) {
     235:	r7 = r6
     236:	r7 += r4
     237:	if r7 > r9 goto +0x6 <LBB1_66>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     238:	r1 = 0x0
     239:	r2 = 0x0
     240:	r3 = r6
     241:	r5 = r0
     242:	call 0x1c
     243:	r6 = r7

00000000000007a0 <LBB1_66>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     244:	r1 = r8
     245:	r1 += 0xfe00
     246:	r2 = r8
     247:	r2 <<= 0x20
     248:	r2 >>= 0x20
     249:	if r2 > 0x200 goto -0x19 <LBB1_68>
     250:	r8 >>= 0x1
     251:	r1 = r8
     252:	goto -0x1c <LBB1_68>

00000000000007e8 <LBB1_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     253:	r1 = *(u8 *)(r6 + 0x14)
     254:	if r1 != 0x3a goto -0xd6 <LBB1_6>
     255:	r1 = 0x2
     256:	*(u32 *)(r10 - 0x4) = r1
     257:	r2 = r10
     258:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     259:	r1 = 0x0 ll
     261:	call 0x1
;   if (likely(value)) {
     262:	if r0 == 0x0 goto +0x2 <LBB1_18>
     263:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     264:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000848 <LBB1_18>:
;   assert_boundary(icmp6, pkt->end, false);
     265:	r1 = r6
     266:	r1 += 0x3e
     267:	if r1 > r9 goto -0xe3 <LBB1_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     268:	r1 = *(u8 *)(r8 + 0x0)
     269:	if r1 != 0x80 goto -0xe5 <LBB1_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     270:	r1 = *(u8 *)(r6 + 0x37)
     271:	if r1 != 0x0 goto -0xe7 <LBB1_6>
     272:	r1 = 0x3
     273:	*(u32 *)(r10 - 0x4) = r1
     274:	r2 = r10
     275:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     276:	r1 = 0x0 ll
     278:	call 0x1
;   if (likely(value)) {
     279:	if r0 == 0x0 goto +0x2 <LBB1_23>
     280:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     281:	lock *(u32 *)(r0 + 0x0) += r1

00000000000008d0 <LBB1_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     282:	r3 = r6
     283:	r3 += 0x16
     284:	r1 = 0x0
     285:	r2 = 0x0
     286:	r4 = 0x20
     287:	r5 = 0x0
     288:	call 0x1c
     289:	r1 = r0
     290:	r1 <<= 0x20
     291:	r1 >>= 0x20
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     292:	r0 = *(u16 *)(r6 + 0x12)
     293:	r0 <<= 0x10
     294:	r0 <<= 0x20
     295:	r0 >>= 0x20
;   csum += addend;
     296:	r0 += r1
     297:	r3 = r0
     298:	r3 <<= 0x20
     299:	r3 >>= 0x20
     300:	r1 = 0x1
     301:	r2 = 0x1
     302:	if r3 != r0 goto +0x1 <LBB1_25>
     303:	r2 = 0x0

0000000000000980 <LBB1_25>:
;   return csum + (csum < addend);
     304:	r0 += r2
     305:	r2 = r0
     306:	r2 <<= 0x20
     307:	r2 >>= 0x20
     308:	r3 = 0xc5ffffff ll
     310:	if r2 > r3 goto +0x1 <LBB1_27>
     311:	r1 = 0x0

00000000000009c0 <LBB1_27>:
;   csum += addend;
     312:	r0 += r1
     313:	r6 = 0x400
;   return csum + (csum < addend);
     314:	r0 += 0x3a000000
     315:	goto +0x4 <LBB1_28>

00000000000009e0 <LBB1_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     316:	r1 &= 0xffff
     317:	r6 = r1
     318:	if r1 > 0x4 goto +0x1 <LBB1_28>
     319:	goto +0x18 <LBB1_79>

0000000000000a00 <LBB1_28>:
;     __u16 j = (i >= 512) ? 512 : i;
     320:	r4 = r6
     321:	r4 <<= 0x20
     322:	r4 >>= 0x20
     323:	r1 = 0x200
     324:	if r1 > r4 goto +0x1 <LBB1_30>
     325:	r4 = 0x200

0000000000000a30 <LBB1_30>:
;     if (likely(buf + j <= data_end)) {
     326:	r7 = r8
     327:	r7 += r4
     328:	if r7 > r9 goto +0x6 <LBB1_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     329:	r1 = 0x0
     330:	r2 = 0x0
     331:	r3 = r8
     332:	r5 = r0
     333:	call 0x1c
     334:	r8 = r7

0000000000000a78 <LBB1_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     335:	r1 = r6
     336:	r1 += 0xfe00
     337:	r2 = r6
     338:	r2 <<= 0x20
     339:	r2 >>= 0x20
     340:	if r2 > 0x200 goto -0x19 <LBB1_34>
     341:	r6 >>= 0x1
     342:	r1 = r6
     343:	goto -0x1c <LBB1_34>

0000000000000ac0 <LBB1_79>:
;   if (likely(buf + 4 <= data_end)) {
     344:	r1 = r8
     345:	r1 += 0x4
     346:	r6 = *(u64 *)(r10 - 0x30)
     347:	if r1 > r9 goto +0xd <LBB1_38>
;   csum += addend;
     348:	r0 <<= 0x20
     349:	r0 >>= 0x20
;     sum = csum_add(sum, *(__be32 *)buf++);
     350:	r1 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     351:	r1 += r0
     352:	r3 = r1
     353:	r3 <<= 0x20
     354:	r3 >>= 0x20
     355:	r2 = 0x1
     356:	if r3 != r1 goto +0x1 <LBB1_37>
     357:	r2 = 0x0

0000000000000b30 <LBB1_37>:
;   return csum + (csum < addend);
     358:	r1 += r2
;     sum = csum_add(sum, *(__be32 *)buf++);
     359:	r8 += 0x1
     360:	r0 = r1

0000000000000b48 <LBB1_38>:
     361:	r1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     362:	r2 = r8
     363:	r2 += 0x2
     364:	if r2 > r9 goto +0x2 <LBB1_40>
;     addend = *(__be16 *)buf++;
     365:	r1 = *(u16 *)(r8 + 0x0)
     366:	r8 += 0x1

0000000000000b78 <LBB1_40>:
;   if (likely(buf + 1 <= data_end)) {
     367:	r2 = r8
     368:	r2 += 0x1
     369:	if r2 > r9 goto +0x2 <LBB1_42>
;     addend += *(__u8 *)buf++;
     370:	r2 = *(u8 *)(r8 + 0x0)
     371:	r1 += r2

0000000000000ba0 <LBB1_42>:
;   csum += addend;
     372:	r0 <<= 0x20
     373:	r0 >>= 0x20
     374:	r1 += r0
     375:	r3 = r1
     376:	r3 <<= 0x20
     377:	r3 >>= 0x20
     378:	r2 = 0x1
     379:	if r3 != r1 goto +0x1 <LBB1_44>
     380:	r2 = 0x0

0000000000000be8 <LBB1_44>:
;   return csum + (csum < addend);
     381:	r1 += r2
     382:	r2 = 0xffff0000 ll
;   return csum + (csum < addend);
     384:	r3 = r1
     385:	r3 &= r2
;   sum = (sum & 0xffff) + (sum >> 16);
     386:	r1 &= 0xffff
     387:	r3 >>= 0x10
     388:	r1 += r3
;   sum = (sum & 0xffff) + (sum >> 16);
     389:	r2 = r1
     390:	r2 >>= 0x10
     391:	r2 += r1
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     392:	r2 &= 0xffff
     393:	if r2 != 0xffff goto -0x161 <LBB1_6>
     394:	r1 = 0x4
     395:	*(u32 *)(r10 - 0x4) = r1
     396:	r2 = r10
     397:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     398:	r1 = 0x0 ll
     400:	call 0x1
;   if (likely(value)) {
     401:	if r0 == 0x0 goto +0x2 <LBB1_47>
     402:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     403:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000ca0 <LBB1_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     404:	r8 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     405:	r9 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     406:	r7 = *(u64 *)(r6 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     407:	r6 = *(u64 *)(r6 + 0x26)
     408:	r1 = 0x7
     409:	*(u32 *)(r10 - 0x20) = r1
     410:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     411:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     412:	r1 = 0x0 ll
     414:	call 0x1
;   if (likely(value)) {
     415:	if r0 == 0x0 goto +0x2 <LBB1_74>
     416:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     417:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000d10 <LBB1_74>:
     418:	r1 = 0x60
     419:	r3 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     420:	*(u32 *)(r3 + 0xe) = r1
     421:	r1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     422:	*(u16 *)(r3 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     423:	*(u64 *)(r3 + 0x2e) = r8
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     424:	*(u64 *)(r3 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     425:	*(u64 *)(r3 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     426:	*(u64 *)(r3 + 0x16) = r6
     427:	r1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     428:	*(u16 *)(r3 + 0x14) = r1
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     429:	r1 = *(u16 *)(r3 + 0xa)
     430:	*(u16 *)(r3 + 0x4) = r1
;   __u32 daddr_first           = *(__u32 *)old;
     431:	r1 = *(u32 *)(r3 + 0x0)
;   *(__u64 *)&new->daddr       = *(__u64 *)&old->saddr;
     432:	r2 = *(u16 *)(r3 + 0x6)
     433:	*(u16 *)(r3 + 0x0) = r2
     434:	r2 = *(u16 *)(r3 + 0x8)
     435:	*(u16 *)(r3 + 0x2) = r2
;   __u16 daddr_last            = *(__u16 *)old + 2;
     436:	r2 = r1
     437:	r2 += 0x2
;   *((__u16 *)&new->saddr + 2) = daddr_last;
     438:	*(u16 *)(r3 + 0xa) = r2
;   *(__u32 *)&new->saddr       = daddr_first;
     439:	*(u16 *)(r3 + 0x6) = r1
     440:	r1 >>= 0x10
     441:	*(u16 *)(r3 + 0x8) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     442:	r1 = *(u16 *)(r3 + 0x38)
     443:	r1 += -0x1
     444:	*(u16 *)(r3 + 0x38) = r1
     445:	goto +0x1c <LBB1_75>

0000000000000df0 <LBB1_80>:
;   if (likely(buf + 4 <= data_end)) {
     446:	r1 = r6
     447:	r1 += 0x4
     448:	if r1 > r9 goto +0xc <LBB1_72>
;     sum = csum_add(sum, *(__be32 *)buf++);
     449:	r1 = *(u32 *)(r6 + 0x0)
;   csum += addend;
     450:	r0 <<= 0x20
     451:	r0 >>= 0x20
     452:	r1 += r0
     453:	r3 = r1
     454:	r3 <<= 0x20
     455:	r3 >>= 0x20
     456:	r2 = 0x1
     457:	if r3 != r1 goto +0x1 <LBB1_71>
     458:	r2 = 0x0

0000000000000e58 <LBB1_71>:
;   return csum + (csum < addend);
     459:	r1 += r2
     460:	r0 = r1

0000000000000e68 <LBB1_72>:
     461:	r1 = 0xffff0000 ll
;   sum = (sum & 0xffff) + (sum >> 16);
     463:	r2 = r0
     464:	r2 &= r1
     465:	r2 >>= 0x10
     466:	r0 &= 0xffff
     467:	r0 += r2
;   sum = (sum & 0xffff) + (sum >> 16);
     468:	r1 = r0
     469:	r1 >>= 0x10
     470:	r1 += r0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     471:	r1 ^= -0x1
     472:	r2 = *(u64 *)(r10 - 0x30)
     473:	*(u16 *)(r2 + 0x38) = r1

0000000000000ed0 <LBB1_75>:
     474:	r1 = 0x8
     475:	*(u32 *)(r10 - 0x20) = r1
     476:	r2 = r10
     477:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     478:	r1 = 0x0 ll
     480:	call 0x1
;   if (likely(value)) {
     481:	if r0 == 0x0 goto +0x2 <LBB1_77>
     482:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     483:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000f20 <LBB1_77>:
;   return bpf_redirect(ctx->ifindex, 0);
     484:	r1 = *(u64 *)(r10 - 0x38)
     485:	r1 = *(u32 *)(r1 + 0x28)
     486:	r2 = 0x0
     487:	call 0x17
     488:	r3 = r0

0000000000000f48 <LBB1_78>:
;   return exceed2go_tc(ctx, BASE_LAYER_L2);
     489:	r0 = r3
     490:	exit

0000000000000f58 <exceed2go_tc_l3>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     491:	r9 = *(u32 *)(r1 + 0x50)
     492:	*(u64 *)(r10 - 0x38) = r1
     493:	r2 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
     494:	r8 = r2
     495:	r8 += 0x28
     496:	if r8 > r9 goto +0x1f <LBB2_5>
;   assert_equal(pkt->ipv6->version, 6, false);
     497:	r1 = *(u8 *)(r2 + 0x0)
     498:	r1 &= 0xf0
     499:	if r1 != 0x60 goto +0x1c <LBB2_5>
     500:	*(u64 *)(r10 - 0x30) = r2
     501:	r6 = 0x0
     502:	*(u32 *)(r10 - 0x20) = r6
     503:	r2 = r10
     504:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     505:	r1 = 0x0 ll
     507:	call 0x1
;   if (likely(value)) {
     508:	if r0 == 0x0 goto +0x2 <LBB2_4>
     509:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     510:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000ff8 <LBB2_4>:
     511:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
     512:	r1 = *(u64 *)(r2 + 0x20)
     513:	*(u64 *)(r10 - 0x18) = r1
     514:	r1 = *(u64 *)(r2 + 0x18)
     515:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
     516:	*(u8 *)(r10 - 0xc) = r6
     517:	*(u32 *)(r10 - 0x10) = r6
     518:	r3 = r10
;       .needle = pkt->ipv6->daddr,
     519:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
     520:	r1 = 0x0 ll
     522:	r2 = 0x0 ll
     524:	r4 = 0x0
     525:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
     526:	r1 = *(u8 *)(r10 - 0xc)
     527:	if r1 != 0x0 goto +0xd <LBB2_6>

0000000000001080 <LBB2_5>:
     528:	r1 = 0x5
     529:	*(u32 *)(r10 - 0x20) = r1
     530:	r2 = r10
     531:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     532:	r1 = 0x0 ll
     534:	call 0x1
;   if (likely(value)) {
     535:	if r0 == 0x0 goto +0x2 <LBB2_48>
     536:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     537:	lock *(u32 *)(r0 + 0x0) += r1

00000000000010d0 <LBB2_48>:
     538:	r7 = 0xffffffff ll
     540:	goto +0x17e <LBB2_76>

00000000000010e8 <LBB2_6>:
     541:	r6 = 0x1
     542:	*(u32 *)(r10 - 0x4) = r6
     543:	r2 = r10
     544:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     545:	r1 = 0x0 ll
     547:	call 0x1
;   if (likely(value)) {
     548:	if r0 == 0x0 goto +0x1 <LBB2_8>
;     __sync_fetch_and_add(value, 1);
     549:	lock *(u32 *)(r0 + 0x0) += r6

0000000000001130 <LBB2_8>:
     550:	r6 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
     551:	r1 = *(u8 *)(r6 + 0x7)
     552:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
     553:	r2 = *(u32 *)(r10 - 0x10)
     554:	if r1 >= r2 goto +0x8e <LBB2_14>
     555:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
     556:	r2 += -0x24
     557:	r1 = 0x0 ll
     559:	call 0x1
;     if (exceed_addr != NULL) {
     560:	if r0 == 0x0 goto +0x88 <LBB2_14>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
     561:	r9 -= r6
     562:	r6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
     563:	r6 -= r9
     564:	r6 <<= 0x20
     565:	r6 s>>= 0x20
     566:	r1 = 0x1
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
     567:	if r1 s> r6 goto +0x4 <LBB2_13>
     568:	r9 &= 0x3
     569:	if r9 == 0x0 goto +0x2 <LBB2_13>
;     tail_adj = -(new_ip_pkt_len % 4);
     570:	r9 = -r9
     571:	r6 = r9

00000000000011e0 <LBB2_13>:
     572:	r1 = *(u64 *)(r10 - 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     573:	r2 = *(u64 *)(r1 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     574:	*(u64 *)(r10 - 0x50) = r2
     575:	r1 = *(u64 *)(r1 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     576:	*(u64 *)(r10 - 0x48) = r1
     577:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     578:	*(u64 *)(r10 - 0x40) = r1
     579:	r1 = *(u64 *)(r0 + 0x0)
     580:	*(u64 *)(r10 - 0x30) = r1
     581:	r1 = 0x6
     582:	*(u32 *)(r10 - 0x20) = r1
     583:	r1 = 0x0
     584:	r8 = *(u64 *)(r10 - 0x38)
;   return tail_adj < 0 ? tail_adj : 0;
     585:	if r1 s> r6 goto +0x1 <LBB2_50>
     586:	r6 = 0x0

0000000000001258 <LBB2_50>:
     587:	r2 = r10
     588:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     589:	r1 = 0x0 ll
     591:	call 0x1
;   if (likely(value)) {
     592:	if r0 == 0x0 goto +0x2 <LBB2_52>
     593:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     594:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001298 <LBB2_52>:
;     long rc_head_adj = bpf_skb_adjust_room(ctx,
     595:	r1 = r8
     596:	r2 = 0x30
     597:	r3 = 0x1
     598:	r4 = 0x1
     599:	call 0x32
     600:	r7 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     601:	if r0 != 0x0 goto +0x141 <LBB2_76>
;     int new_len = ctx->len + pkt.tail_adjust;
     602:	r2 = *(u32 *)(r8 + 0x0)
     603:	r2 += r6
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     604:	r1 = r8
     605:	r3 = 0x0
     606:	call 0x26
     607:	if r0 != 0x0 goto +0x13b <LBB2_76>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     608:	r9 = *(u32 *)(r8 + 0x50)
     609:	r6 = *(u32 *)(r8 + 0x4c)
;   assert_boundary(icmp6, pkt->end, false);
     610:	r1 = r6
     611:	r1 += 0x30
     612:	if r1 > r9 goto +0x136 <LBB2_76>
     613:	r1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     614:	*(u32 *)(r6 + 0x0) = r1
     615:	r1 = 0x3
;   *icmp6                    = icmp6_new;
     616:	*(u32 *)(r6 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     617:	r1 = *(u64 *)(r10 - 0x50)
     618:	*(u64 *)(r6 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     619:	r1 = *(u64 *)(r10 - 0x48)
     620:	*(u64 *)(r6 + 0x18) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     621:	r1 = *(u64 *)(r10 - 0x40)
     622:	*(u64 *)(r6 + 0x10) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     623:	r1 = *(u64 *)(r10 - 0x30)
     624:	*(u64 *)(r6 + 0x8) = r1
     625:	r1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     626:	*(u16 *)(r6 + 0x6) = r1
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     627:	r8 = r6
     628:	r8 += 0x28
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     629:	r1 = r9
     630:	r1 -= r8
     631:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     632:	*(u16 *)(r6 + 0x4) = r1
     633:	r1 = 0x0
;   *icmp6                    = icmp6_new;
     634:	*(u32 *)(r6 + 0x2c) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     635:	r3 = r6
     636:	r3 += 0x8
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     637:	r2 = 0x0
     638:	r4 = 0x20
     639:	r5 = 0x0
     640:	call 0x1c
     641:	r1 = r0
     642:	r1 <<= 0x20
     643:	r1 >>= 0x20
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     644:	r0 = *(u16 *)(r6 + 0x4)
     645:	r0 <<= 0x10
     646:	r0 <<= 0x20
     647:	r0 >>= 0x20
;   csum += addend;
     648:	r0 += r1
     649:	r3 = r0
     650:	r3 <<= 0x20
     651:	r3 >>= 0x20
     652:	r1 = 0x1
     653:	r2 = 0x1
     654:	if r3 != r0 goto +0x1 <LBB2_57>
     655:	r2 = 0x0

0000000000001480 <LBB2_57>:
     656:	*(u64 *)(r10 - 0x30) = r6
;   return csum + (csum < addend);
     657:	r0 += r2
     658:	r2 = r0
     659:	r2 <<= 0x20
     660:	r2 >>= 0x20
     661:	r3 = 0xc5ffffff ll
     663:	if r2 > r3 goto +0x1 <LBB2_59>
     664:	r1 = 0x0

00000000000014c8 <LBB2_59>:
;   csum += addend;
     665:	r0 += r1
     666:	r6 = 0x400
;   return csum + (csum < addend);
     667:	r0 += 0x3a000000
     668:	goto +0x4 <LBB2_60>

00000000000014e8 <LBB2_66>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     669:	r1 &= 0xffff
     670:	r6 = r1
     671:	if r1 > 0x4 goto +0x1 <LBB2_60>
     672:	goto +0xcf <LBB2_78>

0000000000001508 <LBB2_60>:
;     __u16 j = (i >= 512) ? 512 : i;
     673:	r4 = r6
     674:	r4 <<= 0x20
     675:	r4 >>= 0x20
     676:	r1 = 0x200
     677:	if r1 > r4 goto +0x1 <LBB2_62>
     678:	r4 = 0x200

0000000000001538 <LBB2_62>:
;     if (likely(buf + j <= data_end)) {
     679:	r7 = r8
     680:	r7 += r4
     681:	if r7 > r9 goto +0x6 <LBB2_64>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     682:	r1 = 0x0
     683:	r2 = 0x0
     684:	r3 = r8
     685:	r5 = r0
     686:	call 0x1c
     687:	r8 = r7

0000000000001580 <LBB2_64>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     688:	r1 = r6
     689:	r1 += 0xfe00
     690:	r2 = r6
     691:	r2 <<= 0x20
     692:	r2 >>= 0x20
     693:	if r2 > 0x200 goto -0x19 <LBB2_66>
     694:	r6 >>= 0x1
     695:	r1 = r6
     696:	goto -0x1c <LBB2_66>

00000000000015c8 <LBB2_14>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     697:	r1 = *(u8 *)(r6 + 0x6)
     698:	if r1 != 0x3a goto -0xab <LBB2_5>
     699:	r1 = 0x2
     700:	*(u32 *)(r10 - 0x4) = r1
     701:	r2 = r10
     702:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     703:	r1 = 0x0 ll
     705:	call 0x1
;   if (likely(value)) {
     706:	if r0 == 0x0 goto +0x2 <LBB2_17>
     707:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     708:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001628 <LBB2_17>:
;   assert_boundary(icmp6, pkt->end, false);
     709:	r1 = r6
     710:	r1 += 0x30
     711:	if r1 > r9 goto -0xb8 <LBB2_5>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     712:	r1 = *(u8 *)(r8 + 0x0)
     713:	if r1 != 0x80 goto -0xba <LBB2_5>
;   assert_equal(icmp6->icmp6_code, 0, false);
     714:	r1 = *(u8 *)(r6 + 0x29)
     715:	if r1 != 0x0 goto -0xbc <LBB2_5>
     716:	r1 = 0x3
     717:	*(u32 *)(r10 - 0x4) = r1
     718:	r2 = r10
     719:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     720:	r1 = 0x0 ll
     722:	call 0x1
;   if (likely(value)) {
     723:	if r0 == 0x0 goto +0x2 <LBB2_22>
     724:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     725:	lock *(u32 *)(r0 + 0x0) += r1

00000000000016b0 <LBB2_22>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     726:	r3 = r6
     727:	r3 += 0x8
     728:	r1 = 0x0
     729:	r2 = 0x0
     730:	r4 = 0x20
     731:	r5 = 0x0
     732:	call 0x1c
     733:	r1 = r0
     734:	r1 <<= 0x20
     735:	r1 >>= 0x20
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     736:	r0 = *(u16 *)(r6 + 0x4)
     737:	r0 <<= 0x10
     738:	r0 <<= 0x20
     739:	r0 >>= 0x20
;   csum += addend;
     740:	r0 += r1
     741:	r3 = r0
     742:	r3 <<= 0x20
     743:	r3 >>= 0x20
     744:	r1 = 0x1
     745:	r2 = 0x1
     746:	if r3 != r0 goto +0x1 <LBB2_24>
     747:	r2 = 0x0

0000000000001760 <LBB2_24>:
;   return csum + (csum < addend);
     748:	r0 += r2
     749:	r2 = r0
     750:	r2 <<= 0x20
     751:	r2 >>= 0x20
     752:	r3 = 0xc5ffffff ll
     754:	if r2 > r3 goto +0x1 <LBB2_26>
     755:	r1 = 0x0

00000000000017a0 <LBB2_26>:
;   csum += addend;
     756:	r0 += r1
     757:	r6 = 0x400
;   return csum + (csum < addend);
     758:	r0 += 0x3a000000
     759:	goto +0x4 <LBB2_27>

00000000000017c0 <LBB2_33>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     760:	r1 &= 0xffff
     761:	r6 = r1
     762:	if r1 > 0x4 goto +0x1 <LBB2_27>
     763:	goto +0x18 <LBB2_77>

00000000000017e0 <LBB2_27>:
;     __u16 j = (i >= 512) ? 512 : i;
     764:	r4 = r6
     765:	r4 <<= 0x20
     766:	r4 >>= 0x20
     767:	r1 = 0x200
     768:	if r1 > r4 goto +0x1 <LBB2_29>
     769:	r4 = 0x200

0000000000001810 <LBB2_29>:
;     if (likely(buf + j <= data_end)) {
     770:	r7 = r8
     771:	r7 += r4
     772:	if r7 > r9 goto +0x6 <LBB2_31>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     773:	r1 = 0x0
     774:	r2 = 0x0
     775:	r3 = r8
     776:	r5 = r0
     777:	call 0x1c
     778:	r8 = r7

0000000000001858 <LBB2_31>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     779:	r1 = r6
     780:	r1 += 0xfe00
     781:	r2 = r6
     782:	r2 <<= 0x20
     783:	r2 >>= 0x20
     784:	if r2 > 0x200 goto -0x19 <LBB2_33>
     785:	r6 >>= 0x1
     786:	r1 = r6
     787:	goto -0x1c <LBB2_33>

00000000000018a0 <LBB2_77>:
;   if (likely(buf + 4 <= data_end)) {
     788:	r1 = r8
     789:	r1 += 0x4
     790:	r6 = *(u64 *)(r10 - 0x30)
     791:	if r1 > r9 goto +0xd <LBB2_37>
;   csum += addend;
     792:	r0 <<= 0x20
     793:	r0 >>= 0x20
;     sum = csum_add(sum, *(__be32 *)buf++);
     794:	r1 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     795:	r1 += r0
     796:	r3 = r1
     797:	r3 <<= 0x20
     798:	r3 >>= 0x20
     799:	r2 = 0x1
     800:	if r3 != r1 goto +0x1 <LBB2_36>
     801:	r2 = 0x0

0000000000001910 <LBB2_36>:
;   return csum + (csum < addend);
     802:	r1 += r2
;     sum = csum_add(sum, *(__be32 *)buf++);
     803:	r8 += 0x1
     804:	r0 = r1

0000000000001928 <LBB2_37>:
     805:	r1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     806:	r2 = r8
     807:	r2 += 0x2
     808:	if r2 > r9 goto +0x2 <LBB2_39>
;     addend = *(__be16 *)buf++;
     809:	r1 = *(u16 *)(r8 + 0x0)
     810:	r8 += 0x1

0000000000001958 <LBB2_39>:
;   if (likely(buf + 1 <= data_end)) {
     811:	r2 = r8
     812:	r2 += 0x1
     813:	if r2 > r9 goto +0x2 <LBB2_41>
;     addend += *(__u8 *)buf++;
     814:	r2 = *(u8 *)(r8 + 0x0)
     815:	r1 += r2

0000000000001980 <LBB2_41>:
;   csum += addend;
     816:	r0 <<= 0x20
     817:	r0 >>= 0x20
     818:	r1 += r0
     819:	r3 = r1
     820:	r3 <<= 0x20
     821:	r3 >>= 0x20
     822:	r2 = 0x1
     823:	if r3 != r1 goto +0x1 <LBB2_43>
     824:	r2 = 0x0

00000000000019c8 <LBB2_43>:
;   return csum + (csum < addend);
     825:	r1 += r2
     826:	r2 = 0xffff0000 ll
;   return csum + (csum < addend);
     828:	r3 = r1
     829:	r3 &= r2
;   sum = (sum & 0xffff) + (sum >> 16);
     830:	r1 &= 0xffff
     831:	r3 >>= 0x10
     832:	r1 += r3
;   sum = (sum & 0xffff) + (sum >> 16);
     833:	r2 = r1
     834:	r2 >>= 0x10
     835:	r2 += r1
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     836:	r2 &= 0xffff
     837:	if r2 != 0xffff goto -0x136 <LBB2_5>
     838:	r1 = 0x4
     839:	*(u32 *)(r10 - 0x4) = r1
     840:	r2 = r10
     841:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     842:	r1 = 0x0 ll
     844:	call 0x1
     845:	r8 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     846:	if r0 == 0x0 goto +0x2 <LBB2_46>
     847:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     848:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001a88 <LBB2_46>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     849:	r1 = *(u64 *)(r6 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     850:	*(u64 *)(r10 - 0x40) = r1
     851:	r9 = *(u64 *)(r6 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     852:	r7 = *(u64 *)(r6 + 0x20)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     853:	r6 = *(u64 *)(r6 + 0x18)
     854:	r1 = 0x7
     855:	*(u32 *)(r10 - 0x20) = r1
     856:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     857:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     858:	r1 = 0x0 ll
     860:	call 0x1
;   if (likely(value)) {
     861:	if r0 == 0x0 goto +0x2 <LBB2_72>
     862:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     863:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001b00 <LBB2_72>:
     864:	r1 = 0x60
     865:	r2 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     866:	*(u32 *)(r2 + 0x0) = r1
     867:	r1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     868:	*(u16 *)(r2 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     869:	r1 = *(u64 *)(r10 - 0x40)
     870:	*(u64 *)(r2 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     871:	*(u64 *)(r2 + 0x18) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     872:	*(u64 *)(r2 + 0x10) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     873:	*(u64 *)(r2 + 0x8) = r6
     874:	r1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     875:	*(u16 *)(r2 + 0x6) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     876:	r1 = *(u16 *)(r2 + 0x2a)
     877:	r1 += -0x1
     878:	*(u16 *)(r2 + 0x2a) = r1
     879:	goto +0x1d <LBB2_73>

0000000000001b80 <LBB2_78>:
;   if (likely(buf + 4 <= data_end)) {
     880:	r1 = r8
     881:	r1 += 0x4
     882:	r4 = *(u64 *)(r10 - 0x30)
     883:	if r1 > r9 goto +0xc <LBB2_70>
;     sum = csum_add(sum, *(__be32 *)buf++);
     884:	r1 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     885:	r0 <<= 0x20
     886:	r0 >>= 0x20
     887:	r1 += r0
     888:	r3 = r1
     889:	r3 <<= 0x20
     890:	r3 >>= 0x20
     891:	r2 = 0x1
     892:	if r3 != r1 goto +0x1 <LBB2_69>
     893:	r2 = 0x0

0000000000001bf0 <LBB2_69>:
;   return csum + (csum < addend);
     894:	r1 += r2
     895:	r0 = r1

0000000000001c00 <LBB2_70>:
     896:	r1 = 0xffff0000 ll
;   sum = (sum & 0xffff) + (sum >> 16);
     898:	r2 = r0
     899:	r2 &= r1
     900:	r2 >>= 0x10
     901:	r0 &= 0xffff
     902:	r0 += r2
;   sum = (sum & 0xffff) + (sum >> 16);
     903:	r1 = r0
     904:	r1 >>= 0x10
     905:	r1 += r0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     906:	r1 ^= -0x1
     907:	*(u16 *)(r4 + 0x2a) = r1
     908:	r8 = *(u64 *)(r10 - 0x38)

0000000000001c68 <LBB2_73>:
     909:	r1 = 0x8
     910:	*(u32 *)(r10 - 0x20) = r1
     911:	r2 = r10
     912:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     913:	r1 = 0x0 ll
     915:	call 0x1
;   if (likely(value)) {
     916:	if r0 == 0x0 goto +0x2 <LBB2_75>
     917:	r1 = 0x1
;     __sync_fetch_and_add(value, 1);
     918:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001cb8 <LBB2_75>:
;   return bpf_redirect(ctx->ifindex, 0);
     919:	r1 = *(u32 *)(r8 + 0x28)
     920:	r2 = 0x0
     921:	call 0x17
     922:	r7 = r0

0000000000001cd8 <LBB2_76>:
;   return exceed2go_tc(ctx, BASE_LAYER_L3);
     923:	r0 = r7
     924:	exit
