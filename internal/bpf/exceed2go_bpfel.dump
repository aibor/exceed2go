
exceed2go_bpfel.o:	file format elf64-bpf

Disassembly of section .text:

0000000000000000 <target_search_cb>:
;                  struct target_search_cb_ctx *cb_ctx) {
       0:	r0 = 0x0
;   if (*key == 0) {
       1:	r1 = *(u32 *)(r2 + 0x0)
       2:	if w1 == 0x0 goto +0xf <LBB3_6>
       3:	r0 = 0x1
;   if (!value || !((const __u32 *)(value))[0])
       4:	if r3 == 0x0 goto +0xd <LBB3_6>
       5:	r2 = *(u32 *)(r3 + 0x0)
       6:	if w2 == 0x0 goto +0xb <LBB3_6>
;   return ((a->in6_u.u6_addr64[0] == b->in6_u.u6_addr64[0]) &&
       7:	r2 = *(u64 *)(r3 + 0x0)
       8:	r5 = *(u64 *)(r4 + 0x0)
       9:	r0 = 0x0
      10:	if r5 != r2 goto +0x7 <LBB3_6>
;           (a->in6_u.u6_addr64[1] == b->in6_u.u6_addr64[1]));
      11:	r2 = *(u64 *)(r3 + 0x8)
      12:	r3 = *(u64 *)(r4 + 0x8)
;   if (in6_addr_equal(&cb_ctx->needle, value)) {
      13:	if r3 != r2 goto +0x4 <LBB3_6>
;     cb_ctx->key   = *key;
      14:	*(u32 *)(r4 + 0x10) = r1
      15:	w1 = 0x1
;     cb_ctx->found = true;
      16:	*(u8 *)(r4 + 0x14) = r1
      17:	r0 = 0x1

0000000000000090 <LBB3_6>:
; }
      18:	exit

Disassembly of section xdp:

0000000000000000 <exceed2go_xdp_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r8 = *(u32 *)(r1 + 0x0)
       1:	r9 = *(u32 *)(r1 + 0x4)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       2:	r3 = r8
       3:	r3 += 0x36
       4:	if r3 > r9 goto +0x23 <LBB0_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       5:	r2 = *(u16 *)(r8 + 0xc)
       6:	if w2 != 0xdd86 goto +0x21 <LBB0_6>
       7:	r7 = r8
       8:	r7 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
       9:	r2 = *(u8 *)(r7 + 0x0)
      10:	w2 &= 0xf0
      11:	if w2 != 0x60 goto +0x1c <LBB0_6>
      12:	*(u64 *)(r10 - 0x38) = r1
      13:	*(u64 *)(r10 - 0x30) = r3
      14:	w6 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r6
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB0_5>
      22:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB0_5>:
;       .needle = pkt->ipv6->daddr,
      24:	r1 = *(u64 *)(r8 + 0x2e)
      25:	*(u64 *)(r10 - 0x18) = r1
      26:	r1 = *(u64 *)(r8 + 0x26)
      27:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      28:	*(u8 *)(r10 - 0xc) = r6
      29:	*(u32 *)(r10 - 0x10) = r6
      30:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      31:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      32:	r1 = 0x0 ll
      34:	r2 = 0x0 ll
      36:	r4 = 0x0
      37:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      38:	r1 = *(u8 *)(r10 - 0xc)
      39:	if w1 != 0x0 goto +0xc <LBB0_7>

0000000000000140 <LBB0_6>:
      40:	w1 = 0x5
      41:	*(u32 *)(r10 - 0x20) = r1
      42:	r2 = r10
      43:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      44:	r1 = 0x0 ll
      46:	call 0x1
;   if (likely(value)) {
      47:	if r0 == 0x0 goto +0x2 <LBB0_49>
      48:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      49:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000190 <LBB0_49>:
      50:	w0 = 0x2
      51:	goto +0x15a <LBB0_77>

00000000000001a0 <LBB0_7>:
      52:	w6 = 0x1
      53:	*(u32 *)(r10 - 0x4) = r6
      54:	r2 = r10
      55:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      56:	r1 = 0x0 ll
      58:	call 0x1
;   if (likely(value)) {
      59:	if r0 == 0x0 goto +0x1 <LBB0_9>
;     __sync_fetch_and_add(value, 1);
      60:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001e8 <LBB0_9>:
;   __u32 hop_key = pkt->ipv6->hop_limit;
      61:	r1 = *(u8 *)(r8 + 0x15)
      62:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      63:	r2 = *(u32 *)(r10 - 0x10)
      64:	if w2 <= w1 goto +0x82 <LBB0_15>
      65:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      66:	r2 += -0x24
      67:	r1 = 0x0 ll
      69:	call 0x1
;     if (exceed_addr != NULL) {
      70:	if r0 == 0x0 goto +0x7c <LBB0_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      71:	w9 -= w7
      72:	w7 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      73:	w7 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      74:	if w7 s< 0x1 goto +0x4 <LBB0_14>
      75:	w9 &= 0x3
      76:	if w9 == 0x0 goto +0x2 <LBB0_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      77:	w9 = -w9
      78:	w7 = w9

0000000000000278 <LBB0_14>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      79:	r1 = *(u64 *)(r8 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      80:	*(u64 *)(r10 - 0x30) = r1
      81:	r1 = *(u64 *)(r8 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      82:	*(u64 *)(r10 - 0x40) = r1
      83:	r8 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      84:	r9 = *(u64 *)(r0 + 0x0)
      85:	w1 = 0x6
      86:	*(u32 *)(r10 - 0x20) = r1
      87:	r6 = *(u64 *)(r10 - 0x38)
;   return tail_adj < 0 ? tail_adj : 0;
      88:	if w7 s< 0x0 goto +0x1 <LBB0_51>
      89:	w7 = 0x0

00000000000002d0 <LBB0_51>:
      90:	r2 = r10
      91:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      92:	r1 = 0x0 ll
      94:	call 0x1
;   if (likely(value)) {
      95:	if r0 == 0x0 goto +0x2 <LBB0_53>
      96:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      97:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000310 <LBB0_53>:
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
      98:	r1 = r6
      99:	w2 = -0x30
     100:	call 0x2c
     101:	r1 = r0
     102:	w0 = 0x0
     103:	if r1 != 0x0 goto +0x126 <LBB0_77>
;     assert_equal(bpf_xdp_adjust_tail(ctx, tail_adj), 0, XDP_ABORTED);
     104:	r1 = r6
     105:	w2 = w7
     106:	call 0x41
     107:	r1 = r0
     108:	w0 = 0x0
     109:	if r1 != 0x0 goto +0x120 <LBB0_77>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     110:	r7 = *(u32 *)(r6 + 0x4)
     111:	r6 = *(u32 *)(r6 + 0x0)
;       assert_boundary(old_eth, pkt.end, XDP_ABORTED);
     112:	r1 = r6
     113:	r1 += 0x3e
     114:	if r1 > r7 goto +0x11b <LBB0_77>
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     115:	r2 = r6
     116:	r2 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     117:	w1 = w7
     118:	*(u64 *)(r10 - 0x38) = r2
     119:	w1 -= w2
     120:	w2 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     121:	*(u32 *)(r6 + 0xe) = r2
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     122:	r2 = *(u64 *)(r10 - 0x40)
     123:	*(u64 *)(r6 + 0x26) = r2
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     124:	*(u64 *)(r6 + 0x1e) = r8
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     125:	*(u64 *)(r6 + 0x16) = r9
     126:	w2 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     127:	*(u16 *)(r6 + 0x14) = r2
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     128:	r2 = *(u16 *)(r6 + 0x38)
     129:	*(u16 *)(r6 + 0x2) = r2
     130:	r2 = *(u16 *)(r6 + 0x36)
     131:	*(u16 *)(r6 + 0x0) = r2
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     132:	r2 = *(u16 *)(r6 + 0x32)
     133:	*(u16 *)(r6 + 0x8) = r2
     134:	r2 = *(u16 *)(r6 + 0x30)
     135:	*(u16 *)(r6 + 0x6) = r2
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     136:	r2 = *(u16 *)(r6 + 0x3a)
     137:	*(u16 *)(r6 + 0x4) = r2
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     138:	r2 = *(u16 *)(r6 + 0x34)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     139:	r3 = *(u64 *)(r10 - 0x30)
     140:	*(u64 *)(r6 + 0x2e) = r3
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     141:	*(u16 *)(r6 + 0xa) = r2
;   new->proto = old->proto;
     142:	r2 = *(u16 *)(r6 + 0x3c)
     143:	*(u16 *)(r6 + 0xc) = r2
     144:	w2 = 0x3
;   *icmp6                    = icmp6_new;
     145:	*(u32 *)(r6 + 0x36) = r2
     146:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     147:	*(u16 *)(r6 + 0x12) = r1
     148:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     149:	*(u32 *)(r6 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     150:	r3 = r6
     151:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     152:	r1 = 0x0
     153:	w2 = 0x0
     154:	w4 = 0x20
     155:	w5 = 0x0
     156:	call 0x1c
     157:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     158:	r3 = *(u16 *)(r6 + 0x12)
     159:	w3 <<= 0x10
;   csum += addend;
     160:	w0 = w3
     161:	w0 += w1
     162:	w1 = 0x1
     163:	w2 = 0x1
;   csum += addend;
     164:	if w0 < w3 goto +0x1 <LBB0_58>
     165:	w2 = 0x0

0000000000000530 <LBB0_58>:
;   return csum + (csum < addend);
     166:	w0 += w2
     167:	if w0 > -0x3a000001 goto +0x1 <LBB0_60>
     168:	w1 = 0x0

0000000000000548 <LBB0_60>:
;   csum += addend;
     169:	w0 += w1
     170:	w8 = 0x400
;   return csum + (csum < addend);
     171:	w0 += 0x3a000000
     172:	r3 = *(u64 *)(r10 - 0x38)
     173:	goto +0x4 <LBB0_61>

0000000000000570 <LBB0_67>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     174:	w1 &= 0xffff
     175:	w8 = w1
     176:	if w1 > 0x4 goto +0x1 <LBB0_61>
     177:	goto +0xbd <LBB0_79>

0000000000000590 <LBB0_61>:
     178:	w4 = w8
;     __u16 j = (i >= 512) ? 512 : i;
     179:	if w8 < 0x200 goto +0x1 <LBB0_63>
     180:	w4 = 0x200

00000000000005a8 <LBB0_63>:
;     if (likely(buf + j <= data_end)) {
     181:	r9 = r3
     182:	r9 += r4
     183:	if r9 > r7 goto +0x5 <LBB0_65>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     184:	r1 = 0x0
     185:	w2 = 0x0
     186:	w5 = w0
     187:	call 0x1c
     188:	r3 = r9

00000000000005e8 <LBB0_65>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     189:	w1 = w8
     190:	w1 += 0xfe00
     191:	if w8 > 0x200 goto -0x12 <LBB0_67>
     192:	w8 >>= 0x1
     193:	w1 = w8
     194:	goto -0x15 <LBB0_67>

0000000000000618 <LBB0_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     195:	r1 = *(u8 *)(r8 + 0x14)
     196:	if w1 != 0x3a goto -0x9d <LBB0_6>
     197:	w1 = 0x2
     198:	*(u32 *)(r10 - 0x4) = r1
     199:	r2 = r10
     200:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     201:	r1 = 0x0 ll
     203:	call 0x1
;   if (likely(value)) {
     204:	if r0 == 0x0 goto +0x2 <LBB0_18>
     205:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     206:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000678 <LBB0_18>:
;   assert_boundary(icmp6, pkt->end, false);
     207:	r1 = r8
     208:	r1 += 0x3e
     209:	if r1 > r9 goto -0xaa <LBB0_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     210:	r1 = *(u64 *)(r10 - 0x30)
     211:	r1 = *(u8 *)(r1 + 0x0)
     212:	if w1 != 0x80 goto -0xad <LBB0_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     213:	r1 = *(u8 *)(r8 + 0x37)
     214:	if w1 != 0x0 goto -0xaf <LBB0_6>
     215:	w1 = 0x3
     216:	*(u32 *)(r10 - 0x4) = r1
     217:	r2 = r10
     218:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     219:	r1 = 0x0 ll
     221:	call 0x1
;   if (likely(value)) {
     222:	if r0 == 0x0 goto +0x2 <LBB0_23>
     223:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     224:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000708 <LBB0_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     225:	r3 = r8
     226:	r3 += 0x16
     227:	r1 = 0x0
     228:	w2 = 0x0
     229:	w4 = 0x20
     230:	w5 = 0x0
     231:	call 0x1c
     232:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     233:	r3 = *(u16 *)(r8 + 0x12)
     234:	w3 <<= 0x10
;   csum += addend;
     235:	w0 = w3
     236:	w0 += w1
     237:	w1 = 0x1
     238:	w2 = 0x1
;   csum += addend;
     239:	if w0 < w3 goto +0x1 <LBB0_25>
     240:	w2 = 0x0

0000000000000788 <LBB0_25>:
;   return csum + (csum < addend);
     241:	w0 += w2
     242:	r3 = *(u64 *)(r10 - 0x30)
;   return csum + (csum < addend);
     243:	if w0 > -0x3a000001 goto +0x1 <LBB0_27>
     244:	w1 = 0x0

00000000000007a8 <LBB0_27>:
;   csum += addend;
     245:	w0 += w1
     246:	w6 = 0x400
;   return csum + (csum < addend);
     247:	w0 += 0x3a000000
     248:	goto +0x4 <LBB0_28>

00000000000007c8 <LBB0_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     249:	w1 &= 0xffff
     250:	w6 = w1
     251:	if w1 > 0x4 goto +0x1 <LBB0_28>
     252:	goto +0x11 <LBB0_78>

00000000000007e8 <LBB0_28>:
     253:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     254:	if w6 < 0x200 goto +0x1 <LBB0_30>
     255:	w4 = 0x200

0000000000000800 <LBB0_30>:
;     if (likely(buf + j <= data_end)) {
     256:	r7 = r3
     257:	r7 += r4
     258:	if r7 > r9 goto +0x5 <LBB0_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     259:	r1 = 0x0
     260:	w2 = 0x0
     261:	w5 = w0
     262:	call 0x1c
     263:	r3 = r7

0000000000000840 <LBB0_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     264:	w1 = w6
     265:	w1 += 0xfe00
     266:	if w6 > 0x200 goto -0x12 <LBB0_34>
     267:	w6 >>= 0x1
     268:	w1 = w6
     269:	goto -0x15 <LBB0_34>

0000000000000870 <LBB0_78>:
;   if (likely(buf + 4 <= data_end)) {
     270:	r1 = r3
     271:	r1 += 0x4
     272:	if r1 > r9 goto +0x9 <LBB0_38>
;     sum = csum_add(sum, *(__be32 *)buf++);
     273:	r4 = *(u32 *)(r3 + 0x0)
;   csum += addend;
     274:	w1 = w4
     275:	w1 += w0
     276:	w2 = 0x1
     277:	if w1 < w4 goto +0x1 <LBB0_37>
     278:	w2 = 0x0

00000000000008b8 <LBB0_37>:
;   return csum + (csum < addend);
     279:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     280:	r3 += 0x1
     281:	w0 = w1

00000000000008d0 <LBB0_38>:
     282:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     283:	r2 = r3
     284:	r2 += 0x2
     285:	if r2 > r9 goto +0x2 <LBB0_40>
;     addend = *(__be16 *)buf++;
     286:	r1 = *(u16 *)(r3 + 0x0)
     287:	r3 += 0x1

0000000000000900 <LBB0_40>:
;   if (likely(buf + 1 <= data_end)) {
     288:	r2 = r3
     289:	r2 += 0x1
     290:	if r2 > r9 goto +0x2 <LBB0_42>
;     addend += *(__u8 *)buf++;
     291:	r2 = *(u8 *)(r3 + 0x0)
     292:	w1 += w2

0000000000000928 <LBB0_42>:
;   csum += addend;
     293:	w2 = w1
     294:	w2 += w0
     295:	w3 = 0x1
     296:	if w2 < w1 goto +0x1 <LBB0_44>
     297:	w3 = 0x0

0000000000000950 <LBB0_44>:
;   return csum + (csum < addend);
     298:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     299:	w1 = w2
     300:	w1 >>= 0x10
     301:	w2 &= 0xffff
     302:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     303:	w1 = w2
     304:	w1 >>= 0x10
     305:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     306:	w1 &= 0xffff
     307:	if w1 != 0xffff goto -0x10c <LBB0_6>
     308:	w1 = 0x4
     309:	*(u32 *)(r10 - 0x4) = r1
     310:	r2 = r10
     311:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     312:	r1 = 0x0 ll
     314:	call 0x1
;   if (likely(value)) {
     315:	if r0 == 0x0 goto +0x2 <LBB0_47>
     316:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     317:	lock *(u32 *)(r0 + 0x0) += r1

00000000000009f0 <LBB0_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     318:	r1 = *(u64 *)(r8 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     319:	*(u64 *)(r10 - 0x30) = r1
     320:	r9 = *(u64 *)(r8 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     321:	r7 = *(u64 *)(r8 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     322:	r6 = *(u64 *)(r8 + 0x26)
     323:	w1 = 0x7
     324:	*(u32 *)(r10 - 0x20) = r1
     325:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     326:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     327:	r1 = 0x0 ll
     329:	call 0x1
;   if (likely(value)) {
     330:	if r0 == 0x0 goto +0x2 <LBB0_73>
     331:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     332:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000a68 <LBB0_73>:
;   bpf_memcpy(&tmp, &old->daddr, sizeof(struct mac_addr));
     333:	r1 = *(u16 *)(r8 + 0x4)
     334:	*(u16 *)(r10 - 0x1c) = r1
     335:	r1 = *(u16 *)(r8 + 0x2)
     336:	w1 <<= 0x10
     337:	r2 = *(u16 *)(r8 + 0x0)
     338:	w1 |= w2
     339:	*(u32 *)(r10 - 0x20) = r1
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     340:	r1 = *(u16 *)(r8 + 0x6)
     341:	*(u16 *)(r8 + 0x0) = r1
     342:	r1 = *(u16 *)(r8 + 0x8)
     343:	*(u16 *)(r8 + 0x2) = r1
     344:	r1 = *(u16 *)(r8 + 0xa)
     345:	*(u16 *)(r8 + 0x4) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     346:	r1 = *(u16 *)(r10 - 0x1c)
     347:	*(u16 *)(r8 + 0xa) = r1
     348:	r1 = *(u32 *)(r10 - 0x20)
     349:	*(u16 *)(r8 + 0x6) = r1
     350:	w1 >>= 0x10
     351:	*(u16 *)(r8 + 0x8) = r1
     352:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     353:	*(u32 *)(r8 + 0xe) = r1
     354:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     355:	*(u16 *)(r8 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     356:	r1 = *(u64 *)(r10 - 0x30)
     357:	*(u64 *)(r8 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     358:	*(u64 *)(r8 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     359:	*(u64 *)(r8 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     360:	*(u64 *)(r8 + 0x16) = r6
     361:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     362:	*(u16 *)(r8 + 0x14) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     363:	r1 = *(u16 *)(r8 + 0x38)
     364:	w1 += -0x1
     365:	*(u16 *)(r8 + 0x38) = r1
     366:	goto +0x14 <LBB0_74>

0000000000000b78 <LBB0_79>:
;   if (likely(buf + 4 <= data_end)) {
     367:	r1 = r3
     368:	r1 += 0x4
     369:	if r1 > r7 goto +0x8 <LBB0_71>
;     sum = csum_add(sum, *(__be32 *)buf++);
     370:	r3 = *(u32 *)(r3 + 0x0)
;   csum += addend;
     371:	w1 = w3
     372:	w1 += w0
     373:	w2 = 0x1
     374:	if w1 < w3 goto +0x1 <LBB0_70>
     375:	w2 = 0x0

0000000000000bc0 <LBB0_70>:
;   return csum + (csum < addend);
     376:	w1 += w2
     377:	w0 = w1

0000000000000bd0 <LBB0_71>:
;   sum = (sum & 0xffff) + (sum >> 16);
     378:	w1 = w0
     379:	w1 >>= 0x10
     380:	w0 &= 0xffff
     381:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     382:	w1 = w0
     383:	w1 >>= 0x10
     384:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     385:	w1 ^= -0x1
     386:	*(u16 *)(r6 + 0x38) = r1

0000000000000c18 <LBB0_74>:
     387:	w1 = 0x8
     388:	*(u32 *)(r10 - 0x20) = r1
     389:	r2 = r10
     390:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     391:	r1 = 0x0 ll
     393:	call 0x1
;   if (likely(value)) {
     394:	if r0 == 0x0 goto +0x2 <LBB0_76>
     395:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     396:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000c68 <LBB0_76>:
     397:	w0 = 0x3

0000000000000c70 <LBB0_77>:
;   return exceed2go_xdp(ctx, BASE_LAYER_L2);
     398:	exit

Disassembly of section tc:

0000000000000000 <exceed2go_tc_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r7 = *(u32 *)(r1 + 0x4c)
       1:	r8 = *(u32 *)(r1 + 0x50)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       2:	r3 = r7
       3:	r3 += 0x36
       4:	if r3 > r8 goto +0x23 <LBB1_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       5:	r2 = *(u16 *)(r7 + 0xc)
       6:	if w2 != 0xdd86 goto +0x21 <LBB1_6>
       7:	r6 = r7
       8:	r6 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
       9:	r2 = *(u8 *)(r6 + 0x0)
      10:	w2 &= 0xf0
      11:	if w2 != 0x60 goto +0x1c <LBB1_6>
      12:	*(u64 *)(r10 - 0x30) = r1
      13:	*(u64 *)(r10 - 0x38) = r3
      14:	w9 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r9
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB1_5>
      22:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB1_5>:
;       .needle = pkt->ipv6->daddr,
      24:	r1 = *(u64 *)(r7 + 0x2e)
      25:	*(u64 *)(r10 - 0x18) = r1
      26:	r1 = *(u64 *)(r7 + 0x26)
      27:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      28:	*(u8 *)(r10 - 0xc) = r9
      29:	*(u32 *)(r10 - 0x10) = r9
      30:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      31:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      32:	r1 = 0x0 ll
      34:	r2 = 0x0 ll
      36:	r4 = 0x0
      37:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      38:	r1 = *(u8 *)(r10 - 0xc)
      39:	if w1 != 0x0 goto +0xc <LBB1_7>

0000000000000140 <LBB1_6>:
      40:	w1 = 0x5
      41:	*(u32 *)(r10 - 0x20) = r1
      42:	r2 = r10
      43:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      44:	r1 = 0x0 ll
      46:	call 0x1
;   if (likely(value)) {
      47:	if r0 == 0x0 goto +0x2 <LBB1_49>
      48:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      49:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000190 <LBB1_49>:
      50:	w0 = -0x1
      51:	goto +0x17d <LBB1_81>

00000000000001a0 <LBB1_7>:
      52:	w9 = 0x1
      53:	*(u32 *)(r10 - 0x4) = r9
      54:	r2 = r10
      55:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      56:	r1 = 0x0 ll
      58:	call 0x1
;   if (likely(value)) {
      59:	if r0 == 0x0 goto +0x1 <LBB1_9>
;     __sync_fetch_and_add(value, 1);
      60:	lock *(u32 *)(r0 + 0x0) += r9

00000000000001e8 <LBB1_9>:
;   __u32 hop_key = pkt->ipv6->hop_limit;
      61:	r1 = *(u8 *)(r7 + 0x15)
      62:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      63:	r2 = *(u32 *)(r10 - 0x10)
      64:	if w2 <= w1 goto +0x3b <LBB1_15>
      65:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      66:	r2 += -0x24
      67:	r1 = 0x0 ll
      69:	call 0x1
;     if (exceed_addr != NULL) {
      70:	if r0 == 0x0 goto +0x35 <LBB1_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      71:	w8 -= w6
      72:	w9 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      73:	w9 -= w8
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      74:	if w9 s< 0x1 goto +0x4 <LBB1_14>
      75:	w8 &= 0x3
      76:	if w8 == 0x0 goto +0x2 <LBB1_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      77:	w8 = -w8
      78:	w9 = w8

0000000000000278 <LBB1_14>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      79:	r1 = *(u64 *)(r7 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      80:	*(u64 *)(r10 - 0x50) = r1
      81:	r1 = *(u64 *)(r7 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      82:	*(u64 *)(r10 - 0x48) = r1
      83:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      84:	*(u64 *)(r10 - 0x40) = r1
      85:	r1 = *(u64 *)(r0 + 0x0)
      86:	*(u64 *)(r10 - 0x38) = r1
      87:	w1 = 0x6
      88:	*(u32 *)(r10 - 0x20) = r1
;   return tail_adj < 0 ? tail_adj : 0;
      89:	if w9 s< 0x0 goto +0x1 <LBB1_51>
      90:	w9 = 0x0

00000000000002d8 <LBB1_51>:
      91:	r2 = r10
      92:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      93:	r1 = 0x0 ll
      95:	call 0x1
;   if (likely(value)) {
      96:	if r0 == 0x0 goto +0x2 <LBB1_53>
      97:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      98:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000318 <LBB1_53>:
;       bpf_memcpy(&eth, pkt.eth, sizeof(struct ethhdr));
      99:	r1 = *(u16 *)(r7 + 0xa)
     100:	w1 <<= 0x10
     101:	r2 = *(u16 *)(r7 + 0x8)
     102:	w1 |= w2
     103:	*(u32 *)(r10 - 0x18) = r1
     104:	r1 = *(u16 *)(r7 + 0x0)
     105:	r2 = *(u16 *)(r7 + 0x2)
     106:	r2 <<= 0x10
     107:	r2 |= r1
     108:	r1 = *(u16 *)(r7 + 0x6)
     109:	w1 <<= 0x10
     110:	r3 = *(u16 *)(r7 + 0x4)
     111:	w1 |= w3
     112:	r1 <<= 0x20
     113:	r1 |= r2
     114:	*(u64 *)(r10 - 0x20) = r1
     115:	r6 = *(u16 *)(r7 + 0xc)
     116:	r1 = *(u64 *)(r10 - 0x30)
;     if (ctx->protocol == bpf_htons(ETH_P_IPV6)) {
     117:	r2 = *(u32 *)(r1 + 0x10)
     118:	if w2 != 0xdd86 goto +0xb0 <LBB1_55>
;       rc_head_adj = bpf_skb_adjust_room(ctx,
     119:	w2 = 0x30
     120:	w3 = 0x1
     121:	r4 = 0x1
     122:	call 0x32
     123:	goto +0xae <LBB1_56>

00000000000003e0 <LBB1_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     124:	r1 = *(u8 *)(r7 + 0x14)
     125:	if w1 != 0x3a goto -0x56 <LBB1_6>
     126:	w1 = 0x2
     127:	*(u32 *)(r10 - 0x4) = r1
     128:	r2 = r10
     129:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     130:	r1 = 0x0 ll
     132:	call 0x1
;   if (likely(value)) {
     133:	if r0 == 0x0 goto +0x2 <LBB1_18>
     134:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     135:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000440 <LBB1_18>:
;   assert_boundary(icmp6, pkt->end, false);
     136:	r1 = r7
     137:	r1 += 0x3e
     138:	if r1 > r8 goto -0x63 <LBB1_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     139:	r1 = *(u64 *)(r10 - 0x38)
     140:	r1 = *(u8 *)(r1 + 0x0)
     141:	if w1 != 0x80 goto -0x66 <LBB1_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     142:	r1 = *(u8 *)(r7 + 0x37)
     143:	if w1 != 0x0 goto -0x68 <LBB1_6>
     144:	w1 = 0x3
     145:	*(u32 *)(r10 - 0x4) = r1
     146:	r2 = r10
     147:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     148:	r1 = 0x0 ll
     150:	call 0x1
;   if (likely(value)) {
     151:	if r0 == 0x0 goto +0x2 <LBB1_23>
     152:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     153:	lock *(u32 *)(r0 + 0x0) += r1

00000000000004d0 <LBB1_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     154:	r3 = r7
     155:	r3 += 0x16
     156:	r1 = 0x0
     157:	w2 = 0x0
     158:	w4 = 0x20
     159:	w5 = 0x0
     160:	call 0x1c
     161:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     162:	r3 = *(u16 *)(r7 + 0x12)
     163:	w3 <<= 0x10
;   csum += addend;
     164:	w0 = w3
     165:	w0 += w1
     166:	w1 = 0x1
     167:	w2 = 0x1
;   csum += addend;
     168:	if w0 < w3 goto +0x1 <LBB1_25>
     169:	w2 = 0x0

0000000000000550 <LBB1_25>:
;   return csum + (csum < addend);
     170:	w0 += w2
     171:	r3 = *(u64 *)(r10 - 0x38)
;   return csum + (csum < addend);
     172:	if w0 > -0x3a000001 goto +0x1 <LBB1_27>
     173:	w1 = 0x0

0000000000000570 <LBB1_27>:
;   csum += addend;
     174:	w0 += w1
     175:	w6 = 0x400
;   return csum + (csum < addend);
     176:	w0 += 0x3a000000
     177:	goto +0x4 <LBB1_28>

0000000000000590 <LBB1_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     178:	w1 &= 0xffff
     179:	w6 = w1
     180:	if w1 > 0x4 goto +0x1 <LBB1_28>
     181:	goto +0x11 <LBB1_82>

00000000000005b0 <LBB1_28>:
     182:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     183:	if w6 < 0x200 goto +0x1 <LBB1_30>
     184:	w4 = 0x200

00000000000005c8 <LBB1_30>:
;     if (likely(buf + j <= data_end)) {
     185:	r9 = r3
     186:	r9 += r4
     187:	if r9 > r8 goto +0x5 <LBB1_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     188:	r1 = 0x0
     189:	w2 = 0x0
     190:	w5 = w0
     191:	call 0x1c
     192:	r3 = r9

0000000000000608 <LBB1_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     193:	w1 = w6
     194:	w1 += 0xfe00
     195:	if w6 > 0x200 goto -0x12 <LBB1_34>
     196:	w6 >>= 0x1
     197:	w1 = w6
     198:	goto -0x15 <LBB1_34>

0000000000000638 <LBB1_82>:
;   if (likely(buf + 4 <= data_end)) {
     199:	r1 = r3
     200:	r1 += 0x4
     201:	if r1 > r8 goto +0x9 <LBB1_38>
;     sum = csum_add(sum, *(__be32 *)buf++);
     202:	r4 = *(u32 *)(r3 + 0x0)
;   csum += addend;
     203:	w1 = w4
     204:	w1 += w0
     205:	w2 = 0x1
     206:	if w1 < w4 goto +0x1 <LBB1_37>
     207:	w2 = 0x0

0000000000000680 <LBB1_37>:
;   return csum + (csum < addend);
     208:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     209:	r3 += 0x1
     210:	w0 = w1

0000000000000698 <LBB1_38>:
     211:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     212:	r2 = r3
     213:	r2 += 0x2
     214:	if r2 > r8 goto +0x2 <LBB1_40>
;     addend = *(__be16 *)buf++;
     215:	r1 = *(u16 *)(r3 + 0x0)
     216:	r3 += 0x1

00000000000006c8 <LBB1_40>:
;   if (likely(buf + 1 <= data_end)) {
     217:	r2 = r3
     218:	r2 += 0x1
     219:	if r2 > r8 goto +0x2 <LBB1_42>
;     addend += *(__u8 *)buf++;
     220:	r2 = *(u8 *)(r3 + 0x0)
     221:	w1 += w2

00000000000006f0 <LBB1_42>:
;   csum += addend;
     222:	w2 = w1
     223:	w2 += w0
     224:	w3 = 0x1
     225:	if w2 < w1 goto +0x1 <LBB1_44>
     226:	w3 = 0x0

0000000000000718 <LBB1_44>:
;   return csum + (csum < addend);
     227:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     228:	w1 = w2
     229:	w1 >>= 0x10
     230:	w2 &= 0xffff
     231:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     232:	w1 = w2
     233:	w1 >>= 0x10
     234:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     235:	w1 &= 0xffff
     236:	if w1 != 0xffff goto -0xc5 <LBB1_6>
     237:	w1 = 0x4
     238:	*(u32 *)(r10 - 0x4) = r1
     239:	r2 = r10
     240:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     241:	r1 = 0x0 ll
     243:	call 0x1
;   if (likely(value)) {
     244:	if r0 == 0x0 goto +0x2 <LBB1_47>
     245:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     246:	lock *(u32 *)(r0 + 0x0) += r1

00000000000007b8 <LBB1_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     247:	r1 = *(u64 *)(r7 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     248:	*(u64 *)(r10 - 0x38) = r1
     249:	r9 = *(u64 *)(r7 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     250:	r8 = *(u64 *)(r7 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     251:	r6 = *(u64 *)(r7 + 0x26)
     252:	w1 = 0x7
     253:	*(u32 *)(r10 - 0x20) = r1
     254:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     255:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     256:	r1 = 0x0 ll
     258:	call 0x1
;   if (likely(value)) {
     259:	if r0 == 0x0 goto +0x2 <LBB1_77>
     260:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     261:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000830 <LBB1_77>:
;   bpf_memcpy(&tmp, &old->daddr, sizeof(struct mac_addr));
     262:	r1 = *(u16 *)(r7 + 0x4)
     263:	*(u16 *)(r10 - 0x1c) = r1
     264:	r1 = *(u16 *)(r7 + 0x2)
     265:	w1 <<= 0x10
     266:	r2 = *(u16 *)(r7 + 0x0)
     267:	w1 |= w2
     268:	*(u32 *)(r10 - 0x20) = r1
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     269:	r1 = *(u16 *)(r7 + 0x6)
     270:	*(u16 *)(r7 + 0x0) = r1
     271:	r1 = *(u16 *)(r7 + 0x8)
     272:	*(u16 *)(r7 + 0x2) = r1
     273:	r1 = *(u16 *)(r7 + 0xa)
     274:	*(u16 *)(r7 + 0x4) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     275:	r1 = *(u16 *)(r10 - 0x1c)
     276:	*(u16 *)(r7 + 0xa) = r1
     277:	r1 = *(u32 *)(r10 - 0x20)
     278:	*(u16 *)(r7 + 0x6) = r1
     279:	w1 >>= 0x10
     280:	*(u16 *)(r7 + 0x8) = r1
     281:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     282:	*(u32 *)(r7 + 0xe) = r1
     283:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     284:	*(u16 *)(r7 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     285:	r1 = *(u64 *)(r10 - 0x38)
     286:	*(u64 *)(r7 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     287:	*(u64 *)(r7 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     288:	*(u64 *)(r7 + 0x1e) = r8
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     289:	*(u64 *)(r7 + 0x16) = r6
     290:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     291:	*(u16 *)(r7 + 0x14) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     292:	r1 = *(u16 *)(r7 + 0x38)
     293:	w1 += -0x1
     294:	goto +0x7b <LBB1_78>

0000000000000938 <LBB1_55>:
;       rc_head_adj = bpf_skb_change_head(ctx, (u32)ADJ_LEN, 0);
     295:	w2 = 0x30
     296:	r3 = 0x0
     297:	call 0x2b

0000000000000950 <LBB1_56>:
     298:	r1 = r0
     299:	w0 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     300:	if r1 != 0x0 goto +0x84 <LBB1_81>
     301:	r1 = *(u64 *)(r10 - 0x30)
;     int new_len = ctx->len + pkt.tail_adjust;
     302:	r2 = *(u32 *)(r1 + 0x0)
     303:	w2 += w9
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     304:	r3 = 0x0
     305:	call 0x26
     306:	r1 = r0
     307:	w0 = 0x2
     308:	if r1 != 0x0 goto +0x7c <LBB1_81>
     309:	r1 = *(u64 *)(r10 - 0x30)
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     310:	r8 = *(u32 *)(r1 + 0x50)
     311:	r7 = *(u32 *)(r1 + 0x4c)
;     pkt->ipv6 = next_header(pkt->eth);
     312:	r1 = r7
     313:	r1 += 0xe
;       assert_boundary(pkt.eth, pkt.end, TC_ACT_SHOT);
     314:	if r1 > r8 goto +0x76 <LBB1_81>
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     315:	r1 = *(u16 *)(r10 - 0x16)
     316:	*(u16 *)(r7 + 0x4) = r1
     317:	r1 = *(u16 *)(r10 - 0x18)
     318:	*(u16 *)(r7 + 0x2) = r1
     319:	r1 = *(u16 *)(r10 - 0x1a)
     320:	*(u16 *)(r7 + 0x0) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     321:	r1 = *(u32 *)(r10 - 0x20)
     322:	r2 = *(u16 *)(r10 - 0x1c)
;   new->proto = old->proto;
     323:	*(u16 *)(r7 + 0xc) = r6
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     324:	*(u16 *)(r7 + 0xa) = r2
     325:	*(u16 *)(r7 + 0x6) = r1
     326:	w1 >>= 0x10
     327:	*(u16 *)(r7 + 0x8) = r1
;   assert_boundary(icmp6, pkt->end, false);
     328:	r1 = r7
     329:	r1 += 0x3e
     330:	if r1 > r8 goto +0x66 <LBB1_81>
     331:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     332:	*(u32 *)(r7 + 0xe) = r1
     333:	w1 = 0x3
;   *icmp6                    = icmp6_new;
     334:	*(u32 *)(r7 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     335:	r1 = *(u64 *)(r10 - 0x50)
     336:	*(u64 *)(r7 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     337:	r1 = *(u64 *)(r10 - 0x48)
     338:	*(u64 *)(r7 + 0x26) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     339:	r1 = *(u64 *)(r10 - 0x40)
     340:	*(u64 *)(r7 + 0x1e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     341:	r1 = *(u64 *)(r10 - 0x38)
     342:	*(u64 *)(r7 + 0x16) = r1
     343:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     344:	*(u16 *)(r7 + 0x14) = r1
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     345:	r1 = r7
     346:	r1 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     347:	w2 = w8
     348:	r9 = r1
     349:	w2 -= w1
     350:	r2 = be16 r2
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     351:	*(u16 *)(r7 + 0x12) = r2
     352:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     353:	*(u32 *)(r7 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     354:	r3 = r7
     355:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     356:	r1 = 0x0
     357:	w2 = 0x0
     358:	w4 = 0x20
     359:	w5 = 0x0
     360:	call 0x1c
     361:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     362:	r3 = *(u16 *)(r7 + 0x12)
     363:	w3 <<= 0x10
;   csum += addend;
     364:	w0 = w3
     365:	w0 += w1
     366:	w1 = 0x1
     367:	w2 = 0x1
;   csum += addend;
     368:	if w0 < w3 goto +0x1 <LBB1_62>
     369:	w2 = 0x0

0000000000000b90 <LBB1_62>:
;   return csum + (csum < addend);
     370:	w0 += w2
     371:	if w0 > -0x3a000001 goto +0x1 <LBB1_64>
     372:	w1 = 0x0

0000000000000ba8 <LBB1_64>:
;   csum += addend;
     373:	w0 += w1
     374:	w6 = 0x400
;   return csum + (csum < addend);
     375:	w0 += 0x3a000000
     376:	r3 = r9
     377:	goto +0x4 <LBB1_65>

0000000000000bd0 <LBB1_71>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     378:	w1 &= 0xffff
     379:	w6 = w1
     380:	if w1 > 0x4 goto +0x1 <LBB1_65>
     381:	goto +0x11 <LBB1_83>

0000000000000bf0 <LBB1_65>:
     382:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     383:	if w6 < 0x200 goto +0x1 <LBB1_67>
     384:	w4 = 0x200

0000000000000c08 <LBB1_67>:
;     if (likely(buf + j <= data_end)) {
     385:	r9 = r3
     386:	r9 += r4
     387:	if r9 > r8 goto +0x5 <LBB1_69>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     388:	r1 = 0x0
     389:	w2 = 0x0
     390:	w5 = w0
     391:	call 0x1c
     392:	r3 = r9

0000000000000c48 <LBB1_69>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     393:	w1 = w6
     394:	w1 += 0xfe00
     395:	if w6 > 0x200 goto -0x12 <LBB1_71>
     396:	w6 >>= 0x1
     397:	w1 = w6
     398:	goto -0x15 <LBB1_71>

0000000000000c78 <LBB1_83>:
;   if (likely(buf + 4 <= data_end)) {
     399:	r1 = r3
     400:	r1 += 0x4
     401:	if r1 > r8 goto +0x8 <LBB1_75>
;     sum = csum_add(sum, *(__be32 *)buf++);
     402:	r3 = *(u32 *)(r3 + 0x0)
;   csum += addend;
     403:	w1 = w3
     404:	w1 += w0
     405:	w2 = 0x1
     406:	if w1 < w3 goto +0x1 <LBB1_74>
     407:	w2 = 0x0

0000000000000cc0 <LBB1_74>:
;   return csum + (csum < addend);
     408:	w1 += w2
     409:	w0 = w1

0000000000000cd0 <LBB1_75>:
;   sum = (sum & 0xffff) + (sum >> 16);
     410:	w1 = w0
     411:	w1 >>= 0x10
     412:	w0 &= 0xffff
     413:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     414:	w1 = w0
     415:	w1 >>= 0x10
     416:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     417:	w1 ^= -0x1

0000000000000d10 <LBB1_78>:
     418:	*(u16 *)(r7 + 0x38) = r1
     419:	w1 = 0x8
     420:	*(u32 *)(r10 - 0x4) = r1
     421:	r2 = r10
     422:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     423:	r1 = 0x0 ll
     425:	call 0x1
;   if (likely(value)) {
     426:	if r0 == 0x0 goto +0x2 <LBB1_80>
     427:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     428:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000d68 <LBB1_80>:
;   return bpf_redirect(ctx->ifindex, 0);
     429:	r1 = *(u64 *)(r10 - 0x30)
     430:	r1 = *(u32 *)(r1 + 0x28)
     431:	r2 = 0x0
     432:	call 0x17

0000000000000d88 <LBB1_81>:
;   return exceed2go_tc(ctx, BASE_LAYER_L2);
     433:	exit

0000000000000d90 <exceed2go_tc_l3>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     434:	r8 = *(u32 *)(r1 + 0x50)
     435:	r7 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
     436:	r9 = r7
     437:	r9 += 0x28
     438:	if r9 > r8 goto +0x1e <LBB2_5>
;   assert_equal(pkt->ipv6->version, 6, false);
     439:	r2 = *(u8 *)(r7 + 0x0)
     440:	w2 &= 0xf0
     441:	if w2 != 0x60 goto +0x1b <LBB2_5>
     442:	*(u64 *)(r10 - 0x30) = r1
     443:	w6 = 0x0
     444:	*(u32 *)(r10 - 0x20) = r6
     445:	r2 = r10
     446:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     447:	r1 = 0x0 ll
     449:	call 0x1
;   if (likely(value)) {
     450:	if r0 == 0x0 goto +0x2 <LBB2_4>
     451:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     452:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000e28 <LBB2_4>:
;       .needle = pkt->ipv6->daddr,
     453:	r1 = *(u64 *)(r7 + 0x20)
     454:	*(u64 *)(r10 - 0x18) = r1
     455:	r1 = *(u64 *)(r7 + 0x18)
     456:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
     457:	*(u8 *)(r10 - 0xc) = r6
     458:	*(u32 *)(r10 - 0x10) = r6
     459:	r3 = r10
;       .needle = pkt->ipv6->daddr,
     460:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
     461:	r1 = 0x0 ll
     463:	r2 = 0x0 ll
     465:	r4 = 0x0
     466:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
     467:	r1 = *(u8 *)(r10 - 0xc)
     468:	if w1 != 0x0 goto +0xc <LBB2_6>

0000000000000ea8 <LBB2_5>:
     469:	w1 = 0x5
     470:	*(u32 *)(r10 - 0x20) = r1
     471:	r2 = r10
     472:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     473:	r1 = 0x0 ll
     475:	call 0x1
;   if (likely(value)) {
     476:	if r0 == 0x0 goto +0x2 <LBB2_48>
     477:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     478:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000ef8 <LBB2_48>:
     479:	w0 = -0x1
     480:	goto +0x146 <LBB2_79>

0000000000000f08 <LBB2_6>:
     481:	w6 = 0x1
     482:	*(u32 *)(r10 - 0x4) = r6
     483:	r2 = r10
     484:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     485:	r1 = 0x0 ll
     487:	call 0x1
;   if (likely(value)) {
     488:	if r0 == 0x0 goto +0x1 <LBB2_8>
;     __sync_fetch_and_add(value, 1);
     489:	lock *(u32 *)(r0 + 0x0) += r6

0000000000000f50 <LBB2_8>:
;   __u32 hop_key = pkt->ipv6->hop_limit;
     490:	r1 = *(u8 *)(r7 + 0x7)
     491:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
     492:	r2 = *(u32 *)(r10 - 0x10)
     493:	if w2 <= w1 goto +0x29 <LBB2_14>
     494:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
     495:	r2 += -0x24
     496:	r1 = 0x0 ll
     498:	call 0x1
;     if (exceed_addr != NULL) {
     499:	if r0 == 0x0 goto +0x23 <LBB2_14>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
     500:	w8 -= w7
     501:	w9 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
     502:	w9 -= w8
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
     503:	if w9 s< 0x1 goto +0x4 <LBB2_13>
     504:	w8 &= 0x3
     505:	if w8 == 0x0 goto +0x2 <LBB2_13>
;     tail_adj = -(new_ip_pkt_len % 4);
     506:	w8 = -w8
     507:	w9 = w8

0000000000000fe0 <LBB2_13>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     508:	r1 = *(u64 *)(r7 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     509:	*(u64 *)(r10 - 0x48) = r1
     510:	r1 = *(u64 *)(r7 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     511:	*(u64 *)(r10 - 0x40) = r1
     512:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     513:	*(u64 *)(r10 - 0x38) = r1
     514:	r6 = *(u64 *)(r0 + 0x0)
     515:	w1 = 0x6
     516:	*(u32 *)(r10 - 0x20) = r1
;   return tail_adj < 0 ? tail_adj : 0;
     517:	if w9 s< 0x0 goto +0x1 <LBB2_50>
     518:	w9 = 0x0

0000000000001038 <LBB2_50>:
     519:	r2 = r10
     520:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     521:	r1 = 0x0 ll
     523:	call 0x1
;   if (likely(value)) {
     524:	if r0 == 0x0 goto +0x2 <LBB2_52>
     525:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     526:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001078 <LBB2_52>:
     527:	r1 = *(u64 *)(r10 - 0x30)
;     if (ctx->protocol == bpf_htons(ETH_P_IPV6)) {
     528:	r2 = *(u32 *)(r1 + 0x10)
     529:	if w2 != 0xdd86 goto +0x9c <LBB2_54>
;       rc_head_adj = bpf_skb_adjust_room(ctx,
     530:	w2 = 0x30
     531:	w3 = 0x1
     532:	r4 = 0x1
     533:	call 0x32
     534:	goto +0x9a <LBB2_55>

00000000000010b8 <LBB2_14>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     535:	r1 = *(u8 *)(r7 + 0x6)
     536:	if w1 != 0x3a goto -0x44 <LBB2_5>
     537:	w1 = 0x2
     538:	*(u32 *)(r10 - 0x4) = r1
     539:	r2 = r10
     540:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     541:	r1 = 0x0 ll
     543:	call 0x1
;   if (likely(value)) {
     544:	if r0 == 0x0 goto +0x2 <LBB2_17>
     545:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     546:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001118 <LBB2_17>:
;   assert_boundary(icmp6, pkt->end, false);
     547:	r1 = r7
     548:	r1 += 0x30
     549:	if r1 > r8 goto -0x51 <LBB2_5>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     550:	r1 = *(u8 *)(r9 + 0x0)
     551:	if w1 != 0x80 goto -0x53 <LBB2_5>
;   assert_equal(icmp6->icmp6_code, 0, false);
     552:	r1 = *(u8 *)(r7 + 0x29)
     553:	if w1 != 0x0 goto -0x55 <LBB2_5>
     554:	w1 = 0x3
     555:	*(u32 *)(r10 - 0x4) = r1
     556:	r2 = r10
     557:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     558:	r1 = 0x0 ll
     560:	call 0x1
;   if (likely(value)) {
     561:	if r0 == 0x0 goto +0x2 <LBB2_22>
     562:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     563:	lock *(u32 *)(r0 + 0x0) += r1

00000000000011a0 <LBB2_22>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     564:	r3 = r7
     565:	r3 += 0x8
     566:	r1 = 0x0
     567:	w2 = 0x0
     568:	w4 = 0x20
     569:	w5 = 0x0
     570:	call 0x1c
     571:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     572:	r3 = *(u16 *)(r7 + 0x4)
     573:	w3 <<= 0x10
;   csum += addend;
     574:	w0 = w3
     575:	w0 += w1
     576:	w1 = 0x1
     577:	w2 = 0x1
;   csum += addend;
     578:	if w0 < w3 goto +0x1 <LBB2_24>
     579:	w2 = 0x0

0000000000001220 <LBB2_24>:
;   return csum + (csum < addend);
     580:	w0 += w2
     581:	r3 = r9
;   return csum + (csum < addend);
     582:	if w0 > -0x3a000001 goto +0x1 <LBB2_26>
     583:	w1 = 0x0

0000000000001240 <LBB2_26>:
;   csum += addend;
     584:	w0 += w1
     585:	w9 = 0x400
;   return csum + (csum < addend);
     586:	w0 += 0x3a000000
     587:	goto +0x4 <LBB2_27>

0000000000001260 <LBB2_33>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     588:	w1 &= 0xffff
     589:	w9 = w1
     590:	if w1 > 0x4 goto +0x1 <LBB2_27>
     591:	goto +0x11 <LBB2_80>

0000000000001280 <LBB2_27>:
     592:	w4 = w9
;     __u16 j = (i >= 512) ? 512 : i;
     593:	if w9 < 0x200 goto +0x1 <LBB2_29>
     594:	w4 = 0x200

0000000000001298 <LBB2_29>:
;     if (likely(buf + j <= data_end)) {
     595:	r6 = r3
     596:	r6 += r4
     597:	if r6 > r8 goto +0x5 <LBB2_31>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     598:	r1 = 0x0
     599:	w2 = 0x0
     600:	w5 = w0
     601:	call 0x1c
     602:	r3 = r6

00000000000012d8 <LBB2_31>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     603:	w1 = w9
     604:	w1 += 0xfe00
     605:	if w9 > 0x200 goto -0x12 <LBB2_33>
     606:	w9 >>= 0x1
     607:	w1 = w9
     608:	goto -0x15 <LBB2_33>

0000000000001308 <LBB2_80>:
;   if (likely(buf + 4 <= data_end)) {
     609:	r1 = r3
     610:	r1 += 0x4
     611:	if r1 > r8 goto +0x9 <LBB2_37>
;     sum = csum_add(sum, *(__be32 *)buf++);
     612:	r4 = *(u32 *)(r3 + 0x0)
;   csum += addend;
     613:	w1 = w4
     614:	w1 += w0
     615:	w2 = 0x1
     616:	if w1 < w4 goto +0x1 <LBB2_36>
     617:	w2 = 0x0

0000000000001350 <LBB2_36>:
;   return csum + (csum < addend);
     618:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     619:	r3 += 0x1
     620:	w0 = w1

0000000000001368 <LBB2_37>:
     621:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     622:	r2 = r3
     623:	r2 += 0x2
     624:	if r2 > r8 goto +0x2 <LBB2_39>
;     addend = *(__be16 *)buf++;
     625:	r1 = *(u16 *)(r3 + 0x0)
     626:	r3 += 0x1

0000000000001398 <LBB2_39>:
;   if (likely(buf + 1 <= data_end)) {
     627:	r2 = r3
     628:	r2 += 0x1
     629:	if r2 > r8 goto +0x2 <LBB2_41>
;     addend += *(__u8 *)buf++;
     630:	r2 = *(u8 *)(r3 + 0x0)
     631:	w1 += w2

00000000000013c0 <LBB2_41>:
;   csum += addend;
     632:	w2 = w1
     633:	w2 += w0
     634:	w3 = 0x1
     635:	if w2 < w1 goto +0x1 <LBB2_43>
     636:	w3 = 0x0

00000000000013e8 <LBB2_43>:
;   return csum + (csum < addend);
     637:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     638:	w1 = w2
     639:	w1 >>= 0x10
     640:	w2 &= 0xffff
     641:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     642:	w1 = w2
     643:	w1 >>= 0x10
     644:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     645:	w1 &= 0xffff
     646:	if w1 != 0xffff goto -0xb2 <LBB2_5>
     647:	w1 = 0x4
     648:	*(u32 *)(r10 - 0x4) = r1
     649:	r2 = r10
     650:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     651:	r1 = 0x0 ll
     653:	call 0x1
;   if (likely(value)) {
     654:	if r0 == 0x0 goto +0x2 <LBB2_46>
     655:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     656:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001488 <LBB2_46>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     657:	r1 = *(u64 *)(r7 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     658:	*(u64 *)(r10 - 0x38) = r1
     659:	r6 = *(u64 *)(r7 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     660:	r9 = *(u64 *)(r7 + 0x20)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     661:	r8 = *(u64 *)(r7 + 0x18)
     662:	w1 = 0x7
     663:	*(u32 *)(r10 - 0x20) = r1
     664:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     665:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     666:	r1 = 0x0 ll
     668:	call 0x1
;   if (likely(value)) {
     669:	if r0 == 0x0 goto +0x2 <LBB2_75>
     670:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     671:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001500 <LBB2_75>:
     672:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     673:	*(u32 *)(r7 + 0x0) = r1
     674:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     675:	*(u16 *)(r7 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     676:	r1 = *(u64 *)(r10 - 0x38)
     677:	*(u64 *)(r7 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     678:	*(u64 *)(r7 + 0x18) = r6
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     679:	*(u64 *)(r7 + 0x10) = r9
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     680:	*(u64 *)(r7 + 0x8) = r8
     681:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     682:	*(u16 *)(r7 + 0x6) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     683:	r1 = *(u16 *)(r7 + 0x2a)
     684:	w1 += -0x1
     685:	goto +0x6a <LBB2_76>

0000000000001570 <LBB2_54>:
;       rc_head_adj = bpf_skb_change_head(ctx, (u32)ADJ_LEN, 0);
     686:	w2 = 0x30
     687:	r3 = 0x0
     688:	call 0x2b

0000000000001588 <LBB2_55>:
     689:	r1 = r0
     690:	w0 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     691:	if r1 != 0x0 goto +0x73 <LBB2_79>
     692:	r1 = *(u64 *)(r10 - 0x30)
;     int new_len = ctx->len + pkt.tail_adjust;
     693:	r2 = *(u32 *)(r1 + 0x0)
     694:	w2 += w9
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     695:	r3 = 0x0
     696:	call 0x26
     697:	r1 = r0
     698:	w0 = 0x2
     699:	if r1 != 0x0 goto +0x6b <LBB2_79>
     700:	r1 = *(u64 *)(r10 - 0x30)
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     701:	r8 = *(u32 *)(r1 + 0x50)
     702:	r7 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(icmp6, pkt->end, false);
     703:	r1 = r7
     704:	r1 += 0x30
     705:	if r1 > r8 goto +0x65 <LBB2_79>
     706:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     707:	*(u32 *)(r7 + 0x0) = r1
     708:	w1 = 0x3
;   *icmp6                    = icmp6_new;
     709:	*(u32 *)(r7 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     710:	r1 = *(u64 *)(r10 - 0x48)
     711:	*(u64 *)(r7 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     712:	r1 = *(u64 *)(r10 - 0x40)
     713:	*(u64 *)(r7 + 0x18) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     714:	r1 = *(u64 *)(r10 - 0x38)
     715:	*(u64 *)(r7 + 0x10) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     716:	*(u64 *)(r7 + 0x8) = r6
     717:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     718:	*(u16 *)(r7 + 0x6) = r1
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     719:	r1 = r7
     720:	r1 += 0x28
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     721:	w2 = w8
     722:	*(u64 *)(r10 - 0x38) = r1
     723:	w2 -= w1
     724:	r2 = be16 r2
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     725:	*(u16 *)(r7 + 0x4) = r2
     726:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     727:	*(u32 *)(r7 + 0x2c) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     728:	r3 = r7
     729:	r3 += 0x8
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     730:	r1 = 0x0
     731:	w2 = 0x0
     732:	w4 = 0x20
     733:	w5 = 0x0
     734:	call 0x1c
     735:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     736:	r3 = *(u16 *)(r7 + 0x4)
     737:	w3 <<= 0x10
;   csum += addend;
     738:	w0 = w3
     739:	w0 += w1
     740:	w1 = 0x1
     741:	w2 = 0x1
;   csum += addend;
     742:	if w0 < w3 goto +0x1 <LBB2_60>
     743:	w2 = 0x0

0000000000001740 <LBB2_60>:
;   return csum + (csum < addend);
     744:	w0 += w2
     745:	if w0 > -0x3a000001 goto +0x1 <LBB2_62>
     746:	w1 = 0x0

0000000000001758 <LBB2_62>:
;   csum += addend;
     747:	w0 += w1
     748:	w9 = 0x400
;   return csum + (csum < addend);
     749:	w0 += 0x3a000000
     750:	r3 = *(u64 *)(r10 - 0x38)
     751:	goto +0x4 <LBB2_63>

0000000000001780 <LBB2_69>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     752:	w1 &= 0xffff
     753:	w9 = w1
     754:	if w1 > 0x4 goto +0x1 <LBB2_63>
     755:	goto +0x11 <LBB2_81>

00000000000017a0 <LBB2_63>:
     756:	w4 = w9
;     __u16 j = (i >= 512) ? 512 : i;
     757:	if w9 < 0x200 goto +0x1 <LBB2_65>
     758:	w4 = 0x200

00000000000017b8 <LBB2_65>:
;     if (likely(buf + j <= data_end)) {
     759:	r6 = r3
     760:	r6 += r4
     761:	if r6 > r8 goto +0x5 <LBB2_67>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     762:	r1 = 0x0
     763:	w2 = 0x0
     764:	w5 = w0
     765:	call 0x1c
     766:	r3 = r6

00000000000017f8 <LBB2_67>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     767:	w1 = w9
     768:	w1 += 0xfe00
     769:	if w9 > 0x200 goto -0x12 <LBB2_69>
     770:	w9 >>= 0x1
     771:	w1 = w9
     772:	goto -0x15 <LBB2_69>

0000000000001828 <LBB2_81>:
;   if (likely(buf + 4 <= data_end)) {
     773:	r1 = r3
     774:	r1 += 0x4
     775:	if r1 > r8 goto +0x8 <LBB2_73>
;     sum = csum_add(sum, *(__be32 *)buf++);
     776:	r3 = *(u32 *)(r3 + 0x0)
;   csum += addend;
     777:	w1 = w3
     778:	w1 += w0
     779:	w2 = 0x1
     780:	if w1 < w3 goto +0x1 <LBB2_72>
     781:	w2 = 0x0

0000000000001870 <LBB2_72>:
;   return csum + (csum < addend);
     782:	w1 += w2
     783:	w0 = w1

0000000000001880 <LBB2_73>:
;   sum = (sum & 0xffff) + (sum >> 16);
     784:	w1 = w0
     785:	w1 >>= 0x10
     786:	w0 &= 0xffff
     787:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     788:	w1 = w0
     789:	w1 >>= 0x10
     790:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     791:	w1 ^= -0x1

00000000000018c0 <LBB2_76>:
     792:	*(u16 *)(r7 + 0x2a) = r1
     793:	w1 = 0x8
     794:	*(u32 *)(r10 - 0x20) = r1
     795:	r2 = r10
     796:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     797:	r1 = 0x0 ll
     799:	call 0x1
;   if (likely(value)) {
     800:	if r0 == 0x0 goto +0x2 <LBB2_78>
     801:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     802:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001918 <LBB2_78>:
;   return bpf_redirect(ctx->ifindex, 0);
     803:	r1 = *(u64 *)(r10 - 0x30)
     804:	r1 = *(u32 *)(r1 + 0x28)
     805:	r2 = 0x0
     806:	call 0x17

0000000000001938 <LBB2_79>:
;   return exceed2go_tc(ctx, BASE_LAYER_L3);
     807:	exit
