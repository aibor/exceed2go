
exceed2go_bpfel.o:	file format elf64-bpf

Disassembly of section .text:

0000000000000000 <target_search_cb>:
;                  struct target_search_cb_ctx *cb_ctx) {
       0:	r0 = 0x0
;   if (*key == 0) {
       1:	r1 = *(u32 *)(r2 + 0x0)
       2:	if w1 == 0x0 goto +0xf <LBB3_6>
       3:	r0 = 0x1
;   if (!value || !((const __u32 *)(value))[0])
       4:	if r3 == 0x0 goto +0xd <LBB3_6>
       5:	r2 = *(u32 *)(r3 + 0x0)
       6:	if w2 == 0x0 goto +0xb <LBB3_6>
;   return ((a->in6_u.u6_addr64[0] == b->in6_u.u6_addr64[0]) &&
       7:	r2 = *(u64 *)(r3 + 0x0)
       8:	r5 = *(u64 *)(r4 + 0x0)
       9:	r0 = 0x0
      10:	if r5 != r2 goto +0x7 <LBB3_6>
;           (a->in6_u.u6_addr64[1] == b->in6_u.u6_addr64[1]));
      11:	r2 = *(u64 *)(r3 + 0x8)
      12:	r3 = *(u64 *)(r4 + 0x8)
;   if (in6_addr_equal(&cb_ctx->needle, value)) {
      13:	if r3 != r2 goto +0x4 <LBB3_6>
;     cb_ctx->key   = *key;
      14:	*(u32 *)(r4 + 0x10) = r1
      15:	w1 = 0x1
;     cb_ctx->found = true;
      16:	*(u8 *)(r4 + 0x14) = r1
      17:	r0 = 0x1

0000000000000090 <LBB3_6>:
; }
      18:	exit

Disassembly of section xdp:

0000000000000000 <exceed2go_xdp_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r2 = *(u32 *)(r1 + 0x0)
       1:	r9 = *(u32 *)(r1 + 0x4)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       2:	r8 = r2
       3:	r8 += 0x36
       4:	if r8 > r9 goto +0x24 <LBB0_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       5:	r3 = *(u16 *)(r2 + 0xc)
       6:	if w3 != 0xdd86 goto +0x22 <LBB0_6>
       7:	r6 = r2
       8:	r6 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
       9:	r3 = *(u8 *)(r6 + 0x0)
      10:	w3 &= 0xf0
      11:	if w3 != 0x60 goto +0x1d <LBB0_6>
      12:	*(u64 *)(r10 - 0x38) = r1
      13:	*(u64 *)(r10 - 0x30) = r2
      14:	w7 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r7
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB0_5>
      22:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB0_5>:
      24:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
      25:	r1 = *(u64 *)(r2 + 0x2e)
      26:	*(u64 *)(r10 - 0x18) = r1
      27:	r1 = *(u64 *)(r2 + 0x26)
      28:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      29:	*(u8 *)(r10 - 0xc) = r7
      30:	*(u32 *)(r10 - 0x10) = r7
      31:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      32:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      33:	r1 = 0x0 ll
      35:	r2 = 0x0 ll
      37:	r4 = 0x0
      38:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      39:	r1 = *(u8 *)(r10 - 0xc)
      40:	if w1 != 0x0 goto +0xc <LBB0_7>

0000000000000148 <LBB0_6>:
      41:	w1 = 0x5
      42:	*(u32 *)(r10 - 0x20) = r1
      43:	r2 = r10
      44:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      45:	r1 = 0x0 ll
      47:	call 0x1
;   if (likely(value)) {
      48:	if r0 == 0x0 goto +0x2 <LBB0_49>
      49:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      50:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000198 <LBB0_49>:
      51:	w8 = 0x2
      52:	goto +0x15e <LBB0_77>

00000000000001a8 <LBB0_7>:
      53:	*(u64 *)(r10 - 0x40) = r6
      54:	w6 = 0x1
      55:	*(u32 *)(r10 - 0x4) = r6
      56:	r2 = r10
      57:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      58:	r1 = 0x0 ll
      60:	call 0x1
;   if (likely(value)) {
      61:	if r0 == 0x0 goto +0x1 <LBB0_9>
;     __sync_fetch_and_add(value, 1);
      62:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001f8 <LBB0_9>:
      63:	r7 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
      64:	r1 = *(u8 *)(r7 + 0x15)
      65:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      66:	r2 = *(u32 *)(r10 - 0x10)
      67:	if w2 <= w1 goto +0x84 <LBB0_15>
      68:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      69:	r2 += -0x24
      70:	r1 = 0x0 ll
      72:	call 0x1
;     if (exceed_addr != NULL) {
      73:	if r0 == 0x0 goto +0x7e <LBB0_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      74:	r1 = *(u64 *)(r10 - 0x40)
      75:	w9 -= w1
      76:	w6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      77:	w6 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      78:	if w6 s< 0x1 goto +0x4 <LBB0_14>
      79:	w9 &= 0x3
      80:	if w9 == 0x0 goto +0x2 <LBB0_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      81:	w9 = -w9
      82:	w6 = w9

0000000000000298 <LBB0_14>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      83:	r1 = *(u64 *)(r7 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      84:	*(u64 *)(r10 - 0x40) = r1
      85:	r1 = *(u64 *)(r7 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      86:	*(u64 *)(r10 - 0x50) = r1
      87:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      88:	*(u64 *)(r10 - 0x48) = r1
      89:	r1 = *(u64 *)(r0 + 0x0)
      90:	*(u64 *)(r10 - 0x30) = r1
      91:	w1 = 0x6
      92:	*(u32 *)(r10 - 0x20) = r1
;   return tail_adj < 0 ? tail_adj : 0;
      93:	if w6 s< 0x0 goto +0x1 <LBB0_51>
      94:	w6 = 0x0

00000000000002f8 <LBB0_51>:
      95:	r2 = r10
      96:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      97:	r1 = 0x0 ll
      99:	call 0x1
     100:	r7 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     101:	if r0 == 0x0 goto +0x2 <LBB0_53>
     102:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     103:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000340 <LBB0_53>:
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
     104:	r1 = r7
     105:	w2 = -0x30
     106:	call 0x2c
     107:	w8 = 0x0
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
     108:	if r0 != 0x0 goto +0x126 <LBB0_77>
;     assert_equal(bpf_xdp_adjust_tail(ctx, tail_adj), 0, XDP_ABORTED);
     109:	r1 = r7
     110:	w2 = w6
     111:	call 0x41
     112:	if r0 != 0x0 goto +0x122 <LBB0_77>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     113:	r9 = *(u32 *)(r7 + 0x4)
     114:	r6 = *(u32 *)(r7 + 0x0)
;       assert_boundary(old_eth, pkt.end, XDP_ABORTED);
     115:	r1 = r6
     116:	r1 += 0x3e
     117:	if r1 > r9 goto +0x11d <LBB0_77>
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     118:	r7 = r6
     119:	r7 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     120:	w1 = w9
     121:	w1 -= w7
     122:	w2 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     123:	*(u32 *)(r6 + 0xe) = r2
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     124:	r2 = *(u64 *)(r10 - 0x50)
     125:	*(u64 *)(r6 + 0x26) = r2
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     126:	r2 = *(u64 *)(r10 - 0x48)
     127:	*(u64 *)(r6 + 0x1e) = r2
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     128:	r2 = *(u64 *)(r10 - 0x30)
     129:	*(u64 *)(r6 + 0x16) = r2
     130:	w2 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     131:	*(u16 *)(r6 + 0x14) = r2
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     132:	r2 = *(u16 *)(r6 + 0x38)
     133:	*(u16 *)(r6 + 0x2) = r2
     134:	r2 = *(u16 *)(r6 + 0x36)
     135:	*(u16 *)(r6 + 0x0) = r2
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     136:	r2 = *(u16 *)(r6 + 0x32)
     137:	*(u16 *)(r6 + 0x8) = r2
     138:	r2 = *(u16 *)(r6 + 0x30)
     139:	*(u16 *)(r6 + 0x6) = r2
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     140:	r2 = *(u16 *)(r6 + 0x3a)
     141:	*(u16 *)(r6 + 0x4) = r2
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     142:	r2 = *(u16 *)(r6 + 0x34)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     143:	r3 = *(u64 *)(r10 - 0x40)
     144:	*(u64 *)(r6 + 0x2e) = r3
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     145:	*(u16 *)(r6 + 0xa) = r2
;   new->proto = old->proto;
     146:	r2 = *(u16 *)(r6 + 0x3c)
     147:	*(u16 *)(r6 + 0xc) = r2
     148:	w2 = 0x3
;   *icmp6                    = icmp6_new;
     149:	*(u32 *)(r6 + 0x36) = r2
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     150:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     151:	*(u16 *)(r6 + 0x12) = r1
     152:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     153:	*(u32 *)(r6 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     154:	r3 = r6
     155:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     156:	r1 = 0x0
     157:	w2 = 0x0
     158:	w4 = 0x20
     159:	w5 = 0x0
     160:	call 0x1c
     161:	r1 = r0
     162:	*(u64 *)(r10 - 0x30) = r6
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     163:	r3 = *(u16 *)(r6 + 0x12)
     164:	w3 <<= 0x10
;   csum += addend;
     165:	w0 = w3
     166:	w0 += w1
     167:	w1 = 0x1
     168:	w2 = 0x1
;   csum += addend;
     169:	if w0 < w3 goto +0x1 <LBB0_58>
     170:	w2 = 0x0

0000000000000558 <LBB0_58>:
;   return csum + (csum < addend);
     171:	w0 += w2
     172:	if w0 > -0x3a000001 goto +0x1 <LBB0_60>
     173:	w1 = 0x0

0000000000000570 <LBB0_60>:
;   csum += addend;
     174:	w0 += w1
     175:	w8 = 0x400
;   return csum + (csum < addend);
     176:	w0 += 0x3a000000
     177:	goto +0x4 <LBB0_61>

0000000000000590 <LBB0_67>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     178:	w1 &= 0xffff
     179:	w8 = w1
     180:	if w1 > 0x4 goto +0x1 <LBB0_61>
     181:	goto +0xbd <LBB0_79>

00000000000005b0 <LBB0_61>:
     182:	w4 = w8
;     __u16 j = (i >= 512) ? 512 : i;
     183:	if w8 < 0x200 goto +0x1 <LBB0_63>
     184:	w4 = 0x200

00000000000005c8 <LBB0_63>:
;     if (likely(buf + j <= data_end)) {
     185:	r6 = r7
     186:	r6 += r4
     187:	if r6 > r9 goto +0x6 <LBB0_65>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     188:	r1 = 0x0
     189:	w2 = 0x0
     190:	r3 = r7
     191:	w5 = w0
     192:	call 0x1c
     193:	r7 = r6

0000000000000610 <LBB0_65>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     194:	w1 = w8
     195:	w1 += 0xfe00
     196:	if w8 > 0x200 goto -0x13 <LBB0_67>
     197:	w8 >>= 0x1
     198:	w1 = w8
     199:	goto -0x16 <LBB0_67>

0000000000000640 <LBB0_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     200:	r1 = *(u8 *)(r7 + 0x14)
     201:	if w1 != 0x3a goto -0xa1 <LBB0_6>
     202:	w1 = 0x2
     203:	*(u32 *)(r10 - 0x4) = r1
     204:	r2 = r10
     205:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     206:	r1 = 0x0 ll
     208:	call 0x1
;   if (likely(value)) {
     209:	if r0 == 0x0 goto +0x2 <LBB0_18>
     210:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     211:	lock *(u32 *)(r0 + 0x0) += r1

00000000000006a0 <LBB0_18>:
;   assert_boundary(icmp6, pkt->end, false);
     212:	r1 = r7
     213:	r1 += 0x3e
     214:	if r1 > r9 goto -0xae <LBB0_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     215:	r1 = *(u8 *)(r8 + 0x0)
     216:	if w1 != 0x80 goto -0xb0 <LBB0_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     217:	r1 = *(u8 *)(r7 + 0x37)
     218:	if w1 != 0x0 goto -0xb2 <LBB0_6>
     219:	w1 = 0x3
     220:	*(u32 *)(r10 - 0x4) = r1
     221:	r2 = r10
     222:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     223:	r1 = 0x0 ll
     225:	call 0x1
;   if (likely(value)) {
     226:	if r0 == 0x0 goto +0x2 <LBB0_23>
     227:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     228:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000728 <LBB0_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     229:	r3 = r7
     230:	r3 += 0x16
     231:	r1 = 0x0
     232:	w2 = 0x0
     233:	w4 = 0x20
     234:	w5 = 0x0
     235:	call 0x1c
     236:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     237:	r3 = *(u16 *)(r7 + 0x12)
     238:	w3 <<= 0x10
;   csum += addend;
     239:	w0 = w3
     240:	w0 += w1
     241:	w1 = 0x1
     242:	w2 = 0x1
;   csum += addend;
     243:	if w0 < w3 goto +0x1 <LBB0_25>
     244:	w2 = 0x0

00000000000007a8 <LBB0_25>:
;   return csum + (csum < addend);
     245:	w0 += w2
     246:	if w0 > -0x3a000001 goto +0x1 <LBB0_27>
     247:	w1 = 0x0

00000000000007c0 <LBB0_27>:
;   csum += addend;
     248:	w0 += w1
     249:	w7 = 0x400
;   return csum + (csum < addend);
     250:	w0 += 0x3a000000
     251:	goto +0x4 <LBB0_28>

00000000000007e0 <LBB0_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     252:	w1 &= 0xffff
     253:	w7 = w1
     254:	if w1 > 0x4 goto +0x1 <LBB0_28>
     255:	goto +0x12 <LBB0_78>

0000000000000800 <LBB0_28>:
     256:	w4 = w7
;     __u16 j = (i >= 512) ? 512 : i;
     257:	if w7 < 0x200 goto +0x1 <LBB0_30>
     258:	w4 = 0x200

0000000000000818 <LBB0_30>:
;     if (likely(buf + j <= data_end)) {
     259:	r6 = r8
     260:	r6 += r4
     261:	if r6 > r9 goto +0x6 <LBB0_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     262:	r1 = 0x0
     263:	w2 = 0x0
     264:	r3 = r8
     265:	w5 = w0
     266:	call 0x1c
     267:	r8 = r6

0000000000000860 <LBB0_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     268:	w1 = w7
     269:	w1 += 0xfe00
     270:	if w7 > 0x200 goto -0x13 <LBB0_34>
     271:	w7 >>= 0x1
     272:	w1 = w7
     273:	goto -0x16 <LBB0_34>

0000000000000890 <LBB0_78>:
;   if (likely(buf + 4 <= data_end)) {
     274:	r1 = r8
     275:	r1 += 0x4
     276:	r6 = *(u64 *)(r10 - 0x30)
     277:	if r1 > r9 goto +0x9 <LBB0_38>
;     sum = csum_add(sum, *(__be32 *)buf++);
     278:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     279:	w1 = w3
     280:	w1 += w0
     281:	w2 = 0x1
     282:	if w1 < w3 goto +0x1 <LBB0_37>
     283:	w2 = 0x0

00000000000008e0 <LBB0_37>:
;   return csum + (csum < addend);
     284:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     285:	r8 += 0x1
     286:	w0 = w1

00000000000008f8 <LBB0_38>:
     287:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     288:	r2 = r8
     289:	r2 += 0x2
     290:	if r2 > r9 goto +0x2 <LBB0_40>
;     addend = *(__be16 *)buf++;
     291:	r1 = *(u16 *)(r8 + 0x0)
     292:	r8 += 0x1

0000000000000928 <LBB0_40>:
;   if (likely(buf + 1 <= data_end)) {
     293:	r2 = r8
     294:	r2 += 0x1
     295:	if r2 > r9 goto +0x2 <LBB0_42>
;     addend += *(__u8 *)buf++;
     296:	r2 = *(u8 *)(r8 + 0x0)
     297:	w1 += w2

0000000000000950 <LBB0_42>:
;   csum += addend;
     298:	w2 = w1
     299:	w2 += w0
     300:	w3 = 0x1
     301:	if w2 < w1 goto +0x1 <LBB0_44>
     302:	w3 = 0x0

0000000000000978 <LBB0_44>:
;   return csum + (csum < addend);
     303:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     304:	w1 = w2
     305:	w1 >>= 0x10
     306:	w2 &= 0xffff
     307:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     308:	w1 = w2
     309:	w1 >>= 0x10
     310:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     311:	w1 &= 0xffff
     312:	if w1 != 0xffff goto -0x110 <LBB0_6>
     313:	w1 = 0x4
     314:	*(u32 *)(r10 - 0x4) = r1
     315:	r2 = r10
     316:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     317:	r1 = 0x0 ll
     319:	call 0x1
;   if (likely(value)) {
     320:	if r0 == 0x0 goto +0x2 <LBB0_47>
     321:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     322:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000a18 <LBB0_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     323:	r8 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     324:	r9 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     325:	r7 = *(u64 *)(r6 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     326:	r6 = *(u64 *)(r6 + 0x26)
     327:	w1 = 0x7
     328:	*(u32 *)(r10 - 0x20) = r1
     329:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     330:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     331:	r1 = 0x0 ll
     333:	call 0x1
;   if (likely(value)) {
     334:	if r0 == 0x0 goto +0x2 <LBB0_73>
     335:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     336:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000a88 <LBB0_73>:
     337:	r3 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(&tmp, &old->daddr, sizeof(struct mac_addr));
     338:	r1 = *(u16 *)(r3 + 0x4)
     339:	*(u16 *)(r10 - 0x1c) = r1
     340:	r1 = *(u16 *)(r3 + 0x2)
     341:	w1 <<= 0x10
     342:	r2 = *(u16 *)(r3 + 0x0)
     343:	w1 |= w2
     344:	*(u32 *)(r10 - 0x20) = r1
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     345:	r1 = *(u16 *)(r3 + 0x6)
     346:	*(u16 *)(r3 + 0x0) = r1
     347:	r1 = *(u16 *)(r3 + 0x8)
     348:	*(u16 *)(r3 + 0x2) = r1
     349:	r1 = *(u16 *)(r3 + 0xa)
     350:	*(u16 *)(r3 + 0x4) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     351:	r1 = *(u16 *)(r10 - 0x1c)
     352:	*(u16 *)(r3 + 0xa) = r1
     353:	r1 = *(u32 *)(r10 - 0x20)
     354:	*(u16 *)(r3 + 0x6) = r1
     355:	w1 >>= 0x10
     356:	*(u16 *)(r3 + 0x8) = r1
     357:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     358:	*(u32 *)(r3 + 0xe) = r1
     359:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     360:	*(u16 *)(r3 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     361:	*(u64 *)(r3 + 0x2e) = r8
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     362:	*(u64 *)(r3 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     363:	*(u64 *)(r3 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     364:	*(u64 *)(r3 + 0x16) = r6
     365:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     366:	*(u16 *)(r3 + 0x14) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     367:	r1 = *(u16 *)(r3 + 0x38)
     368:	w1 += -0x1
     369:	*(u16 *)(r3 + 0x38) = r1
     370:	goto +0x15 <LBB0_74>

0000000000000b98 <LBB0_79>:
;   if (likely(buf + 4 <= data_end)) {
     371:	r1 = r7
     372:	r1 += 0x4
     373:	if r1 > r9 goto +0x8 <LBB0_71>
;     sum = csum_add(sum, *(__be32 *)buf++);
     374:	r3 = *(u32 *)(r7 + 0x0)
;   csum += addend;
     375:	w1 = w3
     376:	w1 += w0
     377:	w2 = 0x1
     378:	if w1 < w3 goto +0x1 <LBB0_70>
     379:	w2 = 0x0

0000000000000be0 <LBB0_70>:
;   return csum + (csum < addend);
     380:	w1 += w2
     381:	w0 = w1

0000000000000bf0 <LBB0_71>:
;   sum = (sum & 0xffff) + (sum >> 16);
     382:	w1 = w0
     383:	w1 >>= 0x10
     384:	w0 &= 0xffff
     385:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     386:	w1 = w0
     387:	w1 >>= 0x10
     388:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     389:	w1 ^= -0x1
     390:	r2 = *(u64 *)(r10 - 0x30)
     391:	*(u16 *)(r2 + 0x38) = r1

0000000000000c40 <LBB0_74>:
     392:	w1 = 0x8
     393:	*(u32 *)(r10 - 0x20) = r1
     394:	r2 = r10
     395:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     396:	r1 = 0x0 ll
     398:	call 0x1
;   if (likely(value)) {
     399:	if r0 == 0x0 goto +0x2 <LBB0_76>
     400:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     401:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000c90 <LBB0_76>:
     402:	w8 = 0x3

0000000000000c98 <LBB0_77>:
;   return exceed2go_xdp(ctx, BASE_LAYER_L2);
     403:	w0 = w8
     404:	exit

Disassembly of section tc:

0000000000000000 <exceed2go_tc_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r9 = *(u32 *)(r1 + 0x50)
       1:	*(u64 *)(r10 - 0x38) = r1
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       2:	r2 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       3:	r8 = r2
       4:	r8 += 0x36
       5:	if r8 > r9 goto +0x23 <LBB1_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       6:	r1 = *(u16 *)(r2 + 0xc)
       7:	if w1 != 0xdd86 goto +0x21 <LBB1_6>
       8:	r7 = r2
       9:	r7 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
      10:	r1 = *(u8 *)(r7 + 0x0)
      11:	w1 &= 0xf0
      12:	if w1 != 0x60 goto +0x1c <LBB1_6>
      13:	*(u64 *)(r10 - 0x30) = r2
      14:	w6 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r6
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB1_5>
      22:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB1_5>:
      24:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
      25:	r1 = *(u64 *)(r2 + 0x2e)
      26:	*(u64 *)(r10 - 0x18) = r1
      27:	r1 = *(u64 *)(r2 + 0x26)
      28:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      29:	*(u8 *)(r10 - 0xc) = r6
      30:	*(u32 *)(r10 - 0x10) = r6
      31:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      32:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      33:	r1 = 0x0 ll
      35:	r2 = 0x0 ll
      37:	r4 = 0x0
      38:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      39:	r1 = *(u8 *)(r10 - 0xc)
      40:	if w1 != 0x0 goto +0xc <LBB1_7>

0000000000000148 <LBB1_6>:
      41:	w1 = 0x5
      42:	*(u32 *)(r10 - 0x20) = r1
      43:	r2 = r10
      44:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      45:	r1 = 0x0 ll
      47:	call 0x1
;   if (likely(value)) {
      48:	if r0 == 0x0 goto +0x2 <LBB1_49>
      49:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      50:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000198 <LBB1_49>:
      51:	w7 = -0x1
      52:	goto +0x17e <LBB1_78>

00000000000001a8 <LBB1_7>:
      53:	w6 = 0x1
      54:	*(u32 *)(r10 - 0x4) = r6
      55:	r2 = r10
      56:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      57:	r1 = 0x0 ll
      59:	call 0x1
;   if (likely(value)) {
      60:	if r0 == 0x0 goto +0x1 <LBB1_9>
;     __sync_fetch_and_add(value, 1);
      61:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001f0 <LBB1_9>:
      62:	r6 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
      63:	r1 = *(u8 *)(r6 + 0x15)
      64:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      65:	r2 = *(u32 *)(r10 - 0x10)
      66:	if w2 <= w1 goto +0x9e <LBB1_15>
      67:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      68:	r2 += -0x24
      69:	r1 = 0x0 ll
      71:	call 0x1
;     if (exceed_addr != NULL) {
      72:	if r0 == 0x0 goto +0x98 <LBB1_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      73:	w9 -= w7
      74:	w6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      75:	w6 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      76:	if w6 s< 0x1 goto +0x4 <LBB1_14>
      77:	w9 &= 0x3
      78:	if w9 == 0x0 goto +0x2 <LBB1_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      79:	w9 = -w9
      80:	w6 = w9

0000000000000288 <LBB1_14>:
      81:	r1 = *(u64 *)(r10 - 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      82:	r2 = *(u64 *)(r1 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      83:	*(u64 *)(r10 - 0x58) = r2
      84:	r1 = *(u64 *)(r1 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      85:	*(u64 *)(r10 - 0x50) = r1
      86:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      87:	*(u64 *)(r10 - 0x48) = r1
      88:	r1 = *(u64 *)(r0 + 0x0)
      89:	*(u64 *)(r10 - 0x40) = r1
      90:	w1 = 0x6
      91:	*(u32 *)(r10 - 0x20) = r1
      92:	r8 = *(u64 *)(r10 - 0x38)
;   return tail_adj < 0 ? tail_adj : 0;
      93:	if w6 s< 0x0 goto +0x1 <LBB1_51>
      94:	w6 = 0x0

00000000000002f8 <LBB1_51>:
      95:	r2 = r10
      96:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      97:	r1 = 0x0 ll
      99:	call 0x1
;   if (likely(value)) {
     100:	if r0 == 0x0 goto +0x2 <LBB1_53>
     101:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     102:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000338 <LBB1_53>:
     103:	r4 = *(u64 *)(r10 - 0x30)
;       bpf_memcpy(&eth, pkt.eth, sizeof(struct ethhdr));
     104:	r1 = *(u16 *)(r4 + 0xa)
     105:	w1 <<= 0x10
     106:	r2 = *(u16 *)(r4 + 0x8)
     107:	w1 |= w2
     108:	*(u32 *)(r10 - 0x18) = r1
     109:	r1 = *(u16 *)(r4 + 0x0)
     110:	r2 = *(u16 *)(r4 + 0x2)
     111:	r2 <<= 0x10
     112:	r2 |= r1
     113:	r1 = *(u16 *)(r4 + 0x6)
     114:	w1 <<= 0x10
     115:	r3 = *(u16 *)(r4 + 0x4)
     116:	w1 |= w3
     117:	r1 <<= 0x20
     118:	r1 |= r2
     119:	*(u64 *)(r10 - 0x20) = r1
     120:	r1 = *(u16 *)(r4 + 0xc)
;     long rc_head_adj = bpf_skb_adjust_room(ctx,
     121:	*(u32 *)(r10 - 0x30) = r1
     122:	r1 = r8
     123:	w2 = 0x30
     124:	w3 = 0x1
     125:	r4 = 0x1
     126:	call 0x32
     127:	w7 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     128:	if r0 != 0x0 goto +0x132 <LBB1_78>
;     int new_len = ctx->len + pkt.tail_adjust;
     129:	r2 = *(u32 *)(r8 + 0x0)
     130:	w2 += w6
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     131:	r1 = r8
     132:	r3 = 0x0
     133:	call 0x26
     134:	if r0 != 0x0 goto +0x12c <LBB1_78>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     135:	r9 = *(u32 *)(r8 + 0x50)
     136:	r6 = *(u32 *)(r8 + 0x4c)
;       assert_boundary(pkt.eth, pkt.end, TC_ACT_SHOT);
     137:	r1 = r6
     138:	r1 += 0xe
     139:	if r1 > r9 goto +0x127 <LBB1_78>
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     140:	r1 = *(u16 *)(r10 - 0x16)
     141:	*(u16 *)(r6 + 0x4) = r1
     142:	r1 = *(u16 *)(r10 - 0x18)
     143:	*(u16 *)(r6 + 0x2) = r1
     144:	r1 = *(u16 *)(r10 - 0x1a)
     145:	*(u16 *)(r6 + 0x0) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     146:	r1 = *(u32 *)(r10 - 0x20)
     147:	r2 = *(u16 *)(r10 - 0x1c)
;   new->proto = old->proto;
     148:	r3 = *(u32 *)(r10 - 0x30)
     149:	*(u16 *)(r6 + 0xc) = r3
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     150:	*(u16 *)(r6 + 0xa) = r2
     151:	*(u16 *)(r6 + 0x6) = r1
     152:	w1 >>= 0x10
     153:	*(u16 *)(r6 + 0x8) = r1
;   assert_boundary(icmp6, pkt->end, false);
     154:	r1 = r6
     155:	r1 += 0x3e
     156:	if r1 > r9 goto +0x116 <LBB1_78>
     157:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     158:	*(u32 *)(r6 + 0xe) = r1
     159:	w1 = 0x3
;   *icmp6                    = icmp6_new;
     160:	*(u32 *)(r6 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     161:	r1 = *(u64 *)(r10 - 0x58)
     162:	*(u64 *)(r6 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     163:	r1 = *(u64 *)(r10 - 0x50)
     164:	*(u64 *)(r6 + 0x26) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     165:	r1 = *(u64 *)(r10 - 0x48)
     166:	*(u64 *)(r6 + 0x1e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     167:	r1 = *(u64 *)(r10 - 0x40)
     168:	*(u64 *)(r6 + 0x16) = r1
     169:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     170:	*(u16 *)(r6 + 0x14) = r1
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     171:	r8 = r6
     172:	r8 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     173:	w1 = w9
     174:	w1 -= w8
     175:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     176:	*(u16 *)(r6 + 0x12) = r1
     177:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     178:	*(u32 *)(r6 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     179:	r3 = r6
     180:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     181:	r1 = 0x0
     182:	w2 = 0x0
     183:	w4 = 0x20
     184:	w5 = 0x0
     185:	call 0x1c
     186:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     187:	r3 = *(u16 *)(r6 + 0x12)
     188:	w3 <<= 0x10
;   csum += addend;
     189:	w0 = w3
     190:	w0 += w1
     191:	w1 = 0x1
     192:	w2 = 0x1
;   csum += addend;
     193:	if w0 < w3 goto +0x1 <LBB1_59>
     194:	w2 = 0x0

0000000000000618 <LBB1_59>:
     195:	*(u64 *)(r10 - 0x30) = r6
;   return csum + (csum < addend);
     196:	w0 += w2
     197:	if w0 > -0x3a000001 goto +0x1 <LBB1_61>
     198:	w1 = 0x0

0000000000000638 <LBB1_61>:
;   csum += addend;
     199:	w0 += w1
     200:	w6 = 0x400
;   return csum + (csum < addend);
     201:	w0 += 0x3a000000
     202:	goto +0x4 <LBB1_62>

0000000000000658 <LBB1_68>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     203:	w1 &= 0xffff
     204:	w6 = w1
     205:	if w1 > 0x4 goto +0x1 <LBB1_62>
     206:	goto +0xc0 <LBB1_80>

0000000000000678 <LBB1_62>:
     207:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     208:	if w6 < 0x200 goto +0x1 <LBB1_64>
     209:	w4 = 0x200

0000000000000690 <LBB1_64>:
;     if (likely(buf + j <= data_end)) {
     210:	r7 = r8
     211:	r7 += r4
     212:	if r7 > r9 goto +0x6 <LBB1_66>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     213:	r1 = 0x0
     214:	w2 = 0x0
     215:	r3 = r8
     216:	w5 = w0
     217:	call 0x1c
     218:	r8 = r7

00000000000006d8 <LBB1_66>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     219:	w1 = w6
     220:	w1 += 0xfe00
     221:	if w6 > 0x200 goto -0x13 <LBB1_68>
     222:	w6 >>= 0x1
     223:	w1 = w6
     224:	goto -0x16 <LBB1_68>

0000000000000708 <LBB1_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     225:	r1 = *(u8 *)(r6 + 0x14)
     226:	if w1 != 0x3a goto -0xba <LBB1_6>
     227:	w1 = 0x2
     228:	*(u32 *)(r10 - 0x4) = r1
     229:	r2 = r10
     230:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     231:	r1 = 0x0 ll
     233:	call 0x1
;   if (likely(value)) {
     234:	if r0 == 0x0 goto +0x2 <LBB1_18>
     235:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     236:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000768 <LBB1_18>:
;   assert_boundary(icmp6, pkt->end, false);
     237:	r1 = r6
     238:	r1 += 0x3e
     239:	if r1 > r9 goto -0xc7 <LBB1_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     240:	r1 = *(u8 *)(r8 + 0x0)
     241:	if w1 != 0x80 goto -0xc9 <LBB1_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     242:	r1 = *(u8 *)(r6 + 0x37)
     243:	if w1 != 0x0 goto -0xcb <LBB1_6>
     244:	w1 = 0x3
     245:	*(u32 *)(r10 - 0x4) = r1
     246:	r2 = r10
     247:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     248:	r1 = 0x0 ll
     250:	call 0x1
;   if (likely(value)) {
     251:	if r0 == 0x0 goto +0x2 <LBB1_23>
     252:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     253:	lock *(u32 *)(r0 + 0x0) += r1

00000000000007f0 <LBB1_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     254:	r3 = r6
     255:	r3 += 0x16
     256:	r1 = 0x0
     257:	w2 = 0x0
     258:	w4 = 0x20
     259:	w5 = 0x0
     260:	call 0x1c
     261:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     262:	r3 = *(u16 *)(r6 + 0x12)
     263:	w3 <<= 0x10
;   csum += addend;
     264:	w0 = w3
     265:	w0 += w1
     266:	w1 = 0x1
     267:	w2 = 0x1
;   csum += addend;
     268:	if w0 < w3 goto +0x1 <LBB1_25>
     269:	w2 = 0x0

0000000000000870 <LBB1_25>:
;   return csum + (csum < addend);
     270:	w0 += w2
     271:	if w0 > -0x3a000001 goto +0x1 <LBB1_27>
     272:	w1 = 0x0

0000000000000888 <LBB1_27>:
;   csum += addend;
     273:	w0 += w1
     274:	w6 = 0x400
;   return csum + (csum < addend);
     275:	w0 += 0x3a000000
     276:	goto +0x4 <LBB1_28>

00000000000008a8 <LBB1_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     277:	w1 &= 0xffff
     278:	w6 = w1
     279:	if w1 > 0x4 goto +0x1 <LBB1_28>
     280:	goto +0x12 <LBB1_79>

00000000000008c8 <LBB1_28>:
     281:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     282:	if w6 < 0x200 goto +0x1 <LBB1_30>
     283:	w4 = 0x200

00000000000008e0 <LBB1_30>:
;     if (likely(buf + j <= data_end)) {
     284:	r7 = r8
     285:	r7 += r4
     286:	if r7 > r9 goto +0x6 <LBB1_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     287:	r1 = 0x0
     288:	w2 = 0x0
     289:	r3 = r8
     290:	w5 = w0
     291:	call 0x1c
     292:	r8 = r7

0000000000000928 <LBB1_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     293:	w1 = w6
     294:	w1 += 0xfe00
     295:	if w6 > 0x200 goto -0x13 <LBB1_34>
     296:	w6 >>= 0x1
     297:	w1 = w6
     298:	goto -0x16 <LBB1_34>

0000000000000958 <LBB1_79>:
;   if (likely(buf + 4 <= data_end)) {
     299:	r1 = r8
     300:	r1 += 0x4
     301:	r6 = *(u64 *)(r10 - 0x30)
     302:	if r1 > r9 goto +0x9 <LBB1_38>
;     sum = csum_add(sum, *(__be32 *)buf++);
     303:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     304:	w1 = w3
     305:	w1 += w0
     306:	w2 = 0x1
     307:	if w1 < w3 goto +0x1 <LBB1_37>
     308:	w2 = 0x0

00000000000009a8 <LBB1_37>:
;   return csum + (csum < addend);
     309:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     310:	r8 += 0x1
     311:	w0 = w1

00000000000009c0 <LBB1_38>:
     312:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     313:	r2 = r8
     314:	r2 += 0x2
     315:	if r2 > r9 goto +0x2 <LBB1_40>
;     addend = *(__be16 *)buf++;
     316:	r1 = *(u16 *)(r8 + 0x0)
     317:	r8 += 0x1

00000000000009f0 <LBB1_40>:
;   if (likely(buf + 1 <= data_end)) {
     318:	r2 = r8
     319:	r2 += 0x1
     320:	if r2 > r9 goto +0x2 <LBB1_42>
;     addend += *(__u8 *)buf++;
     321:	r2 = *(u8 *)(r8 + 0x0)
     322:	w1 += w2

0000000000000a18 <LBB1_42>:
;   csum += addend;
     323:	w2 = w1
     324:	w2 += w0
     325:	w3 = 0x1
     326:	if w2 < w1 goto +0x1 <LBB1_44>
     327:	w3 = 0x0

0000000000000a40 <LBB1_44>:
;   return csum + (csum < addend);
     328:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     329:	w1 = w2
     330:	w1 >>= 0x10
     331:	w2 &= 0xffff
     332:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     333:	w1 = w2
     334:	w1 >>= 0x10
     335:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     336:	w1 &= 0xffff
     337:	if w1 != 0xffff goto -0x129 <LBB1_6>
     338:	w1 = 0x4
     339:	*(u32 *)(r10 - 0x4) = r1
     340:	r2 = r10
     341:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     342:	r1 = 0x0 ll
     344:	call 0x1
     345:	r8 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     346:	if r0 == 0x0 goto +0x2 <LBB1_47>
     347:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     348:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000ae8 <LBB1_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     349:	r1 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     350:	*(u64 *)(r10 - 0x40) = r1
     351:	r9 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     352:	r7 = *(u64 *)(r6 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     353:	r6 = *(u64 *)(r6 + 0x26)
     354:	w1 = 0x7
     355:	*(u32 *)(r10 - 0x20) = r1
     356:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     357:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     358:	r1 = 0x0 ll
     360:	call 0x1
;   if (likely(value)) {
     361:	if r0 == 0x0 goto +0x2 <LBB1_74>
     362:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     363:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000b60 <LBB1_74>:
     364:	r3 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(&tmp, &old->daddr, sizeof(struct mac_addr));
     365:	r1 = *(u16 *)(r3 + 0x4)
     366:	*(u16 *)(r10 - 0x1c) = r1
     367:	r1 = *(u16 *)(r3 + 0x2)
     368:	w1 <<= 0x10
     369:	r2 = *(u16 *)(r3 + 0x0)
     370:	w1 |= w2
     371:	*(u32 *)(r10 - 0x20) = r1
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     372:	r1 = *(u16 *)(r3 + 0x6)
     373:	*(u16 *)(r3 + 0x0) = r1
     374:	r1 = *(u16 *)(r3 + 0x8)
     375:	*(u16 *)(r3 + 0x2) = r1
     376:	r1 = *(u16 *)(r3 + 0xa)
     377:	*(u16 *)(r3 + 0x4) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     378:	r1 = *(u16 *)(r10 - 0x1c)
     379:	*(u16 *)(r3 + 0xa) = r1
     380:	r1 = *(u32 *)(r10 - 0x20)
     381:	*(u16 *)(r3 + 0x6) = r1
     382:	w1 >>= 0x10
     383:	*(u16 *)(r3 + 0x8) = r1
     384:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     385:	*(u32 *)(r3 + 0xe) = r1
     386:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     387:	*(u16 *)(r3 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     388:	r1 = *(u64 *)(r10 - 0x40)
     389:	*(u64 *)(r3 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     390:	*(u64 *)(r3 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     391:	*(u64 *)(r3 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     392:	*(u64 *)(r3 + 0x16) = r6
     393:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     394:	*(u16 *)(r3 + 0x14) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     395:	r1 = *(u16 *)(r3 + 0x38)
     396:	w1 += -0x1
     397:	*(u16 *)(r3 + 0x38) = r1
     398:	goto +0x16 <LBB1_75>

0000000000000c78 <LBB1_80>:
;   if (likely(buf + 4 <= data_end)) {
     399:	r1 = r8
     400:	r1 += 0x4
     401:	r4 = *(u64 *)(r10 - 0x30)
     402:	if r1 > r9 goto +0x8 <LBB1_72>
;     sum = csum_add(sum, *(__be32 *)buf++);
     403:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     404:	w1 = w3
     405:	w1 += w0
     406:	w2 = 0x1
     407:	if w1 < w3 goto +0x1 <LBB1_71>
     408:	w2 = 0x0

0000000000000cc8 <LBB1_71>:
;   return csum + (csum < addend);
     409:	w1 += w2
     410:	w0 = w1

0000000000000cd8 <LBB1_72>:
;   sum = (sum & 0xffff) + (sum >> 16);
     411:	w1 = w0
     412:	w1 >>= 0x10
     413:	w0 &= 0xffff
     414:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     415:	w1 = w0
     416:	w1 >>= 0x10
     417:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     418:	w1 ^= -0x1
     419:	*(u16 *)(r4 + 0x38) = r1
     420:	r8 = *(u64 *)(r10 - 0x38)

0000000000000d28 <LBB1_75>:
     421:	w1 = 0x8
     422:	*(u32 *)(r10 - 0x4) = r1
     423:	r2 = r10
     424:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     425:	r1 = 0x0 ll
     427:	call 0x1
;   if (likely(value)) {
     428:	if r0 == 0x0 goto +0x2 <LBB1_77>
     429:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     430:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000d78 <LBB1_77>:
;   return bpf_redirect(ctx->ifindex, 0);
     431:	r1 = *(u32 *)(r8 + 0x28)
     432:	r2 = 0x0
     433:	call 0x17
     434:	r7 = r0

0000000000000d98 <LBB1_78>:
;   return exceed2go_tc(ctx, BASE_LAYER_L2);
     435:	w0 = w7
     436:	exit

0000000000000da8 <exceed2go_tc_l3>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     437:	r9 = *(u32 *)(r1 + 0x50)
     438:	*(u64 *)(r10 - 0x38) = r1
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     439:	r2 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
     440:	r8 = r2
     441:	r8 += 0x28
     442:	if r8 > r9 goto +0x1f <LBB2_5>
;   assert_equal(pkt->ipv6->version, 6, false);
     443:	r1 = *(u8 *)(r2 + 0x0)
     444:	w1 &= 0xf0
     445:	if w1 != 0x60 goto +0x1c <LBB2_5>
     446:	*(u64 *)(r10 - 0x30) = r2
     447:	w6 = 0x0
     448:	*(u32 *)(r10 - 0x20) = r6
     449:	r2 = r10
     450:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     451:	r1 = 0x0 ll
     453:	call 0x1
;   if (likely(value)) {
     454:	if r0 == 0x0 goto +0x2 <LBB2_4>
     455:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     456:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000e48 <LBB2_4>:
     457:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
     458:	r1 = *(u64 *)(r2 + 0x20)
     459:	*(u64 *)(r10 - 0x18) = r1
     460:	r1 = *(u64 *)(r2 + 0x18)
     461:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
     462:	*(u8 *)(r10 - 0xc) = r6
     463:	*(u32 *)(r10 - 0x10) = r6
     464:	r3 = r10
;       .needle = pkt->ipv6->daddr,
     465:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
     466:	r1 = 0x0 ll
     468:	r2 = 0x0 ll
     470:	r4 = 0x0
     471:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
     472:	r1 = *(u8 *)(r10 - 0xc)
     473:	if w1 != 0x0 goto +0xc <LBB2_6>

0000000000000ed0 <LBB2_5>:
     474:	w1 = 0x5
     475:	*(u32 *)(r10 - 0x20) = r1
     476:	r2 = r10
     477:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     478:	r1 = 0x0 ll
     480:	call 0x1
;   if (likely(value)) {
     481:	if r0 == 0x0 goto +0x2 <LBB2_48>
     482:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     483:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000f20 <LBB2_48>:
     484:	w7 = -0x1
     485:	goto +0x147 <LBB2_76>

0000000000000f30 <LBB2_6>:
     486:	w6 = 0x1
     487:	*(u32 *)(r10 - 0x4) = r6
     488:	r2 = r10
     489:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     490:	r1 = 0x0 ll
     492:	call 0x1
;   if (likely(value)) {
     493:	if r0 == 0x0 goto +0x1 <LBB2_8>
;     __sync_fetch_and_add(value, 1);
     494:	lock *(u32 *)(r0 + 0x0) += r6

0000000000000f78 <LBB2_8>:
     495:	r6 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
     496:	r1 = *(u8 *)(r6 + 0x7)
     497:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
     498:	r2 = *(u32 *)(r10 - 0x10)
     499:	if w2 <= w1 goto +0x7a <LBB2_14>
     500:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
     501:	r2 += -0x24
     502:	r1 = 0x0 ll
     504:	call 0x1
;     if (exceed_addr != NULL) {
     505:	if r0 == 0x0 goto +0x74 <LBB2_14>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
     506:	w9 -= w6
     507:	w6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
     508:	w6 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
     509:	if w6 s< 0x1 goto +0x4 <LBB2_13>
     510:	w9 &= 0x3
     511:	if w9 == 0x0 goto +0x2 <LBB2_13>
;     tail_adj = -(new_ip_pkt_len % 4);
     512:	w9 = -w9
     513:	w6 = w9

0000000000001010 <LBB2_13>:
     514:	r1 = *(u64 *)(r10 - 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     515:	r2 = *(u64 *)(r1 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     516:	*(u64 *)(r10 - 0x50) = r2
     517:	r1 = *(u64 *)(r1 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     518:	*(u64 *)(r10 - 0x48) = r1
     519:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     520:	*(u64 *)(r10 - 0x40) = r1
     521:	r1 = *(u64 *)(r0 + 0x0)
     522:	*(u64 *)(r10 - 0x30) = r1
     523:	w1 = 0x6
     524:	*(u32 *)(r10 - 0x20) = r1
     525:	r8 = *(u64 *)(r10 - 0x38)
;   return tail_adj < 0 ? tail_adj : 0;
     526:	if w6 s< 0x0 goto +0x1 <LBB2_50>
     527:	w6 = 0x0

0000000000001080 <LBB2_50>:
     528:	r2 = r10
     529:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     530:	r1 = 0x0 ll
     532:	call 0x1
;   if (likely(value)) {
     533:	if r0 == 0x0 goto +0x2 <LBB2_52>
     534:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     535:	lock *(u32 *)(r0 + 0x0) += r1

00000000000010c0 <LBB2_52>:
;     long rc_head_adj = bpf_skb_adjust_room(ctx,
     536:	r1 = r8
     537:	w2 = 0x30
     538:	w3 = 0x1
     539:	r4 = 0x1
     540:	call 0x32
     541:	w7 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     542:	if r0 != 0x0 goto +0x10e <LBB2_76>
;     int new_len = ctx->len + pkt.tail_adjust;
     543:	r2 = *(u32 *)(r8 + 0x0)
     544:	w2 += w6
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     545:	r1 = r8
     546:	r3 = 0x0
     547:	call 0x26
     548:	if r0 != 0x0 goto +0x108 <LBB2_76>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     549:	r9 = *(u32 *)(r8 + 0x50)
     550:	r6 = *(u32 *)(r8 + 0x4c)
;   assert_boundary(icmp6, pkt->end, false);
     551:	r1 = r6
     552:	r1 += 0x30
     553:	if r1 > r9 goto +0x103 <LBB2_76>
     554:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     555:	*(u32 *)(r6 + 0x0) = r1
     556:	w1 = 0x3
;   *icmp6                    = icmp6_new;
     557:	*(u32 *)(r6 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     558:	r1 = *(u64 *)(r10 - 0x50)
     559:	*(u64 *)(r6 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     560:	r1 = *(u64 *)(r10 - 0x48)
     561:	*(u64 *)(r6 + 0x18) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     562:	r1 = *(u64 *)(r10 - 0x40)
     563:	*(u64 *)(r6 + 0x10) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     564:	r1 = *(u64 *)(r10 - 0x30)
     565:	*(u64 *)(r6 + 0x8) = r1
     566:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     567:	*(u16 *)(r6 + 0x6) = r1
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     568:	r8 = r6
     569:	r8 += 0x28
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     570:	w1 = w9
     571:	w1 -= w8
     572:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     573:	*(u16 *)(r6 + 0x4) = r1
     574:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     575:	*(u32 *)(r6 + 0x2c) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     576:	r3 = r6
     577:	r3 += 0x8
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     578:	r1 = 0x0
     579:	w2 = 0x0
     580:	w4 = 0x20
     581:	w5 = 0x0
     582:	call 0x1c
     583:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     584:	r3 = *(u16 *)(r6 + 0x4)
     585:	w3 <<= 0x10
;   csum += addend;
     586:	w0 = w3
     587:	w0 += w1
     588:	w1 = 0x1
     589:	w2 = 0x1
;   csum += addend;
     590:	if w0 < w3 goto +0x1 <LBB2_57>
     591:	w2 = 0x0

0000000000001280 <LBB2_57>:
     592:	*(u64 *)(r10 - 0x30) = r6
;   return csum + (csum < addend);
     593:	w0 += w2
     594:	if w0 > -0x3a000001 goto +0x1 <LBB2_59>
     595:	w1 = 0x0

00000000000012a0 <LBB2_59>:
;   csum += addend;
     596:	w0 += w1
     597:	w6 = 0x400
;   return csum + (csum < addend);
     598:	w0 += 0x3a000000
     599:	goto +0x4 <LBB2_60>

00000000000012c0 <LBB2_66>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     600:	w1 &= 0xffff
     601:	w6 = w1
     602:	if w1 > 0x4 goto +0x1 <LBB2_60>
     603:	goto +0xad <LBB2_78>

00000000000012e0 <LBB2_60>:
     604:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     605:	if w6 < 0x200 goto +0x1 <LBB2_62>
     606:	w4 = 0x200

00000000000012f8 <LBB2_62>:
;     if (likely(buf + j <= data_end)) {
     607:	r7 = r8
     608:	r7 += r4
     609:	if r7 > r9 goto +0x6 <LBB2_64>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     610:	r1 = 0x0
     611:	w2 = 0x0
     612:	r3 = r8
     613:	w5 = w0
     614:	call 0x1c
     615:	r8 = r7

0000000000001340 <LBB2_64>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     616:	w1 = w6
     617:	w1 += 0xfe00
     618:	if w6 > 0x200 goto -0x13 <LBB2_66>
     619:	w6 >>= 0x1
     620:	w1 = w6
     621:	goto -0x16 <LBB2_66>

0000000000001370 <LBB2_14>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     622:	r1 = *(u8 *)(r6 + 0x6)
     623:	if w1 != 0x3a goto -0x96 <LBB2_5>
     624:	w1 = 0x2
     625:	*(u32 *)(r10 - 0x4) = r1
     626:	r2 = r10
     627:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     628:	r1 = 0x0 ll
     630:	call 0x1
;   if (likely(value)) {
     631:	if r0 == 0x0 goto +0x2 <LBB2_17>
     632:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     633:	lock *(u32 *)(r0 + 0x0) += r1

00000000000013d0 <LBB2_17>:
;   assert_boundary(icmp6, pkt->end, false);
     634:	r1 = r6
     635:	r1 += 0x30
     636:	if r1 > r9 goto -0xa3 <LBB2_5>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     637:	r1 = *(u8 *)(r8 + 0x0)
     638:	if w1 != 0x80 goto -0xa5 <LBB2_5>
;   assert_equal(icmp6->icmp6_code, 0, false);
     639:	r1 = *(u8 *)(r6 + 0x29)
     640:	if w1 != 0x0 goto -0xa7 <LBB2_5>
     641:	w1 = 0x3
     642:	*(u32 *)(r10 - 0x4) = r1
     643:	r2 = r10
     644:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     645:	r1 = 0x0 ll
     647:	call 0x1
;   if (likely(value)) {
     648:	if r0 == 0x0 goto +0x2 <LBB2_22>
     649:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     650:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001458 <LBB2_22>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     651:	r3 = r6
     652:	r3 += 0x8
     653:	r1 = 0x0
     654:	w2 = 0x0
     655:	w4 = 0x20
     656:	w5 = 0x0
     657:	call 0x1c
     658:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     659:	r3 = *(u16 *)(r6 + 0x4)
     660:	w3 <<= 0x10
;   csum += addend;
     661:	w0 = w3
     662:	w0 += w1
     663:	w1 = 0x1
     664:	w2 = 0x1
;   csum += addend;
     665:	if w0 < w3 goto +0x1 <LBB2_24>
     666:	w2 = 0x0

00000000000014d8 <LBB2_24>:
;   return csum + (csum < addend);
     667:	w0 += w2
     668:	if w0 > -0x3a000001 goto +0x1 <LBB2_26>
     669:	w1 = 0x0

00000000000014f0 <LBB2_26>:
;   csum += addend;
     670:	w0 += w1
     671:	w6 = 0x400
;   return csum + (csum < addend);
     672:	w0 += 0x3a000000
     673:	goto +0x4 <LBB2_27>

0000000000001510 <LBB2_33>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     674:	w1 &= 0xffff
     675:	w6 = w1
     676:	if w1 > 0x4 goto +0x1 <LBB2_27>
     677:	goto +0x12 <LBB2_77>

0000000000001530 <LBB2_27>:
     678:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     679:	if w6 < 0x200 goto +0x1 <LBB2_29>
     680:	w4 = 0x200

0000000000001548 <LBB2_29>:
;     if (likely(buf + j <= data_end)) {
     681:	r7 = r8
     682:	r7 += r4
     683:	if r7 > r9 goto +0x6 <LBB2_31>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     684:	r1 = 0x0
     685:	w2 = 0x0
     686:	r3 = r8
     687:	w5 = w0
     688:	call 0x1c
     689:	r8 = r7

0000000000001590 <LBB2_31>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     690:	w1 = w6
     691:	w1 += 0xfe00
     692:	if w6 > 0x200 goto -0x13 <LBB2_33>
     693:	w6 >>= 0x1
     694:	w1 = w6
     695:	goto -0x16 <LBB2_33>

00000000000015c0 <LBB2_77>:
;   if (likely(buf + 4 <= data_end)) {
     696:	r1 = r8
     697:	r1 += 0x4
     698:	r6 = *(u64 *)(r10 - 0x30)
     699:	if r1 > r9 goto +0x9 <LBB2_37>
;     sum = csum_add(sum, *(__be32 *)buf++);
     700:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     701:	w1 = w3
     702:	w1 += w0
     703:	w2 = 0x1
     704:	if w1 < w3 goto +0x1 <LBB2_36>
     705:	w2 = 0x0

0000000000001610 <LBB2_36>:
;   return csum + (csum < addend);
     706:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     707:	r8 += 0x1
     708:	w0 = w1

0000000000001628 <LBB2_37>:
     709:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     710:	r2 = r8
     711:	r2 += 0x2
     712:	if r2 > r9 goto +0x2 <LBB2_39>
;     addend = *(__be16 *)buf++;
     713:	r1 = *(u16 *)(r8 + 0x0)
     714:	r8 += 0x1

0000000000001658 <LBB2_39>:
;   if (likely(buf + 1 <= data_end)) {
     715:	r2 = r8
     716:	r2 += 0x1
     717:	if r2 > r9 goto +0x2 <LBB2_41>
;     addend += *(__u8 *)buf++;
     718:	r2 = *(u8 *)(r8 + 0x0)
     719:	w1 += w2

0000000000001680 <LBB2_41>:
;   csum += addend;
     720:	w2 = w1
     721:	w2 += w0
     722:	w3 = 0x1
     723:	if w2 < w1 goto +0x1 <LBB2_43>
     724:	w3 = 0x0

00000000000016a8 <LBB2_43>:
;   return csum + (csum < addend);
     725:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     726:	w1 = w2
     727:	w1 >>= 0x10
     728:	w2 &= 0xffff
     729:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     730:	w1 = w2
     731:	w1 >>= 0x10
     732:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     733:	w1 &= 0xffff
     734:	if w1 != 0xffff goto -0x105 <LBB2_5>
     735:	w1 = 0x4
     736:	*(u32 *)(r10 - 0x4) = r1
     737:	r2 = r10
     738:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     739:	r1 = 0x0 ll
     741:	call 0x1
     742:	r8 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     743:	if r0 == 0x0 goto +0x2 <LBB2_46>
     744:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     745:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001750 <LBB2_46>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     746:	r1 = *(u64 *)(r6 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     747:	*(u64 *)(r10 - 0x40) = r1
     748:	r9 = *(u64 *)(r6 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     749:	r7 = *(u64 *)(r6 + 0x20)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     750:	r6 = *(u64 *)(r6 + 0x18)
     751:	w1 = 0x7
     752:	*(u32 *)(r10 - 0x20) = r1
     753:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     754:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     755:	r1 = 0x0 ll
     757:	call 0x1
;   if (likely(value)) {
     758:	if r0 == 0x0 goto +0x2 <LBB2_72>
     759:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     760:	lock *(u32 *)(r0 + 0x0) += r1

00000000000017c8 <LBB2_72>:
     761:	w1 = 0x60
     762:	r2 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     763:	*(u32 *)(r2 + 0x0) = r1
     764:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     765:	*(u16 *)(r2 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     766:	r1 = *(u64 *)(r10 - 0x40)
     767:	*(u64 *)(r2 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     768:	*(u64 *)(r2 + 0x18) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     769:	*(u64 *)(r2 + 0x10) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     770:	*(u64 *)(r2 + 0x8) = r6
     771:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     772:	*(u16 *)(r2 + 0x6) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     773:	r1 = *(u16 *)(r2 + 0x2a)
     774:	w1 += -0x1
     775:	*(u16 *)(r2 + 0x2a) = r1
     776:	goto +0x16 <LBB2_73>

0000000000001848 <LBB2_78>:
;   if (likely(buf + 4 <= data_end)) {
     777:	r1 = r8
     778:	r1 += 0x4
     779:	r4 = *(u64 *)(r10 - 0x30)
     780:	if r1 > r9 goto +0x8 <LBB2_70>
;     sum = csum_add(sum, *(__be32 *)buf++);
     781:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     782:	w1 = w3
     783:	w1 += w0
     784:	w2 = 0x1
     785:	if w1 < w3 goto +0x1 <LBB2_69>
     786:	w2 = 0x0

0000000000001898 <LBB2_69>:
;   return csum + (csum < addend);
     787:	w1 += w2
     788:	w0 = w1

00000000000018a8 <LBB2_70>:
;   sum = (sum & 0xffff) + (sum >> 16);
     789:	w1 = w0
     790:	w1 >>= 0x10
     791:	w0 &= 0xffff
     792:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     793:	w1 = w0
     794:	w1 >>= 0x10
     795:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     796:	w1 ^= -0x1
     797:	*(u16 *)(r4 + 0x2a) = r1
     798:	r8 = *(u64 *)(r10 - 0x38)

00000000000018f8 <LBB2_73>:
     799:	w1 = 0x8
     800:	*(u32 *)(r10 - 0x20) = r1
     801:	r2 = r10
     802:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     803:	r1 = 0x0 ll
     805:	call 0x1
;   if (likely(value)) {
     806:	if r0 == 0x0 goto +0x2 <LBB2_75>
     807:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     808:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001948 <LBB2_75>:
;   return bpf_redirect(ctx->ifindex, 0);
     809:	r1 = *(u32 *)(r8 + 0x28)
     810:	r2 = 0x0
     811:	call 0x17
     812:	r7 = r0

0000000000001968 <LBB2_76>:
;   return exceed2go_tc(ctx, BASE_LAYER_L3);
     813:	w0 = w7
     814:	exit
