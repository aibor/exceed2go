
exceed2go_bpfel.o:	file format elf64-bpf

Disassembly of section .text:

0000000000000000 <target_search_cb>:
;                  struct target_search_cb_ctx *cb_ctx) {
       0:	r0 = 0x0
;   if (*key == 0) {
       1:	r1 = *(u32 *)(r2 + 0x0)
       2:	if w1 == 0x0 goto +0xf <LBB3_6>
       3:	r0 = 0x1
;   if (!value || !((const __u32 *)(value))[0])
       4:	if r3 == 0x0 goto +0xd <LBB3_6>
       5:	r2 = *(u32 *)(r3 + 0x0)
       6:	if w2 == 0x0 goto +0xb <LBB3_6>
;   return ((a->in6_u.u6_addr64[0] == b->in6_u.u6_addr64[0]) &&
       7:	r2 = *(u64 *)(r3 + 0x0)
       8:	r5 = *(u64 *)(r4 + 0x0)
       9:	r0 = 0x0
      10:	if r5 != r2 goto +0x7 <LBB3_6>
;           (a->in6_u.u6_addr64[1] == b->in6_u.u6_addr64[1]));
      11:	r2 = *(u64 *)(r3 + 0x8)
      12:	r3 = *(u64 *)(r4 + 0x8)
;   if (in6_addr_equal(&cb_ctx->needle, value)) {
      13:	if r3 != r2 goto +0x4 <LBB3_6>
;     cb_ctx->key   = *key;
      14:	*(u32 *)(r4 + 0x10) = r1
      15:	w1 = 0x1
;     cb_ctx->found = true;
      16:	*(u8 *)(r4 + 0x14) = r1
      17:	r0 = 0x1

0000000000000090 <LBB3_6>:
; }
      18:	exit

Disassembly of section xdp:

0000000000000000 <exceed2go_xdp_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r2 = *(u32 *)(r1 + 0x0)
       1:	r9 = *(u32 *)(r1 + 0x4)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       2:	r8 = r2
       3:	r8 += 0x36
       4:	if r8 > r9 goto +0x24 <LBB0_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       5:	r3 = *(u16 *)(r2 + 0xc)
       6:	if w3 != 0xdd86 goto +0x22 <LBB0_6>
       7:	r6 = r2
       8:	r6 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
       9:	r3 = *(u8 *)(r6 + 0x0)
      10:	w3 &= 0xf0
      11:	if w3 != 0x60 goto +0x1d <LBB0_6>
      12:	*(u64 *)(r10 - 0x38) = r1
      13:	*(u64 *)(r10 - 0x30) = r2
      14:	w7 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r7
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB0_5>
      22:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB0_5>:
      24:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
      25:	r1 = *(u64 *)(r2 + 0x2e)
      26:	*(u64 *)(r10 - 0x18) = r1
      27:	r1 = *(u64 *)(r2 + 0x26)
      28:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      29:	*(u8 *)(r10 - 0xc) = r7
      30:	*(u32 *)(r10 - 0x10) = r7
      31:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      32:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      33:	r1 = 0x0 ll
      35:	r2 = 0x0 ll
      37:	r4 = 0x0
      38:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      39:	r1 = *(u8 *)(r10 - 0xc)
      40:	if w1 != 0x0 goto +0xc <LBB0_7>

0000000000000148 <LBB0_6>:
      41:	w1 = 0x5
      42:	*(u32 *)(r10 - 0x20) = r1
      43:	r2 = r10
      44:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      45:	r1 = 0x0 ll
      47:	call 0x1
;   if (likely(value)) {
      48:	if r0 == 0x0 goto +0x2 <LBB0_49>
      49:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      50:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000198 <LBB0_49>:
      51:	w8 = 0x2
      52:	goto +0x15e <LBB0_77>

00000000000001a8 <LBB0_7>:
      53:	*(u64 *)(r10 - 0x40) = r6
      54:	w6 = 0x1
      55:	*(u32 *)(r10 - 0x4) = r6
      56:	r2 = r10
      57:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      58:	r1 = 0x0 ll
      60:	call 0x1
;   if (likely(value)) {
      61:	if r0 == 0x0 goto +0x1 <LBB0_9>
;     __sync_fetch_and_add(value, 1);
      62:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001f8 <LBB0_9>:
      63:	r7 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
      64:	r1 = *(u8 *)(r7 + 0x15)
      65:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      66:	r2 = *(u32 *)(r10 - 0x10)
      67:	if w2 <= w1 goto +0x84 <LBB0_15>
      68:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      69:	r2 += -0x24
      70:	r1 = 0x0 ll
      72:	call 0x1
;     if (exceed_addr != NULL) {
      73:	if r0 == 0x0 goto +0x7e <LBB0_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      74:	r1 = *(u64 *)(r10 - 0x40)
      75:	w9 -= w1
      76:	w6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      77:	w6 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      78:	if w6 s< 0x1 goto +0x4 <LBB0_14>
      79:	w9 &= 0x3
      80:	if w9 == 0x0 goto +0x2 <LBB0_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      81:	w9 = -w9
      82:	w6 = w9

0000000000000298 <LBB0_14>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      83:	r1 = *(u64 *)(r7 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      84:	*(u64 *)(r10 - 0x40) = r1
      85:	r1 = *(u64 *)(r7 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      86:	*(u64 *)(r10 - 0x50) = r1
      87:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      88:	*(u64 *)(r10 - 0x48) = r1
      89:	r1 = *(u64 *)(r0 + 0x0)
      90:	*(u64 *)(r10 - 0x30) = r1
      91:	w1 = 0x6
      92:	*(u32 *)(r10 - 0x20) = r1
;   return tail_adj < 0 ? tail_adj : 0;
      93:	if w6 s< 0x0 goto +0x1 <LBB0_51>
      94:	w6 = 0x0

00000000000002f8 <LBB0_51>:
      95:	r2 = r10
      96:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      97:	r1 = 0x0 ll
      99:	call 0x1
     100:	r7 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     101:	if r0 == 0x0 goto +0x2 <LBB0_53>
     102:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     103:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000340 <LBB0_53>:
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
     104:	r1 = r7
     105:	w2 = -0x30
     106:	call 0x2c
     107:	w8 = 0x0
;     assert_equal(bpf_xdp_adjust_head(ctx, -(int)ADJ_LEN), 0, XDP_ABORTED);
     108:	if r0 != 0x0 goto +0x126 <LBB0_77>
;     assert_equal(bpf_xdp_adjust_tail(ctx, tail_adj), 0, XDP_ABORTED);
     109:	r1 = r7
     110:	w2 = w6
     111:	call 0x41
     112:	if r0 != 0x0 goto +0x122 <LBB0_77>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     113:	r9 = *(u32 *)(r7 + 0x4)
     114:	r6 = *(u32 *)(r7 + 0x0)
;       assert_boundary(old_eth, pkt.end, XDP_ABORTED);
     115:	r1 = r6
     116:	r1 += 0x3e
     117:	if r1 > r9 goto +0x11d <LBB0_77>
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     118:	r7 = r6
     119:	r7 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     120:	w1 = w9
     121:	w1 -= w7
     122:	w2 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     123:	*(u32 *)(r6 + 0xe) = r2
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     124:	r2 = *(u64 *)(r10 - 0x50)
     125:	*(u64 *)(r6 + 0x26) = r2
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     126:	r2 = *(u64 *)(r10 - 0x48)
     127:	*(u64 *)(r6 + 0x1e) = r2
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     128:	r2 = *(u64 *)(r10 - 0x30)
     129:	*(u64 *)(r6 + 0x16) = r2
     130:	w2 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     131:	*(u16 *)(r6 + 0x14) = r2
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     132:	r2 = *(u16 *)(r6 + 0x38)
     133:	*(u16 *)(r6 + 0x2) = r2
     134:	r2 = *(u16 *)(r6 + 0x36)
     135:	*(u16 *)(r6 + 0x0) = r2
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     136:	r2 = *(u16 *)(r6 + 0x32)
     137:	*(u16 *)(r6 + 0x8) = r2
     138:	r2 = *(u16 *)(r6 + 0x30)
     139:	*(u16 *)(r6 + 0x6) = r2
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     140:	r2 = *(u16 *)(r6 + 0x3a)
     141:	*(u16 *)(r6 + 0x4) = r2
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     142:	r2 = *(u16 *)(r6 + 0x34)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     143:	r3 = *(u64 *)(r10 - 0x40)
     144:	*(u64 *)(r6 + 0x2e) = r3
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     145:	*(u16 *)(r6 + 0xa) = r2
;   new->proto = old->proto;
     146:	r2 = *(u16 *)(r6 + 0x3c)
     147:	*(u16 *)(r6 + 0xc) = r2
     148:	w2 = 0x3
;   *icmp6                    = icmp6_new;
     149:	*(u32 *)(r6 + 0x36) = r2
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     150:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     151:	*(u16 *)(r6 + 0x12) = r1
     152:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     153:	*(u32 *)(r6 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     154:	r3 = r6
     155:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     156:	r1 = 0x0
     157:	w2 = 0x0
     158:	w4 = 0x20
     159:	w5 = 0x0
     160:	call 0x1c
     161:	r1 = r0
     162:	*(u64 *)(r10 - 0x30) = r6
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     163:	r3 = *(u16 *)(r6 + 0x12)
     164:	w3 <<= 0x10
;   csum += addend;
     165:	w0 = w3
     166:	w0 += w1
     167:	w1 = 0x1
     168:	w2 = 0x1
;   csum += addend;
     169:	if w0 < w3 goto +0x1 <LBB0_58>
     170:	w2 = 0x0

0000000000000558 <LBB0_58>:
;   return csum + (csum < addend);
     171:	w0 += w2
     172:	if w0 > -0x3a000001 goto +0x1 <LBB0_60>
     173:	w1 = 0x0

0000000000000570 <LBB0_60>:
;   csum += addend;
     174:	w0 += w1
     175:	w8 = 0x400
;   return csum + (csum < addend);
     176:	w0 += 0x3a000000
     177:	goto +0x4 <LBB0_61>

0000000000000590 <LBB0_67>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     178:	w1 &= 0xffff
     179:	w8 = w1
     180:	if w1 > 0x4 goto +0x1 <LBB0_61>
     181:	goto +0xbd <LBB0_79>

00000000000005b0 <LBB0_61>:
     182:	w4 = w8
;     __u16 j = (i >= 512) ? 512 : i;
     183:	if w8 < 0x200 goto +0x1 <LBB0_63>
     184:	w4 = 0x200

00000000000005c8 <LBB0_63>:
;     if (likely(buf + j <= data_end)) {
     185:	r6 = r7
     186:	r6 += r4
     187:	if r6 > r9 goto +0x6 <LBB0_65>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     188:	r1 = 0x0
     189:	w2 = 0x0
     190:	r3 = r7
     191:	w5 = w0
     192:	call 0x1c
     193:	r7 = r6

0000000000000610 <LBB0_65>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     194:	w1 = w8
     195:	w1 += 0xfe00
     196:	if w8 > 0x200 goto -0x13 <LBB0_67>
     197:	w8 >>= 0x1
     198:	w1 = w8
     199:	goto -0x16 <LBB0_67>

0000000000000640 <LBB0_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     200:	r1 = *(u8 *)(r7 + 0x14)
     201:	if w1 != 0x3a goto -0xa1 <LBB0_6>
     202:	w1 = 0x2
     203:	*(u32 *)(r10 - 0x4) = r1
     204:	r2 = r10
     205:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     206:	r1 = 0x0 ll
     208:	call 0x1
;   if (likely(value)) {
     209:	if r0 == 0x0 goto +0x2 <LBB0_18>
     210:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     211:	lock *(u32 *)(r0 + 0x0) += r1

00000000000006a0 <LBB0_18>:
;   assert_boundary(icmp6, pkt->end, false);
     212:	r1 = r7
     213:	r1 += 0x3e
     214:	if r1 > r9 goto -0xae <LBB0_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     215:	r1 = *(u8 *)(r8 + 0x0)
     216:	if w1 != 0x80 goto -0xb0 <LBB0_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     217:	r1 = *(u8 *)(r7 + 0x37)
     218:	if w1 != 0x0 goto -0xb2 <LBB0_6>
     219:	w1 = 0x3
     220:	*(u32 *)(r10 - 0x4) = r1
     221:	r2 = r10
     222:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     223:	r1 = 0x0 ll
     225:	call 0x1
;   if (likely(value)) {
     226:	if r0 == 0x0 goto +0x2 <LBB0_23>
     227:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     228:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000728 <LBB0_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     229:	r3 = r7
     230:	r3 += 0x16
     231:	r1 = 0x0
     232:	w2 = 0x0
     233:	w4 = 0x20
     234:	w5 = 0x0
     235:	call 0x1c
     236:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     237:	r3 = *(u16 *)(r7 + 0x12)
     238:	w3 <<= 0x10
;   csum += addend;
     239:	w0 = w3
     240:	w0 += w1
     241:	w1 = 0x1
     242:	w2 = 0x1
;   csum += addend;
     243:	if w0 < w3 goto +0x1 <LBB0_25>
     244:	w2 = 0x0

00000000000007a8 <LBB0_25>:
;   return csum + (csum < addend);
     245:	w0 += w2
     246:	if w0 > -0x3a000001 goto +0x1 <LBB0_27>
     247:	w1 = 0x0

00000000000007c0 <LBB0_27>:
;   csum += addend;
     248:	w0 += w1
     249:	w7 = 0x400
;   return csum + (csum < addend);
     250:	w0 += 0x3a000000
     251:	goto +0x4 <LBB0_28>

00000000000007e0 <LBB0_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     252:	w1 &= 0xffff
     253:	w7 = w1
     254:	if w1 > 0x4 goto +0x1 <LBB0_28>
     255:	goto +0x12 <LBB0_78>

0000000000000800 <LBB0_28>:
     256:	w4 = w7
;     __u16 j = (i >= 512) ? 512 : i;
     257:	if w7 < 0x200 goto +0x1 <LBB0_30>
     258:	w4 = 0x200

0000000000000818 <LBB0_30>:
;     if (likely(buf + j <= data_end)) {
     259:	r6 = r8
     260:	r6 += r4
     261:	if r6 > r9 goto +0x6 <LBB0_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     262:	r1 = 0x0
     263:	w2 = 0x0
     264:	r3 = r8
     265:	w5 = w0
     266:	call 0x1c
     267:	r8 = r6

0000000000000860 <LBB0_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     268:	w1 = w7
     269:	w1 += 0xfe00
     270:	if w7 > 0x200 goto -0x13 <LBB0_34>
     271:	w7 >>= 0x1
     272:	w1 = w7
     273:	goto -0x16 <LBB0_34>

0000000000000890 <LBB0_78>:
;   if (likely(buf + 4 <= data_end)) {
     274:	r1 = r8
     275:	r1 += 0x4
     276:	r6 = *(u64 *)(r10 - 0x30)
     277:	if r1 > r9 goto +0x9 <LBB0_38>
;     sum = csum_add(sum, *(__be32 *)buf++);
     278:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     279:	w1 = w3
     280:	w1 += w0
     281:	w2 = 0x1
     282:	if w1 < w3 goto +0x1 <LBB0_37>
     283:	w2 = 0x0

00000000000008e0 <LBB0_37>:
;   return csum + (csum < addend);
     284:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     285:	r8 += 0x1
     286:	w0 = w1

00000000000008f8 <LBB0_38>:
     287:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     288:	r2 = r8
     289:	r2 += 0x2
     290:	if r2 > r9 goto +0x2 <LBB0_40>
;     addend = *(__be16 *)buf++;
     291:	r1 = *(u16 *)(r8 + 0x0)
     292:	r8 += 0x1

0000000000000928 <LBB0_40>:
;   if (likely(buf + 1 <= data_end)) {
     293:	r2 = r8
     294:	r2 += 0x1
     295:	if r2 > r9 goto +0x2 <LBB0_42>
;     addend += *(__u8 *)buf++;
     296:	r2 = *(u8 *)(r8 + 0x0)
     297:	w1 += w2

0000000000000950 <LBB0_42>:
;   csum += addend;
     298:	w2 = w1
     299:	w2 += w0
     300:	w3 = 0x1
     301:	if w2 < w1 goto +0x1 <LBB0_44>
     302:	w3 = 0x0

0000000000000978 <LBB0_44>:
;   return csum + (csum < addend);
     303:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     304:	w1 = w2
     305:	w1 >>= 0x10
     306:	w2 &= 0xffff
     307:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     308:	w1 = w2
     309:	w1 >>= 0x10
     310:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     311:	w1 &= 0xffff
     312:	if w1 != 0xffff goto -0x110 <LBB0_6>
     313:	w1 = 0x4
     314:	*(u32 *)(r10 - 0x4) = r1
     315:	r2 = r10
     316:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     317:	r1 = 0x0 ll
     319:	call 0x1
;   if (likely(value)) {
     320:	if r0 == 0x0 goto +0x2 <LBB0_47>
     321:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     322:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000a18 <LBB0_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     323:	r8 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     324:	r9 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     325:	r7 = *(u64 *)(r6 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     326:	r6 = *(u64 *)(r6 + 0x26)
     327:	w1 = 0x7
     328:	*(u32 *)(r10 - 0x20) = r1
     329:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     330:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     331:	r1 = 0x0 ll
     333:	call 0x1
;   if (likely(value)) {
     334:	if r0 == 0x0 goto +0x2 <LBB0_73>
     335:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     336:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000a88 <LBB0_73>:
     337:	r3 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(&tmp, &old->daddr, sizeof(struct mac_addr));
     338:	r1 = *(u16 *)(r3 + 0x4)
     339:	*(u16 *)(r10 - 0x1c) = r1
     340:	r1 = *(u16 *)(r3 + 0x2)
     341:	w1 <<= 0x10
     342:	r2 = *(u16 *)(r3 + 0x0)
     343:	w1 |= w2
     344:	*(u32 *)(r10 - 0x20) = r1
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     345:	r1 = *(u16 *)(r3 + 0x6)
     346:	*(u16 *)(r3 + 0x0) = r1
     347:	r1 = *(u16 *)(r3 + 0x8)
     348:	*(u16 *)(r3 + 0x2) = r1
     349:	r1 = *(u16 *)(r3 + 0xa)
     350:	*(u16 *)(r3 + 0x4) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     351:	r1 = *(u16 *)(r10 - 0x1c)
     352:	*(u16 *)(r3 + 0xa) = r1
     353:	r1 = *(u32 *)(r10 - 0x20)
     354:	*(u16 *)(r3 + 0x6) = r1
     355:	w1 >>= 0x10
     356:	*(u16 *)(r3 + 0x8) = r1
     357:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     358:	*(u32 *)(r3 + 0xe) = r1
     359:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     360:	*(u16 *)(r3 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     361:	*(u64 *)(r3 + 0x2e) = r8
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     362:	*(u64 *)(r3 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     363:	*(u64 *)(r3 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     364:	*(u64 *)(r3 + 0x16) = r6
     365:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     366:	*(u16 *)(r3 + 0x14) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     367:	r1 = *(u16 *)(r3 + 0x38)
     368:	w1 += -0x1
     369:	*(u16 *)(r3 + 0x38) = r1
     370:	goto +0x15 <LBB0_74>

0000000000000b98 <LBB0_79>:
;   if (likely(buf + 4 <= data_end)) {
     371:	r1 = r7
     372:	r1 += 0x4
     373:	if r1 > r9 goto +0x8 <LBB0_71>
;     sum = csum_add(sum, *(__be32 *)buf++);
     374:	r3 = *(u32 *)(r7 + 0x0)
;   csum += addend;
     375:	w1 = w3
     376:	w1 += w0
     377:	w2 = 0x1
     378:	if w1 < w3 goto +0x1 <LBB0_70>
     379:	w2 = 0x0

0000000000000be0 <LBB0_70>:
;   return csum + (csum < addend);
     380:	w1 += w2
     381:	w0 = w1

0000000000000bf0 <LBB0_71>:
;   sum = (sum & 0xffff) + (sum >> 16);
     382:	w1 = w0
     383:	w1 >>= 0x10
     384:	w0 &= 0xffff
     385:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     386:	w1 = w0
     387:	w1 >>= 0x10
     388:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     389:	w1 ^= -0x1
     390:	r2 = *(u64 *)(r10 - 0x30)
     391:	*(u16 *)(r2 + 0x38) = r1

0000000000000c40 <LBB0_74>:
     392:	w1 = 0x8
     393:	*(u32 *)(r10 - 0x20) = r1
     394:	r2 = r10
     395:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     396:	r1 = 0x0 ll
     398:	call 0x1
;   if (likely(value)) {
     399:	if r0 == 0x0 goto +0x2 <LBB0_76>
     400:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     401:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000c90 <LBB0_76>:
     402:	w8 = 0x3

0000000000000c98 <LBB0_77>:
;   return exceed2go_xdp(ctx, BASE_LAYER_L2);
     403:	w0 = w8
     404:	exit

Disassembly of section tc:

0000000000000000 <exceed2go_tc_l2>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       0:	r9 = *(u32 *)(r1 + 0x50)
       1:	*(u64 *)(r10 - 0x38) = r1
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
       2:	r2 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
       3:	r8 = r2
       4:	r8 += 0x36
       5:	if r8 > r9 goto +0x23 <LBB1_6>
;     assert_equal(pkt->eth->proto, bpf_htons(ETH_P_IPV6), PKT_UNRELATED);
       6:	r1 = *(u16 *)(r2 + 0xc)
       7:	if w1 != 0xdd86 goto +0x21 <LBB1_6>
       8:	r7 = r2
       9:	r7 += 0xe
;   assert_equal(pkt->ipv6->version, 6, false);
      10:	r1 = *(u8 *)(r7 + 0x0)
      11:	w1 &= 0xf0
      12:	if w1 != 0x60 goto +0x1c <LBB1_6>
      13:	*(u64 *)(r10 - 0x30) = r2
      14:	w6 = 0x0
      15:	*(u32 *)(r10 - 0x20) = r6
      16:	r2 = r10
      17:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      18:	r1 = 0x0 ll
      20:	call 0x1
;   if (likely(value)) {
      21:	if r0 == 0x0 goto +0x2 <LBB1_5>
      22:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      23:	lock *(u32 *)(r0 + 0x0) += r1

00000000000000c0 <LBB1_5>:
      24:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
      25:	r1 = *(u64 *)(r2 + 0x2e)
      26:	*(u64 *)(r10 - 0x18) = r1
      27:	r1 = *(u64 *)(r2 + 0x26)
      28:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
      29:	*(u8 *)(r10 - 0xc) = r6
      30:	*(u32 *)(r10 - 0x10) = r6
      31:	r3 = r10
;       .needle = pkt->ipv6->daddr,
      32:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
      33:	r1 = 0x0 ll
      35:	r2 = 0x0 ll
      37:	r4 = 0x0
      38:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
      39:	r1 = *(u8 *)(r10 - 0xc)
      40:	if w1 != 0x0 goto +0xc <LBB1_7>

0000000000000148 <LBB1_6>:
      41:	w1 = 0x5
      42:	*(u32 *)(r10 - 0x20) = r1
      43:	r2 = r10
      44:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      45:	r1 = 0x0 ll
      47:	call 0x1
;   if (likely(value)) {
      48:	if r0 == 0x0 goto +0x2 <LBB1_49>
      49:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
      50:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000198 <LBB1_49>:
      51:	w7 = -0x1
      52:	goto +0x185 <LBB1_81>

00000000000001a8 <LBB1_7>:
      53:	w6 = 0x1
      54:	*(u32 *)(r10 - 0x4) = r6
      55:	r2 = r10
      56:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      57:	r1 = 0x0 ll
      59:	call 0x1
;   if (likely(value)) {
      60:	if r0 == 0x0 goto +0x1 <LBB1_9>
;     __sync_fetch_and_add(value, 1);
      61:	lock *(u32 *)(r0 + 0x0) += r6

00000000000001f0 <LBB1_9>:
      62:	r6 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
      63:	r1 = *(u8 *)(r6 + 0x15)
      64:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
      65:	r2 = *(u32 *)(r10 - 0x10)
      66:	if w2 <= w1 goto +0x3f <LBB1_15>
      67:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
      68:	r2 += -0x24
      69:	r1 = 0x0 ll
      71:	call 0x1
;     if (exceed_addr != NULL) {
      72:	if r0 == 0x0 goto +0x39 <LBB1_15>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
      73:	w9 -= w7
      74:	w6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
      75:	w6 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
      76:	if w6 s< 0x1 goto +0x4 <LBB1_14>
      77:	w9 &= 0x3
      78:	if w9 == 0x0 goto +0x2 <LBB1_14>
;     tail_adj = -(new_ip_pkt_len % 4);
      79:	w9 = -w9
      80:	w6 = w9

0000000000000288 <LBB1_14>:
      81:	r1 = *(u64 *)(r10 - 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      82:	r2 = *(u64 *)(r1 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      83:	*(u64 *)(r10 - 0x58) = r2
      84:	r1 = *(u64 *)(r1 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
      85:	*(u64 *)(r10 - 0x50) = r1
      86:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
      87:	*(u64 *)(r10 - 0x48) = r1
      88:	r1 = *(u64 *)(r0 + 0x0)
      89:	*(u64 *)(r10 - 0x40) = r1
      90:	w1 = 0x6
      91:	*(u32 *)(r10 - 0x20) = r1
      92:	r8 = *(u64 *)(r10 - 0x38)
;   return tail_adj < 0 ? tail_adj : 0;
      93:	if w6 s< 0x0 goto +0x1 <LBB1_51>
      94:	w6 = 0x0

00000000000002f8 <LBB1_51>:
      95:	r2 = r10
      96:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
      97:	r1 = 0x0 ll
      99:	call 0x1
;   if (likely(value)) {
     100:	if r0 == 0x0 goto +0x2 <LBB1_53>
     101:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     102:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000338 <LBB1_53>:
     103:	r4 = *(u64 *)(r10 - 0x30)
;       bpf_memcpy(&eth, pkt.eth, sizeof(struct ethhdr));
     104:	r1 = *(u16 *)(r4 + 0xa)
     105:	w1 <<= 0x10
     106:	r2 = *(u16 *)(r4 + 0x8)
     107:	w1 |= w2
     108:	*(u32 *)(r10 - 0x18) = r1
     109:	r1 = *(u16 *)(r4 + 0x0)
     110:	r2 = *(u16 *)(r4 + 0x2)
     111:	r2 <<= 0x10
     112:	r2 |= r1
     113:	r1 = *(u16 *)(r4 + 0x6)
     114:	w1 <<= 0x10
     115:	r3 = *(u16 *)(r4 + 0x4)
     116:	w1 |= w3
     117:	r1 <<= 0x20
     118:	r1 |= r2
     119:	*(u64 *)(r10 - 0x20) = r1
     120:	r1 = *(u16 *)(r4 + 0xc)
;     if (ctx->protocol == bpf_htons(ETH_P_IPV6)) {
     121:	*(u32 *)(r10 - 0x30) = r1
     122:	r1 = *(u32 *)(r8 + 0x10)
     123:	if w1 != 0xdd86 goto +0xb4 <LBB1_55>
;       rc_head_adj = bpf_skb_adjust_room(ctx,
     124:	r1 = r8
     125:	w2 = 0x30
     126:	w3 = 0x1
     127:	r4 = 0x1
     128:	call 0x32
     129:	goto +0xb2 <LBB1_56>

0000000000000410 <LBB1_15>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     130:	r1 = *(u8 *)(r6 + 0x14)
     131:	if w1 != 0x3a goto -0x5b <LBB1_6>
     132:	w1 = 0x2
     133:	*(u32 *)(r10 - 0x4) = r1
     134:	r2 = r10
     135:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     136:	r1 = 0x0 ll
     138:	call 0x1
;   if (likely(value)) {
     139:	if r0 == 0x0 goto +0x2 <LBB1_18>
     140:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     141:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000470 <LBB1_18>:
;   assert_boundary(icmp6, pkt->end, false);
     142:	r1 = r6
     143:	r1 += 0x3e
     144:	if r1 > r9 goto -0x68 <LBB1_6>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     145:	r1 = *(u8 *)(r8 + 0x0)
     146:	if w1 != 0x80 goto -0x6a <LBB1_6>
;   assert_equal(icmp6->icmp6_code, 0, false);
     147:	r1 = *(u8 *)(r6 + 0x37)
     148:	if w1 != 0x0 goto -0x6c <LBB1_6>
     149:	w1 = 0x3
     150:	*(u32 *)(r10 - 0x4) = r1
     151:	r2 = r10
     152:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     153:	r1 = 0x0 ll
     155:	call 0x1
;   if (likely(value)) {
     156:	if r0 == 0x0 goto +0x2 <LBB1_23>
     157:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     158:	lock *(u32 *)(r0 + 0x0) += r1

00000000000004f8 <LBB1_23>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     159:	r3 = r6
     160:	r3 += 0x16
     161:	r1 = 0x0
     162:	w2 = 0x0
     163:	w4 = 0x20
     164:	w5 = 0x0
     165:	call 0x1c
     166:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     167:	r3 = *(u16 *)(r6 + 0x12)
     168:	w3 <<= 0x10
;   csum += addend;
     169:	w0 = w3
     170:	w0 += w1
     171:	w1 = 0x1
     172:	w2 = 0x1
;   csum += addend;
     173:	if w0 < w3 goto +0x1 <LBB1_25>
     174:	w2 = 0x0

0000000000000578 <LBB1_25>:
;   return csum + (csum < addend);
     175:	w0 += w2
     176:	if w0 > -0x3a000001 goto +0x1 <LBB1_27>
     177:	w1 = 0x0

0000000000000590 <LBB1_27>:
;   csum += addend;
     178:	w0 += w1
     179:	w6 = 0x400
;   return csum + (csum < addend);
     180:	w0 += 0x3a000000
     181:	goto +0x4 <LBB1_28>

00000000000005b0 <LBB1_34>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     182:	w1 &= 0xffff
     183:	w6 = w1
     184:	if w1 > 0x4 goto +0x1 <LBB1_28>
     185:	goto +0x12 <LBB1_82>

00000000000005d0 <LBB1_28>:
     186:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     187:	if w6 < 0x200 goto +0x1 <LBB1_30>
     188:	w4 = 0x200

00000000000005e8 <LBB1_30>:
;     if (likely(buf + j <= data_end)) {
     189:	r7 = r8
     190:	r7 += r4
     191:	if r7 > r9 goto +0x6 <LBB1_32>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     192:	r1 = 0x0
     193:	w2 = 0x0
     194:	r3 = r8
     195:	w5 = w0
     196:	call 0x1c
     197:	r8 = r7

0000000000000630 <LBB1_32>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     198:	w1 = w6
     199:	w1 += 0xfe00
     200:	if w6 > 0x200 goto -0x13 <LBB1_34>
     201:	w6 >>= 0x1
     202:	w1 = w6
     203:	goto -0x16 <LBB1_34>

0000000000000660 <LBB1_82>:
;   if (likely(buf + 4 <= data_end)) {
     204:	r1 = r8
     205:	r1 += 0x4
     206:	r6 = *(u64 *)(r10 - 0x30)
     207:	if r1 > r9 goto +0x9 <LBB1_38>
;     sum = csum_add(sum, *(__be32 *)buf++);
     208:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     209:	w1 = w3
     210:	w1 += w0
     211:	w2 = 0x1
     212:	if w1 < w3 goto +0x1 <LBB1_37>
     213:	w2 = 0x0

00000000000006b0 <LBB1_37>:
;   return csum + (csum < addend);
     214:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     215:	r8 += 0x1
     216:	w0 = w1

00000000000006c8 <LBB1_38>:
     217:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     218:	r2 = r8
     219:	r2 += 0x2
     220:	if r2 > r9 goto +0x2 <LBB1_40>
;     addend = *(__be16 *)buf++;
     221:	r1 = *(u16 *)(r8 + 0x0)
     222:	r8 += 0x1

00000000000006f8 <LBB1_40>:
;   if (likely(buf + 1 <= data_end)) {
     223:	r2 = r8
     224:	r2 += 0x1
     225:	if r2 > r9 goto +0x2 <LBB1_42>
;     addend += *(__u8 *)buf++;
     226:	r2 = *(u8 *)(r8 + 0x0)
     227:	w1 += w2

0000000000000720 <LBB1_42>:
;   csum += addend;
     228:	w2 = w1
     229:	w2 += w0
     230:	w3 = 0x1
     231:	if w2 < w1 goto +0x1 <LBB1_44>
     232:	w3 = 0x0

0000000000000748 <LBB1_44>:
;   return csum + (csum < addend);
     233:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     234:	w1 = w2
     235:	w1 >>= 0x10
     236:	w2 &= 0xffff
     237:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     238:	w1 = w2
     239:	w1 >>= 0x10
     240:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     241:	w1 &= 0xffff
     242:	if w1 != 0xffff goto -0xca <LBB1_6>
     243:	w1 = 0x4
     244:	*(u32 *)(r10 - 0x4) = r1
     245:	r2 = r10
     246:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     247:	r1 = 0x0 ll
     249:	call 0x1
     250:	r8 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     251:	if r0 == 0x0 goto +0x2 <LBB1_47>
     252:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     253:	lock *(u32 *)(r0 + 0x0) += r1

00000000000007f0 <LBB1_47>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     254:	r1 = *(u64 *)(r6 + 0x1e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     255:	*(u64 *)(r10 - 0x40) = r1
     256:	r9 = *(u64 *)(r6 + 0x16)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     257:	r7 = *(u64 *)(r6 + 0x2e)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     258:	r6 = *(u64 *)(r6 + 0x26)
     259:	w1 = 0x7
     260:	*(u32 *)(r10 - 0x20) = r1
     261:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     262:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     263:	r1 = 0x0 ll
     265:	call 0x1
;   if (likely(value)) {
     266:	if r0 == 0x0 goto +0x2 <LBB1_77>
     267:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     268:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000868 <LBB1_77>:
     269:	r3 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(&tmp, &old->daddr, sizeof(struct mac_addr));
     270:	r1 = *(u16 *)(r3 + 0x4)
     271:	*(u16 *)(r10 - 0x1c) = r1
     272:	r1 = *(u16 *)(r3 + 0x2)
     273:	w1 <<= 0x10
     274:	r2 = *(u16 *)(r3 + 0x0)
     275:	w1 |= w2
     276:	*(u32 *)(r10 - 0x20) = r1
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     277:	r1 = *(u16 *)(r3 + 0x6)
     278:	*(u16 *)(r3 + 0x0) = r1
     279:	r1 = *(u16 *)(r3 + 0x8)
     280:	*(u16 *)(r3 + 0x2) = r1
     281:	r1 = *(u16 *)(r3 + 0xa)
     282:	*(u16 *)(r3 + 0x4) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     283:	r1 = *(u16 *)(r10 - 0x1c)
     284:	*(u16 *)(r3 + 0xa) = r1
     285:	r1 = *(u32 *)(r10 - 0x20)
     286:	*(u16 *)(r3 + 0x6) = r1
     287:	w1 >>= 0x10
     288:	*(u16 *)(r3 + 0x8) = r1
     289:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     290:	*(u32 *)(r3 + 0xe) = r1
     291:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     292:	*(u16 *)(r3 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     293:	r1 = *(u64 *)(r10 - 0x40)
     294:	*(u64 *)(r3 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     295:	*(u64 *)(r3 + 0x26) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     296:	*(u64 *)(r3 + 0x1e) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     297:	*(u64 *)(r3 + 0x16) = r6
     298:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     299:	*(u16 *)(r3 + 0x14) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     300:	r1 = *(u16 *)(r3 + 0x38)
     301:	w1 += -0x1
     302:	*(u16 *)(r3 + 0x38) = r1
     303:	goto +0x7c <LBB1_78>

0000000000000980 <LBB1_55>:
;       rc_head_adj = bpf_skb_change_head(ctx, (u32)ADJ_LEN, 0);
     304:	r1 = r8
     305:	w2 = 0x30
     306:	r3 = 0x0
     307:	call 0x2b

00000000000009a0 <LBB1_56>:
     308:	w7 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     309:	if r0 != 0x0 goto +0x84 <LBB1_81>
;     int new_len = ctx->len + pkt.tail_adjust;
     310:	r2 = *(u32 *)(r8 + 0x0)
     311:	w2 += w6
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     312:	r1 = r8
     313:	r3 = 0x0
     314:	call 0x26
     315:	if r0 != 0x0 goto +0x7e <LBB1_81>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     316:	r9 = *(u32 *)(r8 + 0x50)
     317:	r6 = *(u32 *)(r8 + 0x4c)
;       assert_boundary(pkt.eth, pkt.end, TC_ACT_SHOT);
     318:	r1 = r6
     319:	r1 += 0xe
     320:	if r1 > r9 goto +0x79 <LBB1_81>
;   bpf_memcpy(&new->daddr, &old->saddr, sizeof(struct mac_addr));
     321:	r1 = *(u16 *)(r10 - 0x16)
     322:	*(u16 *)(r6 + 0x4) = r1
     323:	r1 = *(u16 *)(r10 - 0x18)
     324:	*(u16 *)(r6 + 0x2) = r1
     325:	r1 = *(u16 *)(r10 - 0x1a)
     326:	*(u16 *)(r6 + 0x0) = r1
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     327:	r1 = *(u32 *)(r10 - 0x20)
     328:	r2 = *(u16 *)(r10 - 0x1c)
;   new->proto = old->proto;
     329:	r3 = *(u32 *)(r10 - 0x30)
     330:	*(u16 *)(r6 + 0xc) = r3
;   bpf_memcpy(&new->saddr, &tmp, sizeof(struct mac_addr));
     331:	*(u16 *)(r6 + 0xa) = r2
     332:	*(u16 *)(r6 + 0x6) = r1
     333:	w1 >>= 0x10
     334:	*(u16 *)(r6 + 0x8) = r1
;   assert_boundary(icmp6, pkt->end, false);
     335:	r1 = r6
     336:	r1 += 0x3e
     337:	if r1 > r9 goto +0x68 <LBB1_81>
     338:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     339:	*(u32 *)(r6 + 0xe) = r1
     340:	w1 = 0x3
;   *icmp6                    = icmp6_new;
     341:	*(u32 *)(r6 + 0x36) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     342:	r1 = *(u64 *)(r10 - 0x58)
     343:	*(u64 *)(r6 + 0x2e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     344:	r1 = *(u64 *)(r10 - 0x50)
     345:	*(u64 *)(r6 + 0x26) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     346:	r1 = *(u64 *)(r10 - 0x48)
     347:	*(u64 *)(r6 + 0x1e) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     348:	r1 = *(u64 *)(r10 - 0x40)
     349:	*(u64 *)(r6 + 0x16) = r1
     350:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     351:	*(u16 *)(r6 + 0x14) = r1
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     352:	r8 = r6
     353:	r8 += 0x36
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     354:	w1 = w9
     355:	w1 -= w8
     356:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     357:	*(u16 *)(r6 + 0x12) = r1
     358:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     359:	*(u32 *)(r6 + 0x3a) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     360:	r3 = r6
     361:	r3 += 0x16
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     362:	r1 = 0x0
     363:	w2 = 0x0
     364:	w4 = 0x20
     365:	w5 = 0x0
     366:	call 0x1c
     367:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     368:	r3 = *(u16 *)(r6 + 0x12)
     369:	w3 <<= 0x10
;   csum += addend;
     370:	w0 = w3
     371:	w0 += w1
     372:	w1 = 0x1
     373:	w2 = 0x1
;   csum += addend;
     374:	if w0 < w3 goto +0x1 <LBB1_62>
     375:	w2 = 0x0

0000000000000bc0 <LBB1_62>:
     376:	*(u64 *)(r10 - 0x30) = r6
;   return csum + (csum < addend);
     377:	w0 += w2
     378:	if w0 > -0x3a000001 goto +0x1 <LBB1_64>
     379:	w1 = 0x0

0000000000000be0 <LBB1_64>:
;   csum += addend;
     380:	w0 += w1
     381:	w6 = 0x400
;   return csum + (csum < addend);
     382:	w0 += 0x3a000000
     383:	goto +0x4 <LBB1_65>

0000000000000c00 <LBB1_71>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     384:	w1 &= 0xffff
     385:	w6 = w1
     386:	if w1 > 0x4 goto +0x1 <LBB1_65>
     387:	goto +0x12 <LBB1_83>

0000000000000c20 <LBB1_65>:
     388:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     389:	if w6 < 0x200 goto +0x1 <LBB1_67>
     390:	w4 = 0x200

0000000000000c38 <LBB1_67>:
;     if (likely(buf + j <= data_end)) {
     391:	r7 = r8
     392:	r7 += r4
     393:	if r7 > r9 goto +0x6 <LBB1_69>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     394:	r1 = 0x0
     395:	w2 = 0x0
     396:	r3 = r8
     397:	w5 = w0
     398:	call 0x1c
     399:	r8 = r7

0000000000000c80 <LBB1_69>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     400:	w1 = w6
     401:	w1 += 0xfe00
     402:	if w6 > 0x200 goto -0x13 <LBB1_71>
     403:	w6 >>= 0x1
     404:	w1 = w6
     405:	goto -0x16 <LBB1_71>

0000000000000cb0 <LBB1_83>:
;   if (likely(buf + 4 <= data_end)) {
     406:	r1 = r8
     407:	r1 += 0x4
     408:	r4 = *(u64 *)(r10 - 0x30)
     409:	if r1 > r9 goto +0x8 <LBB1_75>
;     sum = csum_add(sum, *(__be32 *)buf++);
     410:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     411:	w1 = w3
     412:	w1 += w0
     413:	w2 = 0x1
     414:	if w1 < w3 goto +0x1 <LBB1_74>
     415:	w2 = 0x0

0000000000000d00 <LBB1_74>:
;   return csum + (csum < addend);
     416:	w1 += w2
     417:	w0 = w1

0000000000000d10 <LBB1_75>:
;   sum = (sum & 0xffff) + (sum >> 16);
     418:	w1 = w0
     419:	w1 >>= 0x10
     420:	w0 &= 0xffff
     421:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     422:	w1 = w0
     423:	w1 >>= 0x10
     424:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     425:	w1 ^= -0x1
     426:	*(u16 *)(r4 + 0x38) = r1
     427:	r8 = *(u64 *)(r10 - 0x38)

0000000000000d60 <LBB1_78>:
     428:	w1 = 0x8
     429:	*(u32 *)(r10 - 0x4) = r1
     430:	r2 = r10
     431:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     432:	r1 = 0x0 ll
     434:	call 0x1
;   if (likely(value)) {
     435:	if r0 == 0x0 goto +0x2 <LBB1_80>
     436:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     437:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000db0 <LBB1_80>:
;   return bpf_redirect(ctx->ifindex, 0);
     438:	r1 = *(u32 *)(r8 + 0x28)
     439:	r2 = 0x0
     440:	call 0x17
     441:	r7 = r0

0000000000000dd0 <LBB1_81>:
;   return exceed2go_tc(ctx, BASE_LAYER_L2);
     442:	w0 = w7
     443:	exit

0000000000000de0 <exceed2go_tc_l3>:
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     444:	r9 = *(u32 *)(r1 + 0x50)
     445:	*(u64 *)(r10 - 0x38) = r1
;   pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     446:	r2 = *(u32 *)(r1 + 0x4c)
;   assert_boundary(pkt->ipv6, pkt->end, false);
     447:	r8 = r2
     448:	r8 += 0x28
     449:	if r8 > r9 goto +0x1f <LBB2_5>
;   assert_equal(pkt->ipv6->version, 6, false);
     450:	r1 = *(u8 *)(r2 + 0x0)
     451:	w1 &= 0xf0
     452:	if w1 != 0x60 goto +0x1c <LBB2_5>
     453:	*(u64 *)(r10 - 0x30) = r2
     454:	w6 = 0x0
     455:	*(u32 *)(r10 - 0x20) = r6
     456:	r2 = r10
     457:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     458:	r1 = 0x0 ll
     460:	call 0x1
;   if (likely(value)) {
     461:	if r0 == 0x0 goto +0x2 <LBB2_4>
     462:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     463:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000e80 <LBB2_4>:
     464:	r2 = *(u64 *)(r10 - 0x30)
;       .needle = pkt->ipv6->daddr,
     465:	r1 = *(u64 *)(r2 + 0x20)
     466:	*(u64 *)(r10 - 0x18) = r1
     467:	r1 = *(u64 *)(r2 + 0x18)
     468:	*(u64 *)(r10 - 0x20) = r1
;   struct target_search_cb_ctx target = {
     469:	*(u8 *)(r10 - 0xc) = r6
     470:	*(u32 *)(r10 - 0x10) = r6
     471:	r3 = r10
;       .needle = pkt->ipv6->daddr,
     472:	r3 += -0x20
;   bpf_for_each_map_elem(&exceed2go_addrs, target_search_cb, &target, 0);
     473:	r1 = 0x0 ll
     475:	r2 = 0x0 ll
     477:	r4 = 0x0
     478:	call 0xa4
;   assert_equal(target.found, true, PKT_UNRELATED);
     479:	r1 = *(u8 *)(r10 - 0xc)
     480:	if w1 != 0x0 goto +0xc <LBB2_6>

0000000000000f08 <LBB2_5>:
     481:	w1 = 0x5
     482:	*(u32 *)(r10 - 0x20) = r1
     483:	r2 = r10
     484:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     485:	r1 = 0x0 ll
     487:	call 0x1
;   if (likely(value)) {
     488:	if r0 == 0x0 goto +0x2 <LBB2_48>
     489:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     490:	lock *(u32 *)(r0 + 0x0) += r1

0000000000000f58 <LBB2_48>:
     491:	w7 = -0x1
     492:	goto +0x14e <LBB2_79>

0000000000000f68 <LBB2_6>:
     493:	w6 = 0x1
     494:	*(u32 *)(r10 - 0x4) = r6
     495:	r2 = r10
     496:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     497:	r1 = 0x0 ll
     499:	call 0x1
;   if (likely(value)) {
     500:	if r0 == 0x0 goto +0x1 <LBB2_8>
;     __sync_fetch_and_add(value, 1);
     501:	lock *(u32 *)(r0 + 0x0) += r6

0000000000000fb0 <LBB2_8>:
     502:	r6 = *(u64 *)(r10 - 0x30)
;   __u32 hop_key = pkt->ipv6->hop_limit;
     503:	r1 = *(u8 *)(r6 + 0x7)
     504:	*(u32 *)(r10 - 0x24) = r1
;   if (target.key > hop_key) {
     505:	r2 = *(u32 *)(r10 - 0x10)
     506:	if w2 <= w1 goto +0x2c <LBB2_14>
     507:	r2 = r10
;         bpf_map_lookup_elem(&exceed2go_addrs, &hop_key);
     508:	r2 += -0x24
     509:	r1 = 0x0 ll
     511:	call 0x1
;     if (exceed_addr != NULL) {
     512:	if r0 == 0x0 goto +0x26 <LBB2_14>
;       pkt->tail_adjust = tail_adjust(pkt->end - (void *)pkt->ipv6);
     513:	w9 -= w6
     514:	w6 = 0x4d0
;   int   tail_adj       = IPV6_MTU_MIN - new_ip_pkt_len;
     515:	w6 -= w9
;   if (tail_adj > 0 && new_ip_pkt_len % 4) {
     516:	if w6 s< 0x1 goto +0x4 <LBB2_13>
     517:	w9 &= 0x3
     518:	if w9 == 0x0 goto +0x2 <LBB2_13>
;     tail_adj = -(new_ip_pkt_len % 4);
     519:	w9 = -w9
     520:	w6 = w9

0000000000001048 <LBB2_13>:
     521:	r1 = *(u64 *)(r10 - 0x30)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     522:	r2 = *(u64 *)(r1 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     523:	*(u64 *)(r10 - 0x50) = r2
     524:	r1 = *(u64 *)(r1 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     525:	*(u64 *)(r10 - 0x48) = r1
     526:	r1 = *(u64 *)(r0 + 0x8)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     527:	*(u64 *)(r10 - 0x40) = r1
     528:	r1 = *(u64 *)(r0 + 0x0)
     529:	*(u64 *)(r10 - 0x30) = r1
     530:	w1 = 0x6
     531:	*(u32 *)(r10 - 0x20) = r1
     532:	r8 = *(u64 *)(r10 - 0x38)
;   return tail_adj < 0 ? tail_adj : 0;
     533:	if w6 s< 0x0 goto +0x1 <LBB2_50>
     534:	w6 = 0x0

00000000000010b8 <LBB2_50>:
     535:	r2 = r10
     536:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     537:	r1 = 0x0 ll
     539:	call 0x1
;   if (likely(value)) {
     540:	if r0 == 0x0 goto +0x2 <LBB2_52>
     541:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     542:	lock *(u32 *)(r0 + 0x0) += r1

00000000000010f8 <LBB2_52>:
;     if (ctx->protocol == bpf_htons(ETH_P_IPV6)) {
     543:	r1 = *(u32 *)(r8 + 0x10)
     544:	if w1 != 0xdd86 goto +0xa1 <LBB2_54>
;       rc_head_adj = bpf_skb_adjust_room(ctx,
     545:	r1 = r8
     546:	w2 = 0x30
     547:	w3 = 0x1
     548:	r4 = 0x1
     549:	call 0x32
     550:	goto +0x9f <LBB2_55>

0000000000001138 <LBB2_14>:
;   assert_equal(pkt->ipv6->nexthdr, IPPROTO_ICMPV6, PKT_UNRELATED);
     551:	r1 = *(u8 *)(r6 + 0x6)
     552:	if w1 != 0x3a goto -0x48 <LBB2_5>
     553:	w1 = 0x2
     554:	*(u32 *)(r10 - 0x4) = r1
     555:	r2 = r10
     556:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     557:	r1 = 0x0 ll
     559:	call 0x1
;   if (likely(value)) {
     560:	if r0 == 0x0 goto +0x2 <LBB2_17>
     561:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     562:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001198 <LBB2_17>:
;   assert_boundary(icmp6, pkt->end, false);
     563:	r1 = r6
     564:	r1 += 0x30
     565:	if r1 > r9 goto -0x55 <LBB2_5>
;   assert_equal(icmp6->icmp6_type, ICMP6_ECHO_REQUEST, PKT_UNRELATED);
     566:	r1 = *(u8 *)(r8 + 0x0)
     567:	if w1 != 0x80 goto -0x57 <LBB2_5>
;   assert_equal(icmp6->icmp6_code, 0, false);
     568:	r1 = *(u8 *)(r6 + 0x29)
     569:	if w1 != 0x0 goto -0x59 <LBB2_5>
     570:	w1 = 0x3
     571:	*(u32 *)(r10 - 0x4) = r1
     572:	r2 = r10
     573:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     574:	r1 = 0x0 ll
     576:	call 0x1
;   if (likely(value)) {
     577:	if r0 == 0x0 goto +0x2 <LBB2_22>
     578:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     579:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001220 <LBB2_22>:
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     580:	r3 = r6
     581:	r3 += 0x8
     582:	r1 = 0x0
     583:	w2 = 0x0
     584:	w4 = 0x20
     585:	w5 = 0x0
     586:	call 0x1c
     587:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     588:	r3 = *(u16 *)(r6 + 0x4)
     589:	w3 <<= 0x10
;   csum += addend;
     590:	w0 = w3
     591:	w0 += w1
     592:	w1 = 0x1
     593:	w2 = 0x1
;   csum += addend;
     594:	if w0 < w3 goto +0x1 <LBB2_24>
     595:	w2 = 0x0

00000000000012a0 <LBB2_24>:
;   return csum + (csum < addend);
     596:	w0 += w2
     597:	if w0 > -0x3a000001 goto +0x1 <LBB2_26>
     598:	w1 = 0x0

00000000000012b8 <LBB2_26>:
;   csum += addend;
     599:	w0 += w1
     600:	w6 = 0x400
;   return csum + (csum < addend);
     601:	w0 += 0x3a000000
     602:	goto +0x4 <LBB2_27>

00000000000012d8 <LBB2_33>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     603:	w1 &= 0xffff
     604:	w6 = w1
     605:	if w1 > 0x4 goto +0x1 <LBB2_27>
     606:	goto +0x12 <LBB2_80>

00000000000012f8 <LBB2_27>:
     607:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     608:	if w6 < 0x200 goto +0x1 <LBB2_29>
     609:	w4 = 0x200

0000000000001310 <LBB2_29>:
;     if (likely(buf + j <= data_end)) {
     610:	r7 = r8
     611:	r7 += r4
     612:	if r7 > r9 goto +0x6 <LBB2_31>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     613:	r1 = 0x0
     614:	w2 = 0x0
     615:	r3 = r8
     616:	w5 = w0
     617:	call 0x1c
     618:	r8 = r7

0000000000001358 <LBB2_31>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     619:	w1 = w6
     620:	w1 += 0xfe00
     621:	if w6 > 0x200 goto -0x13 <LBB2_33>
     622:	w6 >>= 0x1
     623:	w1 = w6
     624:	goto -0x16 <LBB2_33>

0000000000001388 <LBB2_80>:
;   if (likely(buf + 4 <= data_end)) {
     625:	r1 = r8
     626:	r1 += 0x4
     627:	r6 = *(u64 *)(r10 - 0x30)
     628:	if r1 > r9 goto +0x9 <LBB2_37>
;     sum = csum_add(sum, *(__be32 *)buf++);
     629:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     630:	w1 = w3
     631:	w1 += w0
     632:	w2 = 0x1
     633:	if w1 < w3 goto +0x1 <LBB2_36>
     634:	w2 = 0x0

00000000000013d8 <LBB2_36>:
;   return csum + (csum < addend);
     635:	w1 += w2
;     sum = csum_add(sum, *(__be32 *)buf++);
     636:	r8 += 0x1
     637:	w0 = w1

00000000000013f0 <LBB2_37>:
     638:	w1 = 0x0
;   if (likely(buf + 2 <= data_end)) {
     639:	r2 = r8
     640:	r2 += 0x2
     641:	if r2 > r9 goto +0x2 <LBB2_39>
;     addend = *(__be16 *)buf++;
     642:	r1 = *(u16 *)(r8 + 0x0)
     643:	r8 += 0x1

0000000000001420 <LBB2_39>:
;   if (likely(buf + 1 <= data_end)) {
     644:	r2 = r8
     645:	r2 += 0x1
     646:	if r2 > r9 goto +0x2 <LBB2_41>
;     addend += *(__u8 *)buf++;
     647:	r2 = *(u8 *)(r8 + 0x0)
     648:	w1 += w2

0000000000001448 <LBB2_41>:
;   csum += addend;
     649:	w2 = w1
     650:	w2 += w0
     651:	w3 = 0x1
     652:	if w2 < w1 goto +0x1 <LBB2_43>
     653:	w3 = 0x0

0000000000001470 <LBB2_43>:
;   return csum + (csum < addend);
     654:	w2 += w3
;   sum = (sum & 0xffff) + (sum >> 16);
     655:	w1 = w2
     656:	w1 >>= 0x10
     657:	w2 &= 0xffff
     658:	w2 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     659:	w1 = w2
     660:	w1 >>= 0x10
     661:	w1 += w2
;   assert_equal(csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, false)),
     662:	w1 &= 0xffff
     663:	if w1 != 0xffff goto -0xb7 <LBB2_5>
     664:	w1 = 0x4
     665:	*(u32 *)(r10 - 0x4) = r1
     666:	r2 = r10
     667:	r2 += -0x4
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     668:	r1 = 0x0 ll
     670:	call 0x1
     671:	r8 = *(u64 *)(r10 - 0x38)
;   if (likely(value)) {
     672:	if r0 == 0x0 goto +0x2 <LBB2_46>
     673:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     674:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001518 <LBB2_46>:
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     675:	r1 = *(u64 *)(r6 + 0x10)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     676:	*(u64 *)(r10 - 0x40) = r1
     677:	r9 = *(u64 *)(r6 + 0x8)
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     678:	r7 = *(u64 *)(r6 + 0x20)
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     679:	r6 = *(u64 *)(r6 + 0x18)
     680:	w1 = 0x7
     681:	*(u32 *)(r10 - 0x20) = r1
     682:	r2 = r10
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     683:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     684:	r1 = 0x0 ll
     686:	call 0x1
;   if (likely(value)) {
     687:	if r0 == 0x0 goto +0x2 <LBB2_75>
     688:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     689:	lock *(u32 *)(r0 + 0x0) += r1

0000000000001590 <LBB2_75>:
     690:	w1 = 0x60
     691:	r2 = *(u64 *)(r10 - 0x30)
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     692:	*(u32 *)(r2 + 0x0) = r1
     693:	w1 = 0x81
;   icmp6->icmp6_type = ICMP6_ECHO_REPLY;
     694:	*(u16 *)(r2 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     695:	r1 = *(u64 *)(r10 - 0x40)
     696:	*(u64 *)(r2 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     697:	*(u64 *)(r2 + 0x18) = r9
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     698:	*(u64 *)(r2 + 0x10) = r7
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     699:	*(u64 *)(r2 + 0x8) = r6
     700:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     701:	*(u16 *)(r2 + 0x6) = r1
;   icmp6->icmp6_cksum += ICMP6_ECHO_REQUEST - ICMP6_ECHO_REPLY;
     702:	r1 = *(u16 *)(r2 + 0x2a)
     703:	w1 += -0x1
     704:	*(u16 *)(r2 + 0x2a) = r1
     705:	goto +0x6b <LBB2_76>

0000000000001610 <LBB2_54>:
;       rc_head_adj = bpf_skb_change_head(ctx, (u32)ADJ_LEN, 0);
     706:	r1 = r8
     707:	w2 = 0x30
     708:	r3 = 0x0
     709:	call 0x2b

0000000000001630 <LBB2_55>:
     710:	w7 = 0x2
;     assert_equal(rc_head_adj, 0, TC_ACT_SHOT);
     711:	if r0 != 0x0 goto +0x73 <LBB2_79>
;     int new_len = ctx->len + pkt.tail_adjust;
     712:	r2 = *(u32 *)(r8 + 0x0)
     713:	w2 += w6
;     assert_equal(bpf_skb_change_tail(ctx, new_len, 0), 0, TC_ACT_SHOT);
     714:	r1 = r8
     715:	r3 = 0x0
     716:	call 0x26
     717:	if r0 != 0x0 goto +0x6d <LBB2_79>
;     pkt_info_set_ptrs(&pkt, ctx->data, ctx->data_end, base_layer);
     718:	r9 = *(u32 *)(r8 + 0x50)
     719:	r6 = *(u32 *)(r8 + 0x4c)
;   assert_boundary(icmp6, pkt->end, false);
     720:	r1 = r6
     721:	r1 += 0x30
     722:	if r1 > r9 goto +0x68 <LBB2_79>
     723:	w1 = 0x60
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     724:	*(u32 *)(r6 + 0x0) = r1
     725:	w1 = 0x3
;   *icmp6                    = icmp6_new;
     726:	*(u32 *)(r6 + 0x28) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     727:	r1 = *(u64 *)(r10 - 0x50)
     728:	*(u64 *)(r6 + 0x20) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     729:	r1 = *(u64 *)(r10 - 0x48)
     730:	*(u64 *)(r6 + 0x18) = r1
;   (dest->in6_u.u6_addr64[1] = src->in6_u.u6_addr64[1]);
     731:	r1 = *(u64 *)(r10 - 0x40)
     732:	*(u64 *)(r6 + 0x10) = r1
;   (dest->in6_u.u6_addr64[0] = src->in6_u.u6_addr64[0]);
     733:	r1 = *(u64 *)(r10 - 0x30)
     734:	*(u64 *)(r6 + 0x8) = r1
     735:	w1 = 0x403a
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     736:	*(u16 *)(r6 + 0x6) = r1
;   struct icmp6hdr *icmp6 = next_header(pkt->ipv6);
     737:	r8 = r6
     738:	r8 += 0x28
;   __be16 payload_len = bpf_htons(pkt->end - (void *)icmp6);
     739:	w1 = w9
     740:	w1 -= w8
     741:	r1 = be16 r1
;   bpf_memcpy(ipv6, &ipv6_new, sizeof(struct ipv6hdr) - 2 * IPV6_ALEN);
     742:	*(u16 *)(r6 + 0x4) = r1
     743:	w1 = 0x0
;   *icmp6                    = icmp6_new;
     744:	*(u32 *)(r6 + 0x2c) = r1
;   in6_addr_copy(&pkt->ipv6->saddr, &pkt->reply_saddr);
     745:	r3 = r6
     746:	r3 += 0x8
;   sum = bpf_csum_diff(NULL, 0, (void *)&ipv6->saddr, 2 * IPV6_ALEN, sum);
     747:	r1 = 0x0
     748:	w2 = 0x0
     749:	w4 = 0x20
     750:	w5 = 0x0
     751:	call 0x1c
     752:	r1 = r0
;   sum = csum_add(sum, ((__u32)ipv6->payload_len) << 16);
     753:	r3 = *(u16 *)(r6 + 0x4)
     754:	w3 <<= 0x10
;   csum += addend;
     755:	w0 = w3
     756:	w0 += w1
     757:	w1 = 0x1
     758:	w2 = 0x1
;   csum += addend;
     759:	if w0 < w3 goto +0x1 <LBB2_60>
     760:	w2 = 0x0

00000000000017c8 <LBB2_60>:
     761:	*(u64 *)(r10 - 0x30) = r6
;   return csum + (csum < addend);
     762:	w0 += w2
     763:	if w0 > -0x3a000001 goto +0x1 <LBB2_62>
     764:	w1 = 0x0

00000000000017e8 <LBB2_62>:
;   csum += addend;
     765:	w0 += w1
     766:	w6 = 0x400
;   return csum + (csum < addend);
     767:	w0 += 0x3a000000
     768:	goto +0x4 <LBB2_63>

0000000000001808 <LBB2_69>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     769:	w1 &= 0xffff
     770:	w6 = w1
     771:	if w1 > 0x4 goto +0x1 <LBB2_63>
     772:	goto +0x12 <LBB2_81>

0000000000001828 <LBB2_63>:
     773:	w4 = w6
;     __u16 j = (i >= 512) ? 512 : i;
     774:	if w6 < 0x200 goto +0x1 <LBB2_65>
     775:	w4 = 0x200

0000000000001840 <LBB2_65>:
;     if (likely(buf + j <= data_end)) {
     776:	r7 = r8
     777:	r7 += r4
     778:	if r7 > r9 goto +0x6 <LBB2_67>
;       sum = bpf_csum_diff(NULL, 0, buf, j, sum);
     779:	r1 = 0x0
     780:	w2 = 0x0
     781:	r3 = r8
     782:	w5 = w0
     783:	call 0x1c
     784:	r8 = r7

0000000000001888 <LBB2_67>:
;   for (__u16 i = 1024; i > 4; i = (i > 512) ? (i - 512) : i >> 1) {
     785:	w1 = w6
     786:	w1 += 0xfe00
     787:	if w6 > 0x200 goto -0x13 <LBB2_69>
     788:	w6 >>= 0x1
     789:	w1 = w6
     790:	goto -0x16 <LBB2_69>

00000000000018b8 <LBB2_81>:
;   if (likely(buf + 4 <= data_end)) {
     791:	r1 = r8
     792:	r1 += 0x4
     793:	r4 = *(u64 *)(r10 - 0x30)
     794:	if r1 > r9 goto +0x8 <LBB2_73>
;     sum = csum_add(sum, *(__be32 *)buf++);
     795:	r3 = *(u32 *)(r8 + 0x0)
;   csum += addend;
     796:	w1 = w3
     797:	w1 += w0
     798:	w2 = 0x1
     799:	if w1 < w3 goto +0x1 <LBB2_72>
     800:	w2 = 0x0

0000000000001908 <LBB2_72>:
;   return csum + (csum < addend);
     801:	w1 += w2
     802:	w0 = w1

0000000000001918 <LBB2_73>:
;   sum = (sum & 0xffff) + (sum >> 16);
     803:	w1 = w0
     804:	w1 >>= 0x10
     805:	w0 &= 0xffff
     806:	w0 += w1
;   sum = (sum & 0xffff) + (sum >> 16);
     807:	w1 = w0
     808:	w1 >>= 0x10
     809:	w1 += w0
;   icmp6->icmp6_cksum = ~csum_fold(icmp6_csum(icmp6, pkt->ipv6, pkt->end, true));
     810:	w1 ^= -0x1
     811:	*(u16 *)(r4 + 0x2a) = r1
     812:	r8 = *(u64 *)(r10 - 0x38)

0000000000001968 <LBB2_76>:
     813:	w1 = 0x8
     814:	*(u32 *)(r10 - 0x20) = r1
     815:	r2 = r10
     816:	r2 += -0x20
;   __u32 *value = bpf_map_lookup_elem(&exceed2go_counters, &key);
     817:	r1 = 0x0 ll
     819:	call 0x1
;   if (likely(value)) {
     820:	if r0 == 0x0 goto +0x2 <LBB2_78>
     821:	w1 = 0x1
;     __sync_fetch_and_add(value, 1);
     822:	lock *(u32 *)(r0 + 0x0) += r1

00000000000019b8 <LBB2_78>:
;   return bpf_redirect(ctx->ifindex, 0);
     823:	r1 = *(u32 *)(r8 + 0x28)
     824:	r2 = 0x0
     825:	call 0x17
     826:	r7 = r0

00000000000019d8 <LBB2_79>:
;   return exceed2go_tc(ctx, BASE_LAYER_L3);
     827:	w0 = w7
     828:	exit
